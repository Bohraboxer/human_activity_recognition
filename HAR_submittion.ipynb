{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "onrdAzmNBhLy",
    "outputId": "24013a82-2244-481a-9295-d97091fe06b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
      "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-98946cf9-1a47-4980-8e4d-80fa0d7af36f\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-98946cf9-1a47-4980-8e4d-80fa0d7af36f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"rohitbohra2994\",\"key\":\"b7947860e2ad40758c4dac7cbd51c8ff\"}'}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VG_Tlr2xi_sE",
    "outputId": "cd725995-7738-4e7f-f91c-0795f09b91d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading humana.zip to /content\n",
      " 98% 83.0M/84.5M [00:00<00:00, 74.3MB/s]\n",
      "100% 84.5M/84.5M [00:00<00:00, 96.4MB/s]\n",
      "humana.zip  kaggle.json  sample_data\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d pankajkarki/humana\n",
    "\n",
    "\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "NiZW_0zH1eSj",
    "outputId": "41874b66-b1f4-4b76-aaf4-90649f9d966b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  humana.zip\n",
      "   creating: HAR/UCI_HAR_Dataset/\n",
      "  inflating: HAR/UCI_HAR_Dataset/.DS_Store  \n",
      "  inflating: HAR/UCI_HAR_Dataset/_DS_Store  \n",
      "  inflating: HAR/UCI_HAR_Dataset/activity_labels.txt  \n",
      "   creating: HAR/UCI_HAR_Dataset/csv_files/\n",
      "  inflating: HAR/UCI_HAR_Dataset/csv_files/test.csv  \n",
      "  inflating: HAR/UCI_HAR_Dataset/csv_files/train.csv  \n",
      "  inflating: HAR/UCI_HAR_Dataset/features.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/features_info.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/README.txt  \n",
      "   creating: HAR/UCI_HAR_Dataset/test/\n",
      "   creating: HAR/UCI_HAR_Dataset/test/Inertial Signals/\n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_acc_x_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_acc_y_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_acc_z_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_gyro_x_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_gyro_y_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/body_gyro_z_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/total_acc_x_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/total_acc_y_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/Inertial Signals/total_acc_z_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/subject_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/X_test.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/test/y_test.txt  \n",
      "   creating: HAR/UCI_HAR_Dataset/train/\n",
      "  inflating: HAR/UCI_HAR_Dataset/train/.DS_Store  \n",
      "   creating: HAR/UCI_HAR_Dataset/train/Inertial Signals/\n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_acc_x_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_acc_y_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_acc_z_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_gyro_x_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_gyro_y_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/body_gyro_z_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/total_acc_x_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/total_acc_y_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/Inertial Signals/total_acc_z_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/subject_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/X_train.txt  \n",
      "  inflating: HAR/UCI_HAR_Dataset/train/y_train.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip humana.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuadSumpGNWG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJZDnBfrBs-0"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0OVCb2DEBvPi"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6F_mPdyBBxwx"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYr75bJaB1Xq"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebquO0yGB41h"
   },
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcxGleVEB765"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hHtfVaILB-KB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitbohra/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQlvFf9rCBqn"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W2y-sIG-CDhf",
    "outputId": "5bc673da-b11a-48d8-fcab-894351bf5c44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goQoq6KLCF13"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hStoyqMACgxx"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJzFKW1yCioB"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDqSPCeCCk2g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitbohra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "/Users/rohitbohra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tMbi1zMTCnkX",
    "outputId": "e2f24014-33e7-470f-d278-ad1251e0eedb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cYu3ANuuu3ol",
    "outputId": "aec990c9-7ef1-44b1-fffb-d6b40e167f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UohGxpWu9G8"
   },
   "outputs": [],
   "source": [
    "def create_model(neurons,dropout_rate):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, input_shape=(timesteps, input_dim)))\n",
    "\tmodel.add(Dropout(dropout_rate))\n",
    "\tmodel.add(Dense(n_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpREf6tzu_xt"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsegmcChvCW8"
   },
   "outputs": [],
   "source": [
    "neurons = [48, 128]\n",
    "dropout_rate = [0.3, 0.5, 0.7]\n",
    "param_grid = dict(neurons=neurons,dropout_rate=dropout_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33442
    },
    "colab_type": "code",
    "id": "yDEJhbhjvMdD",
    "outputId": "a99cf09f-05f2-4d8e-f203-c4f3814927c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.5194 - acc: 0.3758 - val_loss: 1.3882 - val_acc: 0.3485\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2841 - acc: 0.4756 - val_loss: 1.2731 - val_acc: 0.4418\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1908 - acc: 0.4915 - val_loss: 1.2457 - val_acc: 0.4102\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1570 - acc: 0.4779 - val_loss: 1.2479 - val_acc: 0.4102\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1365 - acc: 0.4795 - val_loss: 1.2611 - val_acc: 0.3997\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0653 - acc: 0.4974 - val_loss: 1.1544 - val_acc: 0.4408\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0016 - acc: 0.4952 - val_loss: 1.0480 - val_acc: 0.4520\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9396 - acc: 0.4962 - val_loss: 0.9866 - val_acc: 0.4503\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1224 - acc: 0.4828 - val_loss: 1.2151 - val_acc: 0.4126\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9580 - acc: 0.4875 - val_loss: 1.0257 - val_acc: 0.4316\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.8501 - acc: 0.4960 - val_loss: 0.9471 - val_acc: 0.4510\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8986 - acc: 0.4926 - val_loss: 0.9077 - val_acc: 0.4445\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8285 - acc: 0.5136 - val_loss: 0.8843 - val_acc: 0.4846\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7993 - acc: 0.5668 - val_loss: 0.9073 - val_acc: 0.5775\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7813 - acc: 0.6346 - val_loss: 0.9335 - val_acc: 0.6437\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7617 - acc: 0.6666 - val_loss: 0.9385 - val_acc: 0.6264\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7523 - acc: 0.6658 - val_loss: 0.9723 - val_acc: 0.6088\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7724 - acc: 0.6631 - val_loss: 0.9227 - val_acc: 0.5931\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7933 - acc: 0.6564 - val_loss: 0.8660 - val_acc: 0.6013\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7019 - acc: 0.6493 - val_loss: 0.8327 - val_acc: 0.5884\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.7965 - acc: 0.6121 - val_loss: 0.8546 - val_acc: 0.5762\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.6798 - acc: 0.6344 - val_loss: 0.8035 - val_acc: 0.5786\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6755 - acc: 0.6333 - val_loss: 0.8191 - val_acc: 0.5938\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6515 - acc: 0.6388 - val_loss: 0.8130 - val_acc: 0.6023\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6147 - acc: 0.6513 - val_loss: 0.7593 - val_acc: 0.6064\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5731 - acc: 0.6668 - val_loss: 0.7348 - val_acc: 0.6074\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5402 - acc: 0.6803 - val_loss: 0.7050 - val_acc: 0.6216\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5168 - acc: 0.7035 - val_loss: 0.6287 - val_acc: 0.6267\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5177 - acc: 0.7141 - val_loss: 0.6035 - val_acc: 0.7363\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4990 - acc: 0.7649 - val_loss: 0.6697 - val_acc: 0.7326\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4860 - acc: 0.7843 - val_loss: 0.6501 - val_acc: 0.7489\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4910 - acc: 0.7964 - val_loss: 0.6244 - val_acc: 0.7458\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4592 - acc: 0.8037 - val_loss: 0.8790 - val_acc: 0.6722\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4205 - acc: 0.8090 - val_loss: 0.5326 - val_acc: 0.7608\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4122 - acc: 0.8088 - val_loss: 0.6349 - val_acc: 0.7377\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4062 - acc: 0.8090 - val_loss: 0.5487 - val_acc: 0.7560\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4244 - acc: 0.8068 - val_loss: 0.5541 - val_acc: 0.7584\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4062 - acc: 0.8104 - val_loss: 0.5469 - val_acc: 0.7659\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3624 - acc: 0.8329 - val_loss: 0.6630 - val_acc: 0.7584\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3701 - acc: 0.8502 - val_loss: 0.5054 - val_acc: 0.8402\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3171 - acc: 0.8972 - val_loss: 0.5293 - val_acc: 0.8358\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2663 - acc: 0.9131 - val_loss: 0.6136 - val_acc: 0.8409\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2670 - acc: 0.9127 - val_loss: 0.5375 - val_acc: 0.8670\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.2363 - acc: 0.9204 - val_loss: 0.6031 - val_acc: 0.7866\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2249 - acc: 0.9237 - val_loss: 0.4842 - val_acc: 0.8704\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2124 - acc: 0.9296 - val_loss: 0.6235 - val_acc: 0.8229\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1981 - acc: 0.9376 - val_loss: 0.7445 - val_acc: 0.8035\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1823 - acc: 0.9365 - val_loss: 0.6090 - val_acc: 0.8426\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2709 - acc: 0.9153 - val_loss: 0.5983 - val_acc: 0.8602\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2052 - acc: 0.9286 - val_loss: 0.5249 - val_acc: 0.8717\n",
      "2451/2451 [==============================] - 1s 345us/step\n",
      "4901/4901 [==============================] - 2s 344us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.5444 - acc: 0.3528 - val_loss: 1.4440 - val_acc: 0.3448\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3287 - acc: 0.3940 - val_loss: 1.3270 - val_acc: 0.4041\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2447 - acc: 0.4538 - val_loss: 1.3669 - val_acc: 0.3950\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2085 - acc: 0.4452 - val_loss: 1.2608 - val_acc: 0.4211\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.1490 - acc: 0.4660 - val_loss: 1.2492 - val_acc: 0.4242\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1272 - acc: 0.4707 - val_loss: 1.2833 - val_acc: 0.3990\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1434 - acc: 0.4624 - val_loss: 1.2362 - val_acc: 0.4181\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0868 - acc: 0.4695 - val_loss: 1.1544 - val_acc: 0.4181\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0669 - acc: 0.4956 - val_loss: 1.1675 - val_acc: 0.4533\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9966 - acc: 0.5460 - val_loss: 1.1465 - val_acc: 0.5185\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9512 - acc: 0.5805 - val_loss: 1.1715 - val_acc: 0.5012\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9555 - acc: 0.5782 - val_loss: 1.2114 - val_acc: 0.4839\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0092 - acc: 0.5248 - val_loss: 1.0092 - val_acc: 0.5497\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8220 - acc: 0.6240 - val_loss: 0.9849 - val_acc: 0.5541\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7420 - acc: 0.6470 - val_loss: 0.9091 - val_acc: 0.5558\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6974 - acc: 0.6511 - val_loss: 0.8754 - val_acc: 0.5898\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6876 - acc: 0.6652 - val_loss: 0.8945 - val_acc: 0.6597\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6472 - acc: 0.7054 - val_loss: 1.1001 - val_acc: 0.5853\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6133 - acc: 0.7417 - val_loss: 1.5052 - val_acc: 0.4825\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8817 - acc: 0.6127 - val_loss: 0.9765 - val_acc: 0.5796\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5994 - acc: 0.7468 - val_loss: 0.7215 - val_acc: 0.7309\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5630 - acc: 0.7890 - val_loss: 0.7011 - val_acc: 0.7486\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5546 - acc: 0.7837 - val_loss: 1.2285 - val_acc: 0.5307\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2154 - acc: 0.5119 - val_loss: 1.6557 - val_acc: 0.4214\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8415 - acc: 0.6623 - val_loss: 0.7906 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6662 - acc: 0.7423 - val_loss: 0.7831 - val_acc: 0.7119\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5944 - acc: 0.7792 - val_loss: 0.9310 - val_acc: 0.6227\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5573 - acc: 0.7996 - val_loss: 0.5757 - val_acc: 0.7855\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4867 - acc: 0.8213 - val_loss: 0.6281 - val_acc: 0.7747\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4837 - acc: 0.8364 - val_loss: 0.5807 - val_acc: 0.8066\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4159 - acc: 0.8578 - val_loss: 0.6671 - val_acc: 0.7523\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3957 - acc: 0.8668 - val_loss: 0.5827 - val_acc: 0.8185\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5008 - acc: 0.8086 - val_loss: 0.5821 - val_acc: 0.8076\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3491 - acc: 0.8843 - val_loss: 0.6838 - val_acc: 0.8015\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3212 - acc: 0.9006 - val_loss: 0.5214 - val_acc: 0.8385\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2633 - acc: 0.9141 - val_loss: 0.4791 - val_acc: 0.8639\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2870 - acc: 0.9119 - val_loss: 0.4908 - val_acc: 0.8554\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2763 - acc: 0.9186 - val_loss: 0.4963 - val_acc: 0.8609\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.3007 - acc: 0.9065 - val_loss: 0.6042 - val_acc: 0.8263\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2351 - acc: 0.9272 - val_loss: 1.1064 - val_acc: 0.7184\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2948 - acc: 0.9133 - val_loss: 0.5336 - val_acc: 0.8690\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2602 - acc: 0.9198 - val_loss: 0.5906 - val_acc: 0.8283\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2409 - acc: 0.9241 - val_loss: 0.3994 - val_acc: 0.8853\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1879 - acc: 0.9392 - val_loss: 1.1642 - val_acc: 0.7363\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1956 - acc: 0.9390 - val_loss: 0.4636 - val_acc: 0.8707\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1691 - acc: 0.9423 - val_loss: 0.4969 - val_acc: 0.8711\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1548 - acc: 0.9451 - val_loss: 0.4400 - val_acc: 0.8792\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1509 - acc: 0.9486 - val_loss: 0.5808 - val_acc: 0.8554\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1767 - acc: 0.9427 - val_loss: 0.4862 - val_acc: 0.8789\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1574 - acc: 0.9427 - val_loss: 0.4456 - val_acc: 0.8921\n",
      "2451/2451 [==============================] - 1s 341us/step\n",
      "4901/4901 [==============================] - 2s 327us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 1.5305 - acc: 0.3798 - val_loss: 1.4200 - val_acc: 0.3536\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.3482 - acc: 0.3780 - val_loss: 1.3876 - val_acc: 0.3495\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2756 - acc: 0.3864 - val_loss: 1.2553 - val_acc: 0.4160\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2345 - acc: 0.4553 - val_loss: 1.2587 - val_acc: 0.4869\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1401 - acc: 0.5161 - val_loss: 1.2581 - val_acc: 0.4924\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.0570 - acc: 0.5355 - val_loss: 1.2091 - val_acc: 0.4466\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.0959 - acc: 0.5104 - val_loss: 1.1317 - val_acc: 0.5433\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9733 - acc: 0.5518 - val_loss: 1.3000 - val_acc: 0.3790\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9898 - acc: 0.5516 - val_loss: 1.5014 - val_acc: 0.4584\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9527 - acc: 0.5806 - val_loss: 0.9482 - val_acc: 0.5266\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8510 - acc: 0.6132 - val_loss: 0.8969 - val_acc: 0.5460\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7987 - acc: 0.6330 - val_loss: 0.8434 - val_acc: 0.5860\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7448 - acc: 0.6342 - val_loss: 0.8116 - val_acc: 0.5674\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7168 - acc: 0.6524 - val_loss: 0.7510 - val_acc: 0.5945\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7325 - acc: 0.6387 - val_loss: 0.9287 - val_acc: 0.5792\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6909 - acc: 0.6571 - val_loss: 0.7545 - val_acc: 0.6176\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6626 - acc: 0.6887 - val_loss: 0.7911 - val_acc: 0.6423\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6128 - acc: 0.7193 - val_loss: 0.7489 - val_acc: 0.6902\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6449 - acc: 0.7077 - val_loss: 0.9036 - val_acc: 0.5830\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6216 - acc: 0.7256 - val_loss: 0.6995 - val_acc: 0.7146\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5833 - acc: 0.7411 - val_loss: 0.7200 - val_acc: 0.6949\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6282 - acc: 0.7373 - val_loss: 0.8427 - val_acc: 0.6437\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6160 - acc: 0.7368 - val_loss: 0.7985 - val_acc: 0.6546\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5818 - acc: 0.7411 - val_loss: 0.7187 - val_acc: 0.6861\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5447 - acc: 0.7511 - val_loss: 0.6283 - val_acc: 0.7089\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5297 - acc: 0.7693 - val_loss: 0.5700 - val_acc: 0.7550\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4853 - acc: 0.7862 - val_loss: 0.5673 - val_acc: 0.7492\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4731 - acc: 0.7887 - val_loss: 0.5353 - val_acc: 0.7540\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4523 - acc: 0.7913 - val_loss: 0.5786 - val_acc: 0.7710\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4372 - acc: 0.7980 - val_loss: 0.5552 - val_acc: 0.7716\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4158 - acc: 0.8119 - val_loss: 0.5445 - val_acc: 0.7805\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4123 - acc: 0.8125 - val_loss: 0.5085 - val_acc: 0.7859\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4179 - acc: 0.8219 - val_loss: 0.5731 - val_acc: 0.7530\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4274 - acc: 0.8205 - val_loss: 0.4974 - val_acc: 0.8022\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3934 - acc: 0.8523 - val_loss: 0.5123 - val_acc: 0.8232\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3816 - acc: 0.8586 - val_loss: 0.4688 - val_acc: 0.8358\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3474 - acc: 0.8741 - val_loss: 0.6269 - val_acc: 0.7950\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3288 - acc: 0.8882 - val_loss: 0.6980 - val_acc: 0.7957\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3183 - acc: 0.8925 - val_loss: 0.4158 - val_acc: 0.8578\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2613 - acc: 0.9060 - val_loss: 0.4424 - val_acc: 0.8602\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2440 - acc: 0.9157 - val_loss: 0.7127 - val_acc: 0.7967\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2258 - acc: 0.9200 - val_loss: 0.3597 - val_acc: 0.8884\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2082 - acc: 0.9292 - val_loss: 0.5635 - val_acc: 0.8290\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.2180 - acc: 0.9253 - val_loss: 0.3215 - val_acc: 0.8860\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1950 - acc: 0.9251 - val_loss: 0.4564 - val_acc: 0.8534\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1829 - acc: 0.9364 - val_loss: 0.4169 - val_acc: 0.8833\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1871 - acc: 0.9323 - val_loss: 0.4482 - val_acc: 0.8673\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1919 - acc: 0.9292 - val_loss: 0.3248 - val_acc: 0.9023\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1782 - acc: 0.9337 - val_loss: 0.4545 - val_acc: 0.8694\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1942 - acc: 0.9308 - val_loss: 0.4009 - val_acc: 0.8829\n",
      "2450/2450 [==============================] - 1s 330us/step\n",
      "4902/4902 [==============================] - 2s 336us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 22s 4ms/step - loss: 1.4264 - acc: 0.3932 - val_loss: 1.3449 - val_acc: 0.4089\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3290 - acc: 0.4146 - val_loss: 1.3455 - val_acc: 0.3536\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2818 - acc: 0.4148 - val_loss: 1.2528 - val_acc: 0.4330\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2154 - acc: 0.4597 - val_loss: 1.2608 - val_acc: 0.4550\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2650 - acc: 0.4162 - val_loss: 1.1749 - val_acc: 0.4533\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.2271 - acc: 0.4450 - val_loss: 1.3667 - val_acc: 0.3716\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2687 - acc: 0.4387 - val_loss: 1.2911 - val_acc: 0.4479\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2130 - acc: 0.4679 - val_loss: 1.4305 - val_acc: 0.3841\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0841 - acc: 0.4868 - val_loss: 1.1397 - val_acc: 0.4466\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0643 - acc: 0.5017 - val_loss: 1.3129 - val_acc: 0.3960\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8903 - acc: 0.5948 - val_loss: 0.8550 - val_acc: 0.5843\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.9853 - acc: 0.5670 - val_loss: 1.5479 - val_acc: 0.4038\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7302 - acc: 0.6507 - val_loss: 0.7615 - val_acc: 0.6054\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7820 - acc: 0.6270 - val_loss: 0.8722 - val_acc: 0.5884\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8409 - acc: 0.6142 - val_loss: 1.1376 - val_acc: 0.5053\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.9253 - acc: 0.5948 - val_loss: 1.1890 - val_acc: 0.5361\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.7270 - acc: 0.6533 - val_loss: 1.0123 - val_acc: 0.5962\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.9472 - acc: 0.5640 - val_loss: 0.8962 - val_acc: 0.6084\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8554 - acc: 0.6089 - val_loss: 1.0983 - val_acc: 0.5134\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.6987 - acc: 0.6574 - val_loss: 0.7428 - val_acc: 0.6264\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6700 - acc: 0.6670 - val_loss: 0.7472 - val_acc: 0.6651\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6998 - acc: 0.6827 - val_loss: 0.8692 - val_acc: 0.6451\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.7792 - acc: 0.6744 - val_loss: 1.0296 - val_acc: 0.5667\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8027 - acc: 0.6813 - val_loss: 0.9289 - val_acc: 0.6206\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6447 - acc: 0.7301 - val_loss: 0.7805 - val_acc: 0.6556\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5484 - acc: 0.7747 - val_loss: 0.5666 - val_acc: 0.7805\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5169 - acc: 0.7986 - val_loss: 0.5602 - val_acc: 0.7740\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4226 - acc: 0.8353 - val_loss: 0.8957 - val_acc: 0.6749\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4026 - acc: 0.8557 - val_loss: 0.5695 - val_acc: 0.7940\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3257 - acc: 0.8841 - val_loss: 0.4555 - val_acc: 0.8429\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3256 - acc: 0.8931 - val_loss: 0.4188 - val_acc: 0.8531\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2345 - acc: 0.9131 - val_loss: 0.4147 - val_acc: 0.8636\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2349 - acc: 0.9065 - val_loss: 0.3119 - val_acc: 0.8873\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2079 - acc: 0.9163 - val_loss: 0.3977 - val_acc: 0.8504\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2004 - acc: 0.9208 - val_loss: 0.4157 - val_acc: 0.8527\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1942 - acc: 0.9233 - val_loss: 0.3013 - val_acc: 0.8955\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1832 - acc: 0.9284 - val_loss: 0.3010 - val_acc: 0.8877\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1720 - acc: 0.9341 - val_loss: 0.2962 - val_acc: 0.9016\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1910 - acc: 0.9282 - val_loss: 0.3208 - val_acc: 0.8860\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1673 - acc: 0.9325 - val_loss: 0.3079 - val_acc: 0.8982\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1490 - acc: 0.9443 - val_loss: 0.5338 - val_acc: 0.8680\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1540 - acc: 0.9439 - val_loss: 0.5952 - val_acc: 0.7971\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1546 - acc: 0.9429 - val_loss: 0.3997 - val_acc: 0.8823\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1699 - acc: 0.9327 - val_loss: 0.3879 - val_acc: 0.8873\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1933 - acc: 0.9374 - val_loss: 0.4103 - val_acc: 0.8795\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1968 - acc: 0.9327 - val_loss: 0.3474 - val_acc: 0.8928\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1533 - acc: 0.9421 - val_loss: 0.4160 - val_acc: 0.8789\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1504 - acc: 0.9445 - val_loss: 0.3777 - val_acc: 0.8914\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1301 - acc: 0.9508 - val_loss: 0.3580 - val_acc: 0.8629\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1259 - acc: 0.9523 - val_loss: 0.3617 - val_acc: 0.9033\n",
      "2451/2451 [==============================] - 2s 876us/step\n",
      "4901/4901 [==============================] - 4s 856us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 22s 5ms/step - loss: 1.3894 - acc: 0.3579 - val_loss: 1.4176 - val_acc: 0.3427\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3564 - acc: 0.3865 - val_loss: 1.3330 - val_acc: 0.4048\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2738 - acc: 0.4107 - val_loss: 1.3885 - val_acc: 0.3997\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2508 - acc: 0.4356 - val_loss: 1.2786 - val_acc: 0.4394\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1894 - acc: 0.4595 - val_loss: 1.2621 - val_acc: 0.4194\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1709 - acc: 0.4817 - val_loss: 1.2433 - val_acc: 0.5015\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1240 - acc: 0.5142 - val_loss: 1.1714 - val_acc: 0.4720\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0157 - acc: 0.5785 - val_loss: 1.1108 - val_acc: 0.5704\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8721 - acc: 0.6478 - val_loss: 1.1566 - val_acc: 0.5796\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8520 - acc: 0.6656 - val_loss: 0.9953 - val_acc: 0.6091\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8340 - acc: 0.6762 - val_loss: 0.8713 - val_acc: 0.6400\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6678 - acc: 0.7427 - val_loss: 0.9220 - val_acc: 0.6773\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5509 - acc: 0.7892 - val_loss: 0.8859 - val_acc: 0.7282\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5314 - acc: 0.8102 - val_loss: 0.8206 - val_acc: 0.7706\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4241 - acc: 0.8553 - val_loss: 0.5807 - val_acc: 0.8297\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3412 - acc: 0.8980 - val_loss: 0.8496 - val_acc: 0.7815\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3703 - acc: 0.8931 - val_loss: 0.8087 - val_acc: 0.7737\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3548 - acc: 0.8941 - val_loss: 0.9887 - val_acc: 0.7075\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2535 - acc: 0.9239 - val_loss: 0.4859 - val_acc: 0.8561\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2273 - acc: 0.9212 - val_loss: 0.6027 - val_acc: 0.8405\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2059 - acc: 0.9359 - val_loss: 0.4943 - val_acc: 0.8565\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2201 - acc: 0.9225 - val_loss: 0.5674 - val_acc: 0.8398\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1837 - acc: 0.9394 - val_loss: 0.5766 - val_acc: 0.8507\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1826 - acc: 0.9384 - val_loss: 0.4144 - val_acc: 0.8673\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1717 - acc: 0.9404 - val_loss: 0.5203 - val_acc: 0.8565\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1574 - acc: 0.9461 - val_loss: 0.5974 - val_acc: 0.8761\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2365 - acc: 0.9198 - val_loss: 0.5413 - val_acc: 0.8493\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1614 - acc: 0.9378 - val_loss: 0.4764 - val_acc: 0.8690\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1659 - acc: 0.9435 - val_loss: 0.4575 - val_acc: 0.8782\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1436 - acc: 0.9447 - val_loss: 0.5063 - val_acc: 0.8765\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1391 - acc: 0.9506 - val_loss: 0.6307 - val_acc: 0.8510\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1217 - acc: 0.9578 - val_loss: 0.4486 - val_acc: 0.8856\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1715 - acc: 0.9337 - val_loss: 0.5786 - val_acc: 0.8744\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1338 - acc: 0.9463 - val_loss: 0.6129 - val_acc: 0.8432\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1340 - acc: 0.9496 - val_loss: 0.4742 - val_acc: 0.8870\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1257 - acc: 0.9516 - val_loss: 0.7272 - val_acc: 0.8476\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1268 - acc: 0.9547 - val_loss: 0.4509 - val_acc: 0.8873\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1148 - acc: 0.9541 - val_loss: 0.5687 - val_acc: 0.8690\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1331 - acc: 0.9496 - val_loss: 0.4636 - val_acc: 0.8775\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1261 - acc: 0.9521 - val_loss: 0.6063 - val_acc: 0.8751\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1209 - acc: 0.9537 - val_loss: 0.4139 - val_acc: 0.8856\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1111 - acc: 0.9580 - val_loss: 0.5568 - val_acc: 0.8829\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1306 - acc: 0.9539 - val_loss: 0.3627 - val_acc: 0.8890\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1114 - acc: 0.9576 - val_loss: 0.7187 - val_acc: 0.8497\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1259 - acc: 0.9553 - val_loss: 0.6347 - val_acc: 0.8660\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1099 - acc: 0.9531 - val_loss: 0.5465 - val_acc: 0.8911\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1135 - acc: 0.9551 - val_loss: 0.4194 - val_acc: 0.8918\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1073 - acc: 0.9553 - val_loss: 0.3544 - val_acc: 0.8839\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1060 - acc: 0.9559 - val_loss: 0.4733 - val_acc: 0.8907\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1237 - acc: 0.9539 - val_loss: 0.6011 - val_acc: 0.8802\n",
      "2451/2451 [==============================] - 2s 902us/step\n",
      "4901/4901 [==============================] - 4s 859us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 22s 5ms/step - loss: 1.3966 - acc: 0.3721 - val_loss: 1.5626 - val_acc: 0.3370\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.4195 - acc: 0.3556 - val_loss: 1.4215 - val_acc: 0.3634\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2590 - acc: 0.4288 - val_loss: 1.3251 - val_acc: 0.4113\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2256 - acc: 0.4398 - val_loss: 1.4644 - val_acc: 0.3936\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1756 - acc: 0.4623 - val_loss: 1.2371 - val_acc: 0.4357\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1590 - acc: 0.4694 - val_loss: 1.2831 - val_acc: 0.4486\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1456 - acc: 0.4967 - val_loss: 1.2078 - val_acc: 0.5049\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0047 - acc: 0.5363 - val_loss: 1.1123 - val_acc: 0.5107\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0882 - acc: 0.4965 - val_loss: 1.1707 - val_acc: 0.4778\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0514 - acc: 0.5000 - val_loss: 1.1374 - val_acc: 0.4951\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.9682 - acc: 0.5530 - val_loss: 0.9913 - val_acc: 0.5562\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.8512 - acc: 0.6244 - val_loss: 0.9469 - val_acc: 0.5745\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7868 - acc: 0.6595 - val_loss: 1.0244 - val_acc: 0.5931\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.9640 - acc: 0.5926 - val_loss: 1.1803 - val_acc: 0.5063\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.8217 - acc: 0.6532 - val_loss: 1.0730 - val_acc: 0.5629\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.6495 - acc: 0.7215 - val_loss: 0.9057 - val_acc: 0.6220\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5681 - acc: 0.7548 - val_loss: 0.7203 - val_acc: 0.6790\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5811 - acc: 0.7572 - val_loss: 0.8771 - val_acc: 0.6264\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5206 - acc: 0.7768 - val_loss: 0.7421 - val_acc: 0.7513\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5591 - acc: 0.7791 - val_loss: 0.6191 - val_acc: 0.7686\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.4657 - acc: 0.8213 - val_loss: 0.6514 - val_acc: 0.7706\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 22s 4ms/step - loss: 0.3741 - acc: 0.8599 - val_loss: 0.6203 - val_acc: 0.8208\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3383 - acc: 0.8745 - val_loss: 0.4673 - val_acc: 0.8568\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2701 - acc: 0.9066 - val_loss: 0.4387 - val_acc: 0.8656\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2512 - acc: 0.9082 - val_loss: 0.4094 - val_acc: 0.8772\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2054 - acc: 0.9272 - val_loss: 0.5376 - val_acc: 0.8432\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 0.2123 - acc: 0.9229 - val_loss: 0.7791 - val_acc: 0.7967\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1978 - acc: 0.9227 - val_loss: 0.4286 - val_acc: 0.8728\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1821 - acc: 0.9302 - val_loss: 0.3762 - val_acc: 0.8948\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2058 - acc: 0.9247 - val_loss: 0.4145 - val_acc: 0.8894\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1670 - acc: 0.9341 - val_loss: 0.4315 - val_acc: 0.8890\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1749 - acc: 0.9331 - val_loss: 0.3080 - val_acc: 0.9053\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1474 - acc: 0.9435 - val_loss: 0.3597 - val_acc: 0.8826\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1367 - acc: 0.9419 - val_loss: 0.3928 - val_acc: 0.8999\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1368 - acc: 0.9449 - val_loss: 0.4215 - val_acc: 0.8938\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1418 - acc: 0.9441 - val_loss: 0.4105 - val_acc: 0.8975\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 22s 4ms/step - loss: 0.1508 - acc: 0.9372 - val_loss: 0.4187 - val_acc: 0.8839\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1312 - acc: 0.9461 - val_loss: 0.5037 - val_acc: 0.8992\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1177 - acc: 0.9508 - val_loss: 0.4293 - val_acc: 0.9009\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1488 - acc: 0.9466 - val_loss: 0.5290 - val_acc: 0.8493\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1479 - acc: 0.9408 - val_loss: 0.3940 - val_acc: 0.8931\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1441 - acc: 0.9392 - val_loss: 0.3698 - val_acc: 0.9036\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1337 - acc: 0.9496 - val_loss: 0.3681 - val_acc: 0.9104\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1305 - acc: 0.9482 - val_loss: 0.4239 - val_acc: 0.8996\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1294 - acc: 0.9525 - val_loss: 0.4681 - val_acc: 0.8911\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1228 - acc: 0.9451 - val_loss: 0.3929 - val_acc: 0.9077\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1210 - acc: 0.9486 - val_loss: 0.9354 - val_acc: 0.8161\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1138 - acc: 0.9539 - val_loss: 0.4793 - val_acc: 0.8887\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1000 - acc: 0.9570 - val_loss: 0.4135 - val_acc: 0.9019\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1020 - acc: 0.9545 - val_loss: 0.4142 - val_acc: 0.9108\n",
      "2450/2450 [==============================] - 2s 872us/step\n",
      "4902/4902 [==============================] - 4s 871us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 11s 2ms/step - loss: 1.5197 - acc: 0.3779 - val_loss: 1.4066 - val_acc: 0.3536\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.3071 - acc: 0.4009 - val_loss: 1.3143 - val_acc: 0.4197\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.2207 - acc: 0.4695 - val_loss: 1.2715 - val_acc: 0.4778\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1723 - acc: 0.4546 - val_loss: 1.2349 - val_acc: 0.4727\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.4199 - acc: 0.4670 - val_loss: 1.6956 - val_acc: 0.3156\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3329 - acc: 0.4362 - val_loss: 1.1625 - val_acc: 0.5110\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1948 - acc: 0.4721 - val_loss: 1.0725 - val_acc: 0.5657\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0376 - acc: 0.5644 - val_loss: 0.9633 - val_acc: 0.5792\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9358 - acc: 0.6021 - val_loss: 0.9192 - val_acc: 0.6043\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8528 - acc: 0.6319 - val_loss: 0.8616 - val_acc: 0.5691\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8259 - acc: 0.6242 - val_loss: 0.8260 - val_acc: 0.6240\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8208 - acc: 0.6307 - val_loss: 0.8203 - val_acc: 0.6054\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7525 - acc: 0.6423 - val_loss: 0.8746 - val_acc: 0.5843\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7507 - acc: 0.6352 - val_loss: 0.8522 - val_acc: 0.5938\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7571 - acc: 0.6391 - val_loss: 0.7921 - val_acc: 0.6512\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7257 - acc: 0.6419 - val_loss: 0.7454 - val_acc: 0.6525\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7326 - acc: 0.6482 - val_loss: 0.9552 - val_acc: 0.5579\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.7356 - acc: 0.6474 - val_loss: 0.8756 - val_acc: 0.5969\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6973 - acc: 0.6546 - val_loss: 0.8579 - val_acc: 0.5833\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6940 - acc: 0.6701 - val_loss: 1.0317 - val_acc: 0.5589\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7690 - acc: 0.6329 - val_loss: 0.7363 - val_acc: 0.6284\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6646 - acc: 0.6766 - val_loss: 0.7060 - val_acc: 0.6322\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6423 - acc: 0.6868 - val_loss: 0.8064 - val_acc: 0.6647\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6209 - acc: 0.7139 - val_loss: 0.8239 - val_acc: 0.6634\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6278 - acc: 0.7215 - val_loss: 0.7372 - val_acc: 0.7038\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6187 - acc: 0.7429 - val_loss: 0.7851 - val_acc: 0.7258\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6170 - acc: 0.7231 - val_loss: 0.8062 - val_acc: 0.6172\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5938 - acc: 0.7374 - val_loss: 0.8518 - val_acc: 0.7085\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6998 - acc: 0.6872 - val_loss: 0.8233 - val_acc: 0.6440\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5909 - acc: 0.7360 - val_loss: 0.6288 - val_acc: 0.7350\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6052 - acc: 0.7354 - val_loss: 0.7324 - val_acc: 0.6658\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5571 - acc: 0.7582 - val_loss: 0.8172 - val_acc: 0.6630\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5255 - acc: 0.7800 - val_loss: 0.7013 - val_acc: 0.7374\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5279 - acc: 0.7829 - val_loss: 0.7230 - val_acc: 0.7282\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5156 - acc: 0.7935 - val_loss: 0.7330 - val_acc: 0.7163\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5816 - acc: 0.7690 - val_loss: 0.7874 - val_acc: 0.7370\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5151 - acc: 0.7986 - val_loss: 0.8674 - val_acc: 0.6675\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.4823 - acc: 0.8166 - val_loss: 0.7416 - val_acc: 0.7428\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4403 - acc: 0.8335 - val_loss: 0.6226 - val_acc: 0.7801\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4306 - acc: 0.8376 - val_loss: 0.5970 - val_acc: 0.8062\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3799 - acc: 0.8590 - val_loss: 0.5974 - val_acc: 0.8073\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3908 - acc: 0.8523 - val_loss: 0.5799 - val_acc: 0.8117\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3416 - acc: 0.8819 - val_loss: 0.6408 - val_acc: 0.8005\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3280 - acc: 0.8923 - val_loss: 0.6471 - val_acc: 0.8154\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3014 - acc: 0.9035 - val_loss: 0.5788 - val_acc: 0.8337\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3956 - acc: 0.8949 - val_loss: 0.6250 - val_acc: 0.8375\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2890 - acc: 0.9043 - val_loss: 0.5509 - val_acc: 0.8439\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2701 - acc: 0.9110 - val_loss: 0.5155 - val_acc: 0.8548\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2296 - acc: 0.9239 - val_loss: 0.5419 - val_acc: 0.8480\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2511 - acc: 0.9208 - val_loss: 0.8123 - val_acc: 0.7862\n",
      "2451/2451 [==============================] - 1s 349us/step\n",
      "4901/4901 [==============================] - 2s 360us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 11s 2ms/step - loss: 1.5455 - acc: 0.3434 - val_loss: 1.4547 - val_acc: 0.3420\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3385 - acc: 0.3889 - val_loss: 1.4257 - val_acc: 0.4259\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2730 - acc: 0.4519 - val_loss: 1.2977 - val_acc: 0.4157\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1903 - acc: 0.4624 - val_loss: 1.3517 - val_acc: 0.3943\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1591 - acc: 0.4685 - val_loss: 1.2066 - val_acc: 0.4357\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1174 - acc: 0.4795 - val_loss: 1.2533 - val_acc: 0.4469\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1277 - acc: 0.5048 - val_loss: 1.2857 - val_acc: 0.4228\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0377 - acc: 0.5407 - val_loss: 1.2349 - val_acc: 0.4900\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0949 - acc: 0.5576 - val_loss: 1.1855 - val_acc: 0.5643\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3506 - acc: 0.4693 - val_loss: 1.1890 - val_acc: 0.4863\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0755 - acc: 0.5352 - val_loss: 1.4043 - val_acc: 0.4615\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0098 - acc: 0.5995 - val_loss: 1.1510 - val_acc: 0.5446\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9158 - acc: 0.6297 - val_loss: 1.2724 - val_acc: 0.5348\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8904 - acc: 0.6466 - val_loss: 1.1356 - val_acc: 0.5226\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8080 - acc: 0.6827 - val_loss: 0.9629 - val_acc: 0.6410\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7612 - acc: 0.6954 - val_loss: 1.1801 - val_acc: 0.5266\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6734 - acc: 0.7421 - val_loss: 0.8088 - val_acc: 0.7255\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6627 - acc: 0.7498 - val_loss: 0.8137 - val_acc: 0.7455\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5955 - acc: 0.7794 - val_loss: 0.7755 - val_acc: 0.7340\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6134 - acc: 0.7811 - val_loss: 0.8344 - val_acc: 0.7238\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5635 - acc: 0.8027 - val_loss: 0.8280 - val_acc: 0.6939\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5229 - acc: 0.8206 - val_loss: 0.6664 - val_acc: 0.7567\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4825 - acc: 0.8362 - val_loss: 0.7301 - val_acc: 0.7615\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4445 - acc: 0.8549 - val_loss: 1.4433 - val_acc: 0.6485\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4621 - acc: 0.8559 - val_loss: 0.7432 - val_acc: 0.7367\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4975 - acc: 0.8396 - val_loss: 0.7054 - val_acc: 0.7550\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4652 - acc: 0.8525 - val_loss: 0.6674 - val_acc: 0.7760\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3973 - acc: 0.8774 - val_loss: 0.5922 - val_acc: 0.8219\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3552 - acc: 0.8888 - val_loss: 0.6367 - val_acc: 0.8303\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3411 - acc: 0.8908 - val_loss: 0.6740 - val_acc: 0.8042\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3086 - acc: 0.9072 - val_loss: 0.6471 - val_acc: 0.8252\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2880 - acc: 0.9157 - val_loss: 0.5316 - val_acc: 0.8595\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.2539 - acc: 0.9214 - val_loss: 0.5897 - val_acc: 0.8470\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.2230 - acc: 0.9310 - val_loss: 0.5234 - val_acc: 0.8575\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2121 - acc: 0.9292 - val_loss: 0.5813 - val_acc: 0.8371\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2100 - acc: 0.9327 - val_loss: 0.5358 - val_acc: 0.8527\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2167 - acc: 0.9308 - val_loss: 0.4448 - val_acc: 0.8731\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1911 - acc: 0.9365 - val_loss: 0.5823 - val_acc: 0.8571\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1887 - acc: 0.9398 - val_loss: 0.5226 - val_acc: 0.8622\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1852 - acc: 0.9414 - val_loss: 0.5362 - val_acc: 0.8554\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1789 - acc: 0.9386 - val_loss: 0.4533 - val_acc: 0.8758\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1667 - acc: 0.9467 - val_loss: 0.6056 - val_acc: 0.8711\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.2025 - acc: 0.9378 - val_loss: 0.6868 - val_acc: 0.8388\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1696 - acc: 0.9429 - val_loss: 0.5075 - val_acc: 0.8683\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1837 - acc: 0.9480 - val_loss: 0.5289 - val_acc: 0.8772\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1730 - acc: 0.9437 - val_loss: 0.5064 - val_acc: 0.8846\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1660 - acc: 0.9457 - val_loss: 0.6189 - val_acc: 0.8565\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1558 - acc: 0.9486 - val_loss: 0.5754 - val_acc: 0.8666\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1436 - acc: 0.9463 - val_loss: 0.7412 - val_acc: 0.8144\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.1520 - acc: 0.9433 - val_loss: 0.6678 - val_acc: 0.8666\n",
      "2451/2451 [==============================] - 1s 349us/step\n",
      "4901/4901 [==============================] - 2s 342us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 11s 2ms/step - loss: 1.5265 - acc: 0.3678 - val_loss: 1.4285 - val_acc: 0.3482\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 1.3564 - acc: 0.3760 - val_loss: 1.4217 - val_acc: 0.3482\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.3287 - acc: 0.3790 - val_loss: 1.3678 - val_acc: 0.3498\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2148 - acc: 0.4549 - val_loss: 1.2748 - val_acc: 0.4388\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1615 - acc: 0.4698 - val_loss: 1.2189 - val_acc: 0.4418\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1402 - acc: 0.4800 - val_loss: 1.2585 - val_acc: 0.4309\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1635 - acc: 0.4702 - val_loss: 1.3308 - val_acc: 0.4343\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1002 - acc: 0.4874 - val_loss: 1.2001 - val_acc: 0.4052\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.0572 - acc: 0.4961 - val_loss: 1.2671 - val_acc: 0.4530\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9929 - acc: 0.5575 - val_loss: 1.0948 - val_acc: 0.5327\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9684 - acc: 0.5716 - val_loss: 1.1658 - val_acc: 0.5741\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9543 - acc: 0.5824 - val_loss: 1.0161 - val_acc: 0.5728\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8973 - acc: 0.6100 - val_loss: 0.9932 - val_acc: 0.5901\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9028 - acc: 0.5787 - val_loss: 1.0670 - val_acc: 0.5188\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.9518 - acc: 0.5847 - val_loss: 1.0631 - val_acc: 0.5921\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8275 - acc: 0.6228 - val_loss: 0.9617 - val_acc: 0.6172\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7636 - acc: 0.6373 - val_loss: 1.1944 - val_acc: 0.5497\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7592 - acc: 0.6304 - val_loss: 1.2479 - val_acc: 0.5847\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7231 - acc: 0.6510 - val_loss: 0.9741 - val_acc: 0.5864\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7503 - acc: 0.6406 - val_loss: 0.9284 - val_acc: 0.5986\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7160 - acc: 0.6559 - val_loss: 0.9168 - val_acc: 0.5945\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7077 - acc: 0.6524 - val_loss: 0.8768 - val_acc: 0.6125\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7753 - acc: 0.6577 - val_loss: 0.9456 - val_acc: 0.6328\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7522 - acc: 0.6656 - val_loss: 1.2506 - val_acc: 0.4537\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7941 - acc: 0.6577 - val_loss: 0.9871 - val_acc: 0.5348\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8224 - acc: 0.6520 - val_loss: 0.8165 - val_acc: 0.6434\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6690 - acc: 0.7022 - val_loss: 0.8879 - val_acc: 0.6488\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6246 - acc: 0.7413 - val_loss: 0.8286 - val_acc: 0.6956\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5849 - acc: 0.7703 - val_loss: 0.7542 - val_acc: 0.7475\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5492 - acc: 0.7925 - val_loss: 0.8606 - val_acc: 0.7116\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5363 - acc: 0.8066 - val_loss: 0.6540 - val_acc: 0.7757\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4783 - acc: 0.8348 - val_loss: 0.7608 - val_acc: 0.7536\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4620 - acc: 0.8335 - val_loss: 0.6840 - val_acc: 0.7604\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4160 - acc: 0.8501 - val_loss: 0.6293 - val_acc: 0.7954\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.3935 - acc: 0.8682 - val_loss: 1.3712 - val_acc: 0.6193\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.3934 - acc: 0.8562 - val_loss: 0.9319 - val_acc: 0.7177\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3746 - acc: 0.8643 - val_loss: 0.5505 - val_acc: 0.8215\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4151 - acc: 0.8486 - val_loss: 0.5514 - val_acc: 0.8232\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4363 - acc: 0.8774 - val_loss: 0.5571 - val_acc: 0.8164\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.3011 - acc: 0.8982 - val_loss: 0.4922 - val_acc: 0.8558\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2812 - acc: 0.9145 - val_loss: 0.4968 - val_acc: 0.8544\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2634 - acc: 0.9182 - val_loss: 0.4828 - val_acc: 0.8792\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2229 - acc: 0.9249 - val_loss: 0.4262 - val_acc: 0.8802\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2189 - acc: 0.9184 - val_loss: 1.3393 - val_acc: 0.7051\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2416 - acc: 0.9135 - val_loss: 0.5364 - val_acc: 0.8714\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.2233 - acc: 0.9231 - val_loss: 0.5123 - val_acc: 0.8724\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1828 - acc: 0.9341 - val_loss: 0.5296 - val_acc: 0.8761\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1988 - acc: 0.9329 - val_loss: 0.4525 - val_acc: 0.8931\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.1771 - acc: 0.9323 - val_loss: 0.6282 - val_acc: 0.8707\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.1589 - acc: 0.9384 - val_loss: 0.9303 - val_acc: 0.7852\n",
      "2450/2450 [==============================] - 1s 341us/step\n",
      "4902/4902 [==============================] - 2s 343us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 22s 5ms/step - loss: 1.6053 - acc: 0.3175 - val_loss: 1.3800 - val_acc: 0.3536\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.2954 - acc: 0.3954 - val_loss: 1.3190 - val_acc: 0.3627\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.2616 - acc: 0.4383 - val_loss: 1.2374 - val_acc: 0.4720\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.0852 - acc: 0.5115 - val_loss: 1.0083 - val_acc: 0.5752\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.0882 - acc: 0.5001 - val_loss: 1.0438 - val_acc: 0.6094\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.0706 - acc: 0.5154 - val_loss: 2.5644 - val_acc: 0.3597\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 1.0278 - acc: 0.5627 - val_loss: 0.9878 - val_acc: 0.5528\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0459 - acc: 0.5291 - val_loss: 0.8882 - val_acc: 0.5928\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8662 - acc: 0.6099 - val_loss: 1.1001 - val_acc: 0.5294\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.9286 - acc: 0.5719 - val_loss: 1.2996 - val_acc: 0.4062\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.9640 - acc: 0.5776 - val_loss: 1.1323 - val_acc: 0.5694\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8608 - acc: 0.6148 - val_loss: 0.8602 - val_acc: 0.6590\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8984 - acc: 0.5807 - val_loss: 1.0619 - val_acc: 0.5680\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7720 - acc: 0.6462 - val_loss: 0.9141 - val_acc: 0.6586\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8003 - acc: 0.6593 - val_loss: 0.9157 - val_acc: 0.5986\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7906 - acc: 0.6352 - val_loss: 0.7470 - val_acc: 0.6390\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6767 - acc: 0.6962 - val_loss: 0.8262 - val_acc: 0.6705\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6683 - acc: 0.7292 - val_loss: 0.7974 - val_acc: 0.6149\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6339 - acc: 0.7229 - val_loss: 0.5546 - val_acc: 0.7594\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5750 - acc: 0.7662 - val_loss: 0.7695 - val_acc: 0.6118\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5464 - acc: 0.7672 - val_loss: 0.6540 - val_acc: 0.6902\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6082 - acc: 0.7531 - val_loss: 0.7889 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5422 - acc: 0.7770 - val_loss: 0.5743 - val_acc: 0.7340\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4928 - acc: 0.8115 - val_loss: 0.6041 - val_acc: 0.7492\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4542 - acc: 0.8396 - val_loss: 0.5105 - val_acc: 0.8140\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.4382 - acc: 0.8472 - val_loss: 0.5172 - val_acc: 0.8130\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3955 - acc: 0.8576 - val_loss: 0.7106 - val_acc: 0.7201\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3895 - acc: 0.8541 - val_loss: 0.4817 - val_acc: 0.8029\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3185 - acc: 0.8880 - val_loss: 0.5078 - val_acc: 0.8263\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.3139 - acc: 0.8927 - val_loss: 0.7195 - val_acc: 0.7710\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2794 - acc: 0.9045 - val_loss: 0.3997 - val_acc: 0.8663\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2578 - acc: 0.9104 - val_loss: 0.4685 - val_acc: 0.8317\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2606 - acc: 0.9078 - val_loss: 0.4923 - val_acc: 0.8188\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2366 - acc: 0.9137 - val_loss: 0.4161 - val_acc: 0.8734\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2175 - acc: 0.9168 - val_loss: 0.3582 - val_acc: 0.8839\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1795 - acc: 0.9316 - val_loss: 0.4075 - val_acc: 0.8826\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2079 - acc: 0.9174 - val_loss: 0.4269 - val_acc: 0.8595\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1737 - acc: 0.9270 - val_loss: 0.7835 - val_acc: 0.8066\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1843 - acc: 0.9353 - val_loss: 0.3081 - val_acc: 0.8941\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1846 - acc: 0.9227 - val_loss: 0.3539 - val_acc: 0.8839\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1815 - acc: 0.9321 - val_loss: 0.4058 - val_acc: 0.8772\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1740 - acc: 0.9355 - val_loss: 0.3369 - val_acc: 0.8897\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1537 - acc: 0.9414 - val_loss: 0.3861 - val_acc: 0.8860\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1434 - acc: 0.9367 - val_loss: 0.4496 - val_acc: 0.8863\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1731 - acc: 0.9418 - val_loss: 0.4375 - val_acc: 0.8894\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1837 - acc: 0.9321 - val_loss: 0.2997 - val_acc: 0.8918\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1881 - acc: 0.9257 - val_loss: 0.3812 - val_acc: 0.8839\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1621 - acc: 0.9351 - val_loss: 0.4233 - val_acc: 0.8850\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1715 - acc: 0.9314 - val_loss: 0.4343 - val_acc: 0.8836\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1587 - acc: 0.9416 - val_loss: 0.2908 - val_acc: 0.9033\n",
      "2451/2451 [==============================] - 2s 865us/step\n",
      "4901/4901 [==============================] - 4s 859us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 23s 5ms/step - loss: 1.4123 - acc: 0.3575 - val_loss: 1.4370 - val_acc: 0.3349\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2939 - acc: 0.4058 - val_loss: 1.2514 - val_acc: 0.4564\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2551 - acc: 0.4509 - val_loss: 1.5855 - val_acc: 0.3027\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3481 - acc: 0.4156 - val_loss: 1.4003 - val_acc: 0.3658\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3337 - acc: 0.3854 - val_loss: 1.2765 - val_acc: 0.4235\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3423 - acc: 0.3822 - val_loss: 1.3579 - val_acc: 0.3807\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1858 - acc: 0.4566 - val_loss: 1.2055 - val_acc: 0.4371\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1102 - acc: 0.5160 - val_loss: 1.1969 - val_acc: 0.4435\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1485 - acc: 0.5019 - val_loss: 1.1405 - val_acc: 0.5195\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0143 - acc: 0.5834 - val_loss: 1.0284 - val_acc: 0.5911\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8919 - acc: 0.6058 - val_loss: 1.1226 - val_acc: 0.5290\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7714 - acc: 0.6501 - val_loss: 0.9009 - val_acc: 0.6200\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8225 - acc: 0.6462 - val_loss: 0.8372 - val_acc: 0.6559\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.6722 - acc: 0.7054 - val_loss: 0.8083 - val_acc: 0.6875\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6446 - acc: 0.7245 - val_loss: 0.6922 - val_acc: 0.7268\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5860 - acc: 0.7480 - val_loss: 0.7555 - val_acc: 0.6946\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7109 - acc: 0.7072 - val_loss: 0.8672 - val_acc: 0.6169\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5421 - acc: 0.7935 - val_loss: 0.6330 - val_acc: 0.7940\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4998 - acc: 0.8219 - val_loss: 0.6511 - val_acc: 0.7645\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4016 - acc: 0.8608 - val_loss: 0.5201 - val_acc: 0.8347\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3560 - acc: 0.8757 - val_loss: 0.4644 - val_acc: 0.8215\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2856 - acc: 0.9084 - val_loss: 0.3559 - val_acc: 0.8799\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5123 - acc: 0.8217 - val_loss: 1.2326 - val_acc: 0.5334\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3192 - acc: 0.8833 - val_loss: 0.3800 - val_acc: 0.8911\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2941 - acc: 0.9004 - val_loss: 0.4509 - val_acc: 0.8534\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2178 - acc: 0.9267 - val_loss: 0.4885 - val_acc: 0.8568\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1957 - acc: 0.9321 - val_loss: 0.4399 - val_acc: 0.8782\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2098 - acc: 0.9245 - val_loss: 0.3679 - val_acc: 0.8755\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1855 - acc: 0.9372 - val_loss: 0.4464 - val_acc: 0.8728\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2362 - acc: 0.9331 - val_loss: 0.5141 - val_acc: 0.8683\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2192 - acc: 0.9333 - val_loss: 0.7666 - val_acc: 0.8134\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1796 - acc: 0.9388 - val_loss: 0.4179 - val_acc: 0.8907\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1440 - acc: 0.9496 - val_loss: 0.4067 - val_acc: 0.8945\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1432 - acc: 0.9455 - val_loss: 0.4460 - val_acc: 0.8894\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1449 - acc: 0.9512 - val_loss: 0.3886 - val_acc: 0.8928\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1389 - acc: 0.9523 - val_loss: 0.3287 - val_acc: 0.8914\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1273 - acc: 0.9533 - val_loss: 0.5206 - val_acc: 0.8873\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1588 - acc: 0.9492 - val_loss: 0.3931 - val_acc: 0.8965\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1306 - acc: 0.9504 - val_loss: 0.4672 - val_acc: 0.8941\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1298 - acc: 0.9531 - val_loss: 0.3967 - val_acc: 0.8951\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1250 - acc: 0.9523 - val_loss: 0.3269 - val_acc: 0.8985\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1275 - acc: 0.9521 - val_loss: 0.6637 - val_acc: 0.8826\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1922 - acc: 0.9447 - val_loss: 0.5081 - val_acc: 0.8941\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1318 - acc: 0.9541 - val_loss: 0.5001 - val_acc: 0.8792\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1163 - acc: 0.9551 - val_loss: 0.4090 - val_acc: 0.9036\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1134 - acc: 0.9555 - val_loss: 0.3706 - val_acc: 0.9043\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1418 - acc: 0.9529 - val_loss: 0.4940 - val_acc: 0.8700\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1400 - acc: 0.9514 - val_loss: 0.3933 - val_acc: 0.9053\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1155 - acc: 0.9559 - val_loss: 0.3054 - val_acc: 0.9125\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1181 - acc: 0.9547 - val_loss: 0.3766 - val_acc: 0.9053\n",
      "2451/2451 [==============================] - 2s 890us/step\n",
      "4901/4901 [==============================] - 4s 871us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 23s 5ms/step - loss: 1.4055 - acc: 0.3735 - val_loss: 1.4530 - val_acc: 0.3482\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2900 - acc: 0.3998 - val_loss: 2.8828 - val_acc: 0.3342\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2688 - acc: 0.4235 - val_loss: 1.3700 - val_acc: 0.3787\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2576 - acc: 0.4274 - val_loss: 1.5259 - val_acc: 0.3271\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1999 - acc: 0.4535 - val_loss: 1.2661 - val_acc: 0.4618\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2433 - acc: 0.4429 - val_loss: 1.3897 - val_acc: 0.4197\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1720 - acc: 0.4539 - val_loss: 1.2523 - val_acc: 0.4418\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1366 - acc: 0.4798 - val_loss: 1.2473 - val_acc: 0.4479\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1401 - acc: 0.4598 - val_loss: 1.2706 - val_acc: 0.4231\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1194 - acc: 0.4916 - val_loss: 1.2710 - val_acc: 0.4683\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1148 - acc: 0.5061 - val_loss: 1.3297 - val_acc: 0.5022\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.1265 - acc: 0.4988 - val_loss: 1.2004 - val_acc: 0.5355\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0526 - acc: 0.5235 - val_loss: 1.2045 - val_acc: 0.5154\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0037 - acc: 0.5312 - val_loss: 1.2623 - val_acc: 0.4510\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0115 - acc: 0.5655 - val_loss: 1.0668 - val_acc: 0.5283\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0228 - acc: 0.5636 - val_loss: 0.9596 - val_acc: 0.6420\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.8617 - acc: 0.6471 - val_loss: 1.0096 - val_acc: 0.5843\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7920 - acc: 0.6661 - val_loss: 0.8333 - val_acc: 0.6413\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7464 - acc: 0.6783 - val_loss: 1.0400 - val_acc: 0.6186\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.6361 - acc: 0.7226 - val_loss: 0.7723 - val_acc: 0.6895\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.6067 - acc: 0.7305 - val_loss: 0.8959 - val_acc: 0.6474\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5734 - acc: 0.7479 - val_loss: 0.6233 - val_acc: 0.7550\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.4802 - acc: 0.7956 - val_loss: 0.5602 - val_acc: 0.7944\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.4428 - acc: 0.8239 - val_loss: 0.5588 - val_acc: 0.7801\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3547 - acc: 0.8672 - val_loss: 0.5778 - val_acc: 0.8056\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3469 - acc: 0.8703 - val_loss: 0.5179 - val_acc: 0.8378\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2795 - acc: 0.8958 - val_loss: 0.4656 - val_acc: 0.8504\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2747 - acc: 0.8974 - val_loss: 0.5205 - val_acc: 0.8524\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2201 - acc: 0.9092 - val_loss: 0.4949 - val_acc: 0.8687\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2221 - acc: 0.9188 - val_loss: 0.4565 - val_acc: 0.8646\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2367 - acc: 0.9145 - val_loss: 0.5304 - val_acc: 0.8398\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1847 - acc: 0.9274 - val_loss: 0.5109 - val_acc: 0.8629\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2103 - acc: 0.9231 - val_loss: 0.5010 - val_acc: 0.8778\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1905 - acc: 0.9262 - val_loss: 0.4048 - val_acc: 0.8901\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1864 - acc: 0.9272 - val_loss: 0.3500 - val_acc: 0.8890\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1763 - acc: 0.9259 - val_loss: 0.3896 - val_acc: 0.8972\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1527 - acc: 0.9394 - val_loss: 0.4410 - val_acc: 0.8880\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1507 - acc: 0.9388 - val_loss: 0.4761 - val_acc: 0.8880\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1526 - acc: 0.9386 - val_loss: 0.6167 - val_acc: 0.8161\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1715 - acc: 0.9306 - val_loss: 1.0042 - val_acc: 0.8178\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1574 - acc: 0.9376 - val_loss: 0.4370 - val_acc: 0.8724\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1426 - acc: 0.9415 - val_loss: 0.3779 - val_acc: 0.8996\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1276 - acc: 0.9476 - val_loss: 0.5402 - val_acc: 0.8785\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1445 - acc: 0.9435 - val_loss: 0.4029 - val_acc: 0.8948\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1361 - acc: 0.9474 - val_loss: 0.3609 - val_acc: 0.8955\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1385 - acc: 0.9463 - val_loss: 0.4207 - val_acc: 0.8948\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1463 - acc: 0.9410 - val_loss: 0.4685 - val_acc: 0.8744\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1319 - acc: 0.9447 - val_loss: 0.3435 - val_acc: 0.9040\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1246 - acc: 0.9433 - val_loss: 0.4322 - val_acc: 0.9057\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1352 - acc: 0.9461 - val_loss: 0.4834 - val_acc: 0.8955\n",
      "2450/2450 [==============================] - 2s 856us/step\n",
      "4902/4902 [==============================] - 4s 859us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 12s 2ms/step - loss: 1.5595 - acc: 0.3691 - val_loss: 1.4048 - val_acc: 0.3560\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3316 - acc: 0.4071 - val_loss: 1.3055 - val_acc: 0.4404\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2569 - acc: 0.4575 - val_loss: 1.2749 - val_acc: 0.4466\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2329 - acc: 0.4742 - val_loss: 1.2286 - val_acc: 0.4255\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2785 - acc: 0.4556 - val_loss: 1.2383 - val_acc: 0.4428\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1590 - acc: 0.4977 - val_loss: 1.2307 - val_acc: 0.4204\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1593 - acc: 0.4748 - val_loss: 1.1902 - val_acc: 0.4421\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1412 - acc: 0.4917 - val_loss: 1.2433 - val_acc: 0.4459\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1208 - acc: 0.4962 - val_loss: 1.1309 - val_acc: 0.4574\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0819 - acc: 0.5056 - val_loss: 1.2293 - val_acc: 0.4466\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1035 - acc: 0.5034 - val_loss: 1.1481 - val_acc: 0.4547\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0717 - acc: 0.4919 - val_loss: 1.1077 - val_acc: 0.4537\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0594 - acc: 0.5032 - val_loss: 1.1244 - val_acc: 0.3858\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1581 - acc: 0.4819 - val_loss: 1.0971 - val_acc: 0.5314\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.0338 - acc: 0.5032 - val_loss: 0.9992 - val_acc: 0.5707\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9925 - acc: 0.5387 - val_loss: 1.0018 - val_acc: 0.5280\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9811 - acc: 0.5225 - val_loss: 1.0141 - val_acc: 0.5080\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1277 - acc: 0.4721 - val_loss: 1.1017 - val_acc: 0.5087\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2630 - acc: 0.4928 - val_loss: 1.0914 - val_acc: 0.5592\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8960 - acc: 0.5899 - val_loss: 1.0067 - val_acc: 0.5511\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8187 - acc: 0.6268 - val_loss: 0.9785 - val_acc: 0.6013\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.0372 - acc: 0.5752 - val_loss: 1.4642 - val_acc: 0.4540\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0243 - acc: 0.5391 - val_loss: 1.5188 - val_acc: 0.4964\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0404 - acc: 0.5387 - val_loss: 1.0158 - val_acc: 0.5531\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9013 - acc: 0.5748 - val_loss: 0.9261 - val_acc: 0.5894\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8214 - acc: 0.6148 - val_loss: 0.9383 - val_acc: 0.5731\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7826 - acc: 0.6311 - val_loss: 1.0975 - val_acc: 0.6047\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8903 - acc: 0.5989 - val_loss: 1.0605 - val_acc: 0.5718\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8171 - acc: 0.6144 - val_loss: 0.8722 - val_acc: 0.6037\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7556 - acc: 0.6407 - val_loss: 0.9257 - val_acc: 0.6206\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7656 - acc: 0.6431 - val_loss: 0.9656 - val_acc: 0.5826\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7542 - acc: 0.6350 - val_loss: 0.8979 - val_acc: 0.6196\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7075 - acc: 0.6560 - val_loss: 0.8968 - val_acc: 0.6203\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7013 - acc: 0.6717 - val_loss: 1.0924 - val_acc: 0.6417\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6820 - acc: 0.6844 - val_loss: 0.8423 - val_acc: 0.6736\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6669 - acc: 0.7080 - val_loss: 0.8269 - val_acc: 0.7173\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6371 - acc: 0.7299 - val_loss: 0.8528 - val_acc: 0.7523\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6327 - acc: 0.7260 - val_loss: 0.7813 - val_acc: 0.7380\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5946 - acc: 0.7517 - val_loss: 0.7763 - val_acc: 0.7431\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7026 - acc: 0.7186 - val_loss: 0.7585 - val_acc: 0.7520\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8124 - acc: 0.6992 - val_loss: 1.2479 - val_acc: 0.5765\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6997 - acc: 0.7143 - val_loss: 0.8315 - val_acc: 0.7150\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5702 - acc: 0.7823 - val_loss: 0.9053 - val_acc: 0.6810\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5812 - acc: 0.7882 - val_loss: 0.7991 - val_acc: 0.7289\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5384 - acc: 0.7943 - val_loss: 0.7972 - val_acc: 0.7323\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5668 - acc: 0.7962 - val_loss: 0.7284 - val_acc: 0.7862\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5037 - acc: 0.8170 - val_loss: 0.8163 - val_acc: 0.7733\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5291 - acc: 0.8166 - val_loss: 0.7290 - val_acc: 0.7927\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5467 - acc: 0.8209 - val_loss: 0.7134 - val_acc: 0.7940\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6091 - acc: 0.8188 - val_loss: 0.6821 - val_acc: 0.7974\n",
      "2451/2451 [==============================] - 1s 330us/step\n",
      "4901/4901 [==============================] - 2s 338us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 12s 2ms/step - loss: 1.5839 - acc: 0.3522 - val_loss: 1.4580 - val_acc: 0.3448\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3691 - acc: 0.3948 - val_loss: 1.3990 - val_acc: 0.4343\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.3176 - acc: 0.4095 - val_loss: 1.3297 - val_acc: 0.4116\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.2142 - acc: 0.4622 - val_loss: 1.3301 - val_acc: 0.4693\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 1.2226 - acc: 0.4503 - val_loss: 1.3509 - val_acc: 0.3974\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1966 - acc: 0.4619 - val_loss: 1.2196 - val_acc: 0.4140\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1159 - acc: 0.5048 - val_loss: 1.2452 - val_acc: 0.4330\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1128 - acc: 0.4785 - val_loss: 1.3011 - val_acc: 0.4272\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0917 - acc: 0.4875 - val_loss: 1.2174 - val_acc: 0.4428\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1312 - acc: 0.4838 - val_loss: 1.4058 - val_acc: 0.4401\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1056 - acc: 0.5013 - val_loss: 1.2169 - val_acc: 0.4469\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0653 - acc: 0.5081 - val_loss: 1.2092 - val_acc: 0.4259\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0647 - acc: 0.5021 - val_loss: 1.2489 - val_acc: 0.4476\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0533 - acc: 0.5136 - val_loss: 1.2368 - val_acc: 0.4652\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0267 - acc: 0.5427 - val_loss: 1.3032 - val_acc: 0.4774\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.1009 - acc: 0.5358 - val_loss: 1.2380 - val_acc: 0.5120\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 1.0475 - acc: 0.5646 - val_loss: 1.0449 - val_acc: 0.5989\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9596 - acc: 0.6003 - val_loss: 1.0076 - val_acc: 0.6047\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9279 - acc: 0.6135 - val_loss: 1.0768 - val_acc: 0.6013\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7870 - acc: 0.6603 - val_loss: 0.9075 - val_acc: 0.6508\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8062 - acc: 0.6576 - val_loss: 0.9490 - val_acc: 0.6098\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8013 - acc: 0.6497 - val_loss: 0.9622 - val_acc: 0.6688\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.8115 - acc: 0.6486 - val_loss: 0.8825 - val_acc: 0.6437\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7198 - acc: 0.6856 - val_loss: 0.8597 - val_acc: 0.6905\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7080 - acc: 0.6913 - val_loss: 0.7920 - val_acc: 0.7017\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7137 - acc: 0.7162 - val_loss: 0.9514 - val_acc: 0.6193\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.7532 - acc: 0.6570 - val_loss: 0.7752 - val_acc: 0.6753\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6903 - acc: 0.7048 - val_loss: 0.8245 - val_acc: 0.6956\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6557 - acc: 0.7286 - val_loss: 0.6868 - val_acc: 0.7224\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6598 - acc: 0.7121 - val_loss: 0.7734 - val_acc: 0.7116\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.6174 - acc: 0.7515 - val_loss: 0.7523 - val_acc: 0.7285\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6169 - acc: 0.7460 - val_loss: 0.7838 - val_acc: 0.7089\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5956 - acc: 0.7511 - val_loss: 0.8025 - val_acc: 0.7119\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5925 - acc: 0.7672 - val_loss: 0.7854 - val_acc: 0.7255\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6119 - acc: 0.7578 - val_loss: 0.6980 - val_acc: 0.7336\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5534 - acc: 0.7672 - val_loss: 0.8401 - val_acc: 0.7153\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 10s 2ms/step - loss: 0.5793 - acc: 0.7543 - val_loss: 0.9788 - val_acc: 0.6155\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5720 - acc: 0.7572 - val_loss: 0.8774 - val_acc: 0.6790\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5341 - acc: 0.7884 - val_loss: 0.6990 - val_acc: 0.7370\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.9109 - acc: 0.6215 - val_loss: 0.9511 - val_acc: 0.5972\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.6392 - acc: 0.7260 - val_loss: 0.7735 - val_acc: 0.7343\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5387 - acc: 0.7786 - val_loss: 0.8115 - val_acc: 0.7214\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5445 - acc: 0.7886 - val_loss: 0.6820 - val_acc: 0.7577\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5187 - acc: 0.7951 - val_loss: 0.7266 - val_acc: 0.7530\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4948 - acc: 0.8035 - val_loss: 0.6524 - val_acc: 0.7849\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4964 - acc: 0.8051 - val_loss: 0.6437 - val_acc: 0.7696\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.5241 - acc: 0.7921 - val_loss: 0.6356 - val_acc: 0.8093\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4662 - acc: 0.8092 - val_loss: 0.6123 - val_acc: 0.8052\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.4184 - acc: 0.8355 - val_loss: 0.6288 - val_acc: 0.8375\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 9s 2ms/step - loss: 0.3982 - acc: 0.8494 - val_loss: 0.6119 - val_acc: 0.8476\n",
      "2451/2451 [==============================] - 1s 343us/step\n",
      "4901/4901 [==============================] - 2s 337us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 12s 2ms/step - loss: 1.5552 - acc: 0.3582 - val_loss: 1.4544 - val_acc: 0.3482\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.3551 - acc: 0.3764 - val_loss: 1.4067 - val_acc: 0.3444\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2748 - acc: 0.3988 - val_loss: 1.3691 - val_acc: 0.3767\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2340 - acc: 0.4147 - val_loss: 1.3580 - val_acc: 0.3716\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2238 - acc: 0.4368 - val_loss: 1.3455 - val_acc: 0.3593\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2128 - acc: 0.4331 - val_loss: 1.2980 - val_acc: 0.3814\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2213 - acc: 0.4262 - val_loss: 1.3350 - val_acc: 0.3834\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1849 - acc: 0.4402 - val_loss: 1.3825 - val_acc: 0.3492\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2462 - acc: 0.3817 - val_loss: 1.3733 - val_acc: 0.3675\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.2102 - acc: 0.4198 - val_loss: 1.4758 - val_acc: 0.3695\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1492 - acc: 0.4641 - val_loss: 1.3125 - val_acc: 0.4652\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.1147 - acc: 0.4998 - val_loss: 1.2096 - val_acc: 0.4428\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.0970 - acc: 0.5235 - val_loss: 1.5233 - val_acc: 0.4598\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 1.0599 - acc: 0.5669 - val_loss: 1.2219 - val_acc: 0.5473\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 1.0485 - acc: 0.5673 - val_loss: 1.0581 - val_acc: 0.6155\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9796 - acc: 0.5989 - val_loss: 1.2517 - val_acc: 0.5083\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9687 - acc: 0.5967 - val_loss: 1.0534 - val_acc: 0.6264\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.9163 - acc: 0.6165 - val_loss: 1.0084 - val_acc: 0.6549\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.8443 - acc: 0.6410 - val_loss: 0.9554 - val_acc: 0.6457\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.8070 - acc: 0.6408 - val_loss: 0.8630 - val_acc: 0.6193\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8160 - acc: 0.6408 - val_loss: 0.8884 - val_acc: 0.6264\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7612 - acc: 0.6544 - val_loss: 0.8378 - val_acc: 0.6529\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7506 - acc: 0.6475 - val_loss: 0.8212 - val_acc: 0.6060\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.8579 - acc: 0.6248 - val_loss: 0.8885 - val_acc: 0.6366\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7272 - acc: 0.6675 - val_loss: 0.8271 - val_acc: 0.6508\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7207 - acc: 0.6722 - val_loss: 1.2732 - val_acc: 0.5898\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7668 - acc: 0.6540 - val_loss: 0.9775 - val_acc: 0.5541\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7440 - acc: 0.6365 - val_loss: 0.8015 - val_acc: 0.6108\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.7002 - acc: 0.6683 - val_loss: 0.8115 - val_acc: 0.6508\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6861 - acc: 0.6801 - val_loss: 0.9148 - val_acc: 0.6736\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6385 - acc: 0.7107 - val_loss: 0.8293 - val_acc: 0.6854\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6419 - acc: 0.7071 - val_loss: 0.8632 - val_acc: 0.6766\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6348 - acc: 0.7291 - val_loss: 0.8870 - val_acc: 0.6763\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.6064 - acc: 0.7395 - val_loss: 0.8510 - val_acc: 0.6848\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5558 - acc: 0.7638 - val_loss: 0.8864 - val_acc: 0.6834\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5391 - acc: 0.7752 - val_loss: 1.1080 - val_acc: 0.6552\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5513 - acc: 0.7756 - val_loss: 0.8493 - val_acc: 0.7177\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5308 - acc: 0.7727 - val_loss: 0.7292 - val_acc: 0.7323\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4943 - acc: 0.7917 - val_loss: 0.8615 - val_acc: 0.7245\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4850 - acc: 0.7874 - val_loss: 1.1279 - val_acc: 0.7068\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.5196 - acc: 0.7868 - val_loss: 0.7356 - val_acc: 0.7435\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4764 - acc: 0.7844 - val_loss: 0.8669 - val_acc: 0.7340\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4881 - acc: 0.7899 - val_loss: 0.8329 - val_acc: 0.7431\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4360 - acc: 0.7991 - val_loss: 0.7765 - val_acc: 0.7414\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4401 - acc: 0.8009 - val_loss: 0.7880 - val_acc: 0.7625\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4476 - acc: 0.8072 - val_loss: 0.8430 - val_acc: 0.7604\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.4316 - acc: 0.8044 - val_loss: 0.7481 - val_acc: 0.7615\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 10s 2ms/step - loss: 0.4119 - acc: 0.8009 - val_loss: 0.8346 - val_acc: 0.7638\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4261 - acc: 0.8070 - val_loss: 0.7883 - val_acc: 0.7574\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 9s 2ms/step - loss: 0.4112 - acc: 0.8074 - val_loss: 0.7626 - val_acc: 0.7604\n",
      "2450/2450 [==============================] - 1s 350us/step\n",
      "4902/4902 [==============================] - 2s 350us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 25s 5ms/step - loss: 1.4656 - acc: 0.3836 - val_loss: 1.3771 - val_acc: 0.3526\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3293 - acc: 0.4111 - val_loss: 1.2773 - val_acc: 0.4313\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2750 - acc: 0.4234 - val_loss: 1.3083 - val_acc: 0.3661\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2381 - acc: 0.4505 - val_loss: 1.1937 - val_acc: 0.4445\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1269 - acc: 0.4772 - val_loss: 1.1992 - val_acc: 0.4214\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0801 - acc: 0.4991 - val_loss: 1.0796 - val_acc: 0.6040\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0587 - acc: 0.5456 - val_loss: 1.3856 - val_acc: 0.3678\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0378 - acc: 0.5348 - val_loss: 0.9702 - val_acc: 0.5433\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.8394 - acc: 0.6091 - val_loss: 1.7214 - val_acc: 0.4299\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8108 - acc: 0.6305 - val_loss: 0.7818 - val_acc: 0.6105\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7139 - acc: 0.6544 - val_loss: 0.7617 - val_acc: 0.6216\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6953 - acc: 0.6811 - val_loss: 0.8416 - val_acc: 0.6515\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6736 - acc: 0.7013 - val_loss: 0.7282 - val_acc: 0.7055\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6119 - acc: 0.7394 - val_loss: 0.7476 - val_acc: 0.6637\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5715 - acc: 0.7592 - val_loss: 0.6401 - val_acc: 0.7340\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5731 - acc: 0.7521 - val_loss: 0.6027 - val_acc: 0.7367\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5680 - acc: 0.7613 - val_loss: 0.6741 - val_acc: 0.7024\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5221 - acc: 0.7754 - val_loss: 0.5349 - val_acc: 0.7584\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5759 - acc: 0.7745 - val_loss: 0.5434 - val_acc: 0.7601\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5193 - acc: 0.8047 - val_loss: 0.7417 - val_acc: 0.7167\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4597 - acc: 0.8317 - val_loss: 0.4871 - val_acc: 0.7940\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4381 - acc: 0.8578 - val_loss: 0.6629 - val_acc: 0.7706\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3682 - acc: 0.8855 - val_loss: 0.4546 - val_acc: 0.8086\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3028 - acc: 0.8984 - val_loss: 0.5017 - val_acc: 0.8269\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2686 - acc: 0.9092 - val_loss: 0.5147 - val_acc: 0.8629\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2782 - acc: 0.9196 - val_loss: 0.5310 - val_acc: 0.8561\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2484 - acc: 0.9316 - val_loss: 0.5502 - val_acc: 0.8517\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2396 - acc: 0.9243 - val_loss: 1.1124 - val_acc: 0.7665\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2644 - acc: 0.9216 - val_loss: 0.4359 - val_acc: 0.8755\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2240 - acc: 0.9255 - val_loss: 0.5321 - val_acc: 0.8816\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2054 - acc: 0.9337 - val_loss: 0.4958 - val_acc: 0.8802\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2346 - acc: 0.9278 - val_loss: 0.4877 - val_acc: 0.8283\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2239 - acc: 0.9304 - val_loss: 0.5690 - val_acc: 0.8700\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1983 - acc: 0.9339 - val_loss: 0.6154 - val_acc: 0.8225\n",
      "Epoch 35/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2347 - acc: 0.9182 - val_loss: 0.4754 - val_acc: 0.8364\n",
      "Epoch 36/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2030 - acc: 0.9196 - val_loss: 0.6993 - val_acc: 0.8711\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1844 - acc: 0.9343 - val_loss: 0.3797 - val_acc: 0.8928\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1822 - acc: 0.9372 - val_loss: 0.3593 - val_acc: 0.8941\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1685 - acc: 0.9439 - val_loss: 0.3530 - val_acc: 0.8972\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1842 - acc: 0.9400 - val_loss: 0.4875 - val_acc: 0.8880\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2077 - acc: 0.9265 - val_loss: 0.3791 - val_acc: 0.8823\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1999 - acc: 0.9298 - val_loss: 0.4407 - val_acc: 0.8812\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2051 - acc: 0.9304 - val_loss: 0.4565 - val_acc: 0.8819\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1566 - acc: 0.9427 - val_loss: 0.4619 - val_acc: 0.8914\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1885 - acc: 0.9431 - val_loss: 0.4683 - val_acc: 0.8806\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1807 - acc: 0.9298 - val_loss: 0.5186 - val_acc: 0.8806\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1685 - acc: 0.9406 - val_loss: 0.5577 - val_acc: 0.8931\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1847 - acc: 0.9372 - val_loss: 0.6072 - val_acc: 0.8768\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1423 - acc: 0.9445 - val_loss: 0.4308 - val_acc: 0.9080\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1324 - acc: 0.9488 - val_loss: 0.5948 - val_acc: 0.8989\n",
      "2451/2451 [==============================] - 2s 896us/step\n",
      "4901/4901 [==============================] - 4s 885us/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4901/4901 [==============================] - 24s 5ms/step - loss: 1.4294 - acc: 0.3599 - val_loss: 1.4353 - val_acc: 0.3325\n",
      "Epoch 2/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.3106 - acc: 0.3795 - val_loss: 1.3032 - val_acc: 0.4367\n",
      "Epoch 3/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2488 - acc: 0.4330 - val_loss: 1.3587 - val_acc: 0.4130\n",
      "Epoch 4/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2502 - acc: 0.4209 - val_loss: 1.3324 - val_acc: 0.4191\n",
      "Epoch 5/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2023 - acc: 0.4691 - val_loss: 2.0500 - val_acc: 0.2681\n",
      "Epoch 6/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.2419 - acc: 0.4346 - val_loss: 1.2909 - val_acc: 0.4269\n",
      "Epoch 7/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1802 - acc: 0.4746 - val_loss: 1.2827 - val_acc: 0.4293\n",
      "Epoch 8/50\n",
      "4901/4901 [==============================] - 22s 4ms/step - loss: 1.1968 - acc: 0.4562 - val_loss: 1.3858 - val_acc: 0.4130\n",
      "Epoch 9/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0762 - acc: 0.4866 - val_loss: 1.1861 - val_acc: 0.4595\n",
      "Epoch 10/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1096 - acc: 0.4966 - val_loss: 1.1557 - val_acc: 0.4700\n",
      "Epoch 11/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0804 - acc: 0.4938 - val_loss: 1.2822 - val_acc: 0.4079\n",
      "Epoch 12/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.1047 - acc: 0.4905 - val_loss: 1.3733 - val_acc: 0.4116\n",
      "Epoch 13/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 1.0510 - acc: 0.5262 - val_loss: 1.0458 - val_acc: 0.5355\n",
      "Epoch 14/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8559 - acc: 0.6072 - val_loss: 1.2884 - val_acc: 0.5470\n",
      "Epoch 15/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7862 - acc: 0.6111 - val_loss: 1.0041 - val_acc: 0.5429\n",
      "Epoch 16/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.7809 - acc: 0.6123 - val_loss: 0.8943 - val_acc: 0.5999\n",
      "Epoch 17/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.8091 - acc: 0.6254 - val_loss: 0.9053 - val_acc: 0.6227\n",
      "Epoch 18/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6451 - acc: 0.6780 - val_loss: 0.8400 - val_acc: 0.6349\n",
      "Epoch 19/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6575 - acc: 0.6882 - val_loss: 0.9970 - val_acc: 0.6651\n",
      "Epoch 20/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6293 - acc: 0.7203 - val_loss: 0.9626 - val_acc: 0.6145\n",
      "Epoch 21/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.6408 - acc: 0.7250 - val_loss: 0.8587 - val_acc: 0.6220\n",
      "Epoch 22/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5353 - acc: 0.7835 - val_loss: 0.7424 - val_acc: 0.7852\n",
      "Epoch 23/50\n",
      "4901/4901 [==============================] - 22s 4ms/step - loss: 0.4586 - acc: 0.8321 - val_loss: 0.8760 - val_acc: 0.7255\n",
      "Epoch 24/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.5590 - acc: 0.8168 - val_loss: 0.8735 - val_acc: 0.7458\n",
      "Epoch 25/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.4804 - acc: 0.8478 - val_loss: 1.0584 - val_acc: 0.7129\n",
      "Epoch 26/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3957 - acc: 0.8690 - val_loss: 0.6265 - val_acc: 0.8381\n",
      "Epoch 27/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3448 - acc: 0.8896 - val_loss: 0.6164 - val_acc: 0.8347\n",
      "Epoch 28/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2975 - acc: 0.9123 - val_loss: 0.8339 - val_acc: 0.8151\n",
      "Epoch 29/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.3006 - acc: 0.9043 - val_loss: 0.7738 - val_acc: 0.8286\n",
      "Epoch 30/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2887 - acc: 0.9061 - val_loss: 0.5592 - val_acc: 0.8565\n",
      "Epoch 31/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2498 - acc: 0.9263 - val_loss: 0.5633 - val_acc: 0.8755\n",
      "Epoch 32/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2208 - acc: 0.9274 - val_loss: 0.6128 - val_acc: 0.8405\n",
      "Epoch 33/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2530 - acc: 0.9241 - val_loss: 0.4766 - val_acc: 0.8741\n",
      "Epoch 34/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2627 - acc: 0.9157 - val_loss: 0.5115 - val_acc: 0.8619\n",
      "Epoch 35/50\n",
      "4900/4901 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9180Epoch 36/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2546 - acc: 0.9149 - val_loss: 0.3909 - val_acc: 0.8836\n",
      "Epoch 37/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1977 - acc: 0.9372 - val_loss: 0.4832 - val_acc: 0.8914\n",
      "Epoch 38/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2082 - acc: 0.9341 - val_loss: 0.5197 - val_acc: 0.8921\n",
      "Epoch 39/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2006 - acc: 0.9357 - val_loss: 0.7496 - val_acc: 0.8483\n",
      "Epoch 40/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2246 - acc: 0.9251 - val_loss: 0.6344 - val_acc: 0.8663\n",
      "Epoch 41/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1967 - acc: 0.9359 - val_loss: 0.6113 - val_acc: 0.8582\n",
      "Epoch 42/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.2227 - acc: 0.9255 - val_loss: 0.5128 - val_acc: 0.8643\n",
      "Epoch 43/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1487 - acc: 0.9445 - val_loss: 0.6659 - val_acc: 0.8653\n",
      "Epoch 44/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1666 - acc: 0.9472 - val_loss: 0.4928 - val_acc: 0.8924\n",
      "Epoch 45/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1615 - acc: 0.9445 - val_loss: 0.6082 - val_acc: 0.8853\n",
      "Epoch 46/50\n",
      "4901/4901 [==============================] - 21s 4ms/step - loss: 0.1703 - acc: 0.9427 - val_loss: 0.5860 - val_acc: 0.8907\n",
      "Epoch 47/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.2152 - acc: 0.9308 - val_loss: 0.4093 - val_acc: 0.8985\n",
      "Epoch 48/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1699 - acc: 0.9408 - val_loss: 0.5728 - val_acc: 0.8918\n",
      "Epoch 49/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1315 - acc: 0.9529 - val_loss: 0.5107 - val_acc: 0.8955\n",
      "Epoch 50/50\n",
      "4901/4901 [==============================] - 20s 4ms/step - loss: 0.1842 - acc: 0.9437 - val_loss: 0.3838 - val_acc: 0.9043\n",
      "2451/2451 [==============================] - 2s 859us/step\n",
      "4901/4901 [==============================] - 4s 846us/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 24s 5ms/step - loss: 1.4076 - acc: 0.3703 - val_loss: 1.3884 - val_acc: 0.3488\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.3510 - acc: 0.3717 - val_loss: 1.4784 - val_acc: 0.3420\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.2802 - acc: 0.3790 - val_loss: 1.2963 - val_acc: 0.3817\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 1.2706 - acc: 0.4186 - val_loss: 1.5098 - val_acc: 0.3546\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 1.1880 - acc: 0.4651 - val_loss: 1.3028 - val_acc: 0.4343\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 1.1529 - acc: 0.4727 - val_loss: 1.2447 - val_acc: 0.4917\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 1.1193 - acc: 0.5012 - val_loss: 1.2328 - val_acc: 0.5029\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 1.0895 - acc: 0.5177 - val_loss: 1.0195 - val_acc: 0.5514\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 0.9748 - acc: 0.5620 - val_loss: 0.9129 - val_acc: 0.5585\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 0.8626 - acc: 0.5996 - val_loss: 1.0666 - val_acc: 0.5687\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7950 - acc: 0.6157 - val_loss: 0.8545 - val_acc: 0.5786\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.8330 - acc: 0.6063 - val_loss: 1.1188 - val_acc: 0.5436\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.8489 - acc: 0.5991 - val_loss: 0.9362 - val_acc: 0.5497\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7867 - acc: 0.6149 - val_loss: 1.0182 - val_acc: 0.6162\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7324 - acc: 0.6389 - val_loss: 0.9526 - val_acc: 0.5860\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7034 - acc: 0.6340 - val_loss: 0.8486 - val_acc: 0.6115\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 1.0048 - acc: 0.5626 - val_loss: 1.5511 - val_acc: 0.4700\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.9328 - acc: 0.6122 - val_loss: 0.9942 - val_acc: 0.5775\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.7430 - acc: 0.6563 - val_loss: 0.9196 - val_acc: 0.6162\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.6788 - acc: 0.6946 - val_loss: 0.8433 - val_acc: 0.6505\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 20s 4ms/step - loss: 0.6195 - acc: 0.7242 - val_loss: 0.7069 - val_acc: 0.7418\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.5492 - acc: 0.7840 - val_loss: 0.9959 - val_acc: 0.7234\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.4773 - acc: 0.8356 - val_loss: 0.8055 - val_acc: 0.7421\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3835 - acc: 0.8629 - val_loss: 0.5018 - val_acc: 0.8293\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3240 - acc: 0.8825 - val_loss: 0.4953 - val_acc: 0.8599\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.3113 - acc: 0.8919 - val_loss: 0.4796 - val_acc: 0.8663\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2769 - acc: 0.9058 - val_loss: 0.4012 - val_acc: 0.8816\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2480 - acc: 0.9172 - val_loss: 0.5340 - val_acc: 0.8619\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2359 - acc: 0.9137 - val_loss: 0.3884 - val_acc: 0.8789\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2186 - acc: 0.9266 - val_loss: 0.4883 - val_acc: 0.8758\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2123 - acc: 0.9270 - val_loss: 0.4641 - val_acc: 0.8778\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2147 - acc: 0.9237 - val_loss: 0.5586 - val_acc: 0.8263\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 22s 5ms/step - loss: 0.1896 - acc: 0.9266 - val_loss: 0.6897 - val_acc: 0.8619\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1687 - acc: 0.9353 - val_loss: 0.6305 - val_acc: 0.8622\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1774 - acc: 0.9294 - val_loss: 1.5776 - val_acc: 0.7645\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1618 - acc: 0.9396 - val_loss: 0.4109 - val_acc: 0.8819\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1742 - acc: 0.9396 - val_loss: 0.4845 - val_acc: 0.8873\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1671 - acc: 0.9349 - val_loss: 0.4859 - val_acc: 0.8809\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1590 - acc: 0.9394 - val_loss: 0.6420 - val_acc: 0.8697\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1648 - acc: 0.9382 - val_loss: 0.4391 - val_acc: 0.8568\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1400 - acc: 0.9439 - val_loss: 0.3973 - val_acc: 0.8921\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.2216 - acc: 0.9247 - val_loss: 0.5957 - val_acc: 0.8812\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1812 - acc: 0.9317 - val_loss: 0.8784 - val_acc: 0.8341\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1811 - acc: 0.9255 - val_loss: 0.4732 - val_acc: 0.8901\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1688 - acc: 0.9392 - val_loss: 0.4967 - val_acc: 0.8853\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1835 - acc: 0.9294 - val_loss: 0.6573 - val_acc: 0.8677\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: 0.1942 - acc: 0.9284 - val_loss: 0.4402 - val_acc: 0.8924\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 23s 5ms/step - loss: nan - acc: 0.2458 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: nan - acc: 0.1703 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 21s 4ms/step - loss: nan - acc: 0.1703 - val_loss: nan - val_acc: 0.1683\n",
      "2450/2450 [==============================] - 2s 870us/step\n",
      "4902/4902 [==============================] - 4s 868us/step\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.3685 - acc: 0.3855 - val_loss: 1.5273 - val_acc: 0.3397\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.2811 - acc: 0.4392 - val_loss: 1.4213 - val_acc: 0.3549\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.1808 - acc: 0.4882 - val_loss: 1.0431 - val_acc: 0.5443\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.0374 - acc: 0.5477 - val_loss: 1.4354 - val_acc: 0.4673\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.9672 - acc: 0.5767 - val_loss: 0.8989 - val_acc: 0.6264\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.7207 - acc: 0.6853 - val_loss: 0.7801 - val_acc: 0.6814\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6417 - acc: 0.7690 - val_loss: 0.7546 - val_acc: 0.7316\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4760 - acc: 0.8300 - val_loss: 0.4934 - val_acc: 0.8215\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.3280 - acc: 0.8932 - val_loss: 0.3873 - val_acc: 0.8524\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2761 - acc: 0.9029 - val_loss: 1.0461 - val_acc: 0.6600\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2484 - acc: 0.9131 - val_loss: 0.3199 - val_acc: 0.8884\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2261 - acc: 0.9165 - val_loss: 0.3215 - val_acc: 0.8877\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1947 - acc: 0.9264 - val_loss: 0.4395 - val_acc: 0.8755\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1948 - acc: 0.9252 - val_loss: 0.5933 - val_acc: 0.8758\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1823 - acc: 0.9297 - val_loss: 0.3442 - val_acc: 0.8839\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1755 - acc: 0.9327 - val_loss: 0.5976 - val_acc: 0.8622\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1841 - acc: 0.9350 - val_loss: 0.5469 - val_acc: 0.8629\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1530 - acc: 0.9395 - val_loss: 0.4257 - val_acc: 0.9009\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1405 - acc: 0.9460 - val_loss: 0.5670 - val_acc: 0.8877\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1827 - acc: 0.9344 - val_loss: 0.7220 - val_acc: 0.7981\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1602 - acc: 0.9408 - val_loss: 0.4858 - val_acc: 0.8744\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1381 - acc: 0.9440 - val_loss: 0.5045 - val_acc: 0.8890\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1381 - acc: 0.9456 - val_loss: 0.5158 - val_acc: 0.8782\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1391 - acc: 0.9448 - val_loss: 0.5611 - val_acc: 0.8914\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1361 - acc: 0.9493 - val_loss: 0.3608 - val_acc: 0.8972\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1259 - acc: 0.9486 - val_loss: 0.3705 - val_acc: 0.9016\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1274 - acc: 0.9487 - val_loss: 0.3120 - val_acc: 0.9009\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1317 - acc: 0.9476 - val_loss: 0.4758 - val_acc: 0.8968\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1212 - acc: 0.9513 - val_loss: 0.6037 - val_acc: 0.8951\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1250 - acc: 0.9527 - val_loss: 0.4105 - val_acc: 0.9128\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1280 - acc: 0.9518 - val_loss: 0.4358 - val_acc: 0.9097\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1342 - acc: 0.9468 - val_loss: 0.4145 - val_acc: 0.8877\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1147 - acc: 0.9523 - val_loss: 0.4093 - val_acc: 0.8921\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1168 - acc: 0.9509 - val_loss: 0.4940 - val_acc: 0.8931\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1189 - acc: 0.9554 - val_loss: 0.3159 - val_acc: 0.9063\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1195 - acc: 0.9524 - val_loss: 0.5070 - val_acc: 0.8897\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1236 - acc: 0.9490 - val_loss: 0.4055 - val_acc: 0.9016\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1155 - acc: 0.9524 - val_loss: 0.4358 - val_acc: 0.9094\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1369 - acc: 0.9529 - val_loss: 0.5153 - val_acc: 0.8938\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1441 - acc: 0.9476 - val_loss: 0.3337 - val_acc: 0.8921\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1292 - acc: 0.9491 - val_loss: 0.4215 - val_acc: 0.8958\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1170 - acc: 0.9555 - val_loss: 0.3455 - val_acc: 0.9006\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1091 - acc: 0.9553 - val_loss: 0.3800 - val_acc: 0.9118\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1198 - acc: 0.9486 - val_loss: 0.5918 - val_acc: 0.8951\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1163 - acc: 0.9518 - val_loss: 0.3063 - val_acc: 0.9050\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1151 - acc: 0.9558 - val_loss: 0.3947 - val_acc: 0.9030\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1151 - acc: 0.9521 - val_loss: 0.3418 - val_acc: 0.9158\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1176 - acc: 0.9544 - val_loss: 0.4152 - val_acc: 0.8968\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1160 - acc: 0.9494 - val_loss: 0.3575 - val_acc: 0.9226\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1130 - acc: 0.9533 - val_loss: 0.3935 - val_acc: 0.9114\n"
     ]
    }
   ],
   "source": [
    "#grid_result = grid.fit(X_train, Y_train)\n",
    "grid_result  = grid.fit(X_train,\n",
    "                           Y_train,\n",
    "                           validation_data=(X_test, Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "I7EtI7oOvOYa",
    "outputId": "3a09b965-d69d-412c-bbc5-665547cb8b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.918662 using {'dropout_rate': 0.3, 'neurons': 128}\n",
      "0.906556 (0.028098) with: {'dropout_rate': 0.3, 'neurons': 48}\n",
      "0.918662 (0.021173) with: {'dropout_rate': 0.3, 'neurons': 128}\n",
      "0.840588 (0.070673) with: {'dropout_rate': 0.5, 'neurons': 48}\n",
      "0.906012 (0.020110) with: {'dropout_rate': 0.5, 'neurons': 128}\n",
      "0.838683 (0.018163) with: {'dropout_rate': 0.7, 'neurons': 48}\n",
      "0.676823 (0.365888) with: {'dropout_rate': 0.7, 'neurons': 128}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "kemVKgTSxiYf",
    "outputId": "f5c79390-b8c9-42eb-8c75-64a633d9eb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,430\n",
      "Trainable params: 71,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "id": "cSy5h0a8xiWD",
    "outputId": "f4b20c0b-0289-443f-c23e-51cb11fc517e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.3822 - acc: 0.3678 - val_loss: 1.3504 - val_acc: 0.3488\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.2827 - acc: 0.4377 - val_loss: 1.2654 - val_acc: 0.4228\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 1.1996 - acc: 0.4763 - val_loss: 1.1816 - val_acc: 0.5331\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 1.0573 - acc: 0.5480 - val_loss: 2.7875 - val_acc: 0.3610\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.0358 - acc: 0.5532 - val_loss: 1.7124 - val_acc: 0.4031\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.9561 - acc: 0.5793 - val_loss: 1.0400 - val_acc: 0.5137\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.7865 - acc: 0.6328 - val_loss: 0.8755 - val_acc: 0.6267\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.7688 - acc: 0.6659 - val_loss: 0.9155 - val_acc: 0.6152\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.7362 - acc: 0.6987 - val_loss: 0.7406 - val_acc: 0.7065\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6065 - acc: 0.7621 - val_loss: 0.7274 - val_acc: 0.7221\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.5619 - acc: 0.7788 - val_loss: 0.7424 - val_acc: 0.7245\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.4832 - acc: 0.8169 - val_loss: 0.5496 - val_acc: 0.8059\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.4519 - acc: 0.8400 - val_loss: 0.6659 - val_acc: 0.7794\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.3768 - acc: 0.8649 - val_loss: 0.6567 - val_acc: 0.7513\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.3040 - acc: 0.8917 - val_loss: 0.5937 - val_acc: 0.8174\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2514 - acc: 0.9095 - val_loss: 0.4185 - val_acc: 0.8772\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2161 - acc: 0.9222 - val_loss: 0.3962 - val_acc: 0.8527\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1992 - acc: 0.9286 - val_loss: 0.3946 - val_acc: 0.8633\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1818 - acc: 0.9328 - val_loss: 0.3946 - val_acc: 0.8856\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1689 - acc: 0.9368 - val_loss: 0.3531 - val_acc: 0.8935\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1536 - acc: 0.9419 - val_loss: 0.3391 - val_acc: 0.8985\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1513 - acc: 0.9440 - val_loss: 0.5407 - val_acc: 0.8643\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1364 - acc: 0.9491 - val_loss: 0.2365 - val_acc: 0.9131\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1438 - acc: 0.9482 - val_loss: 0.2866 - val_acc: 0.9121\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1373 - acc: 0.9502 - val_loss: 0.2138 - val_acc: 0.9213\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1427 - acc: 0.9474 - val_loss: 0.2781 - val_acc: 0.9135\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1663 - acc: 0.9436 - val_loss: 0.2796 - val_acc: 0.9094\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1292 - acc: 0.9518 - val_loss: 0.3280 - val_acc: 0.9104\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1198 - acc: 0.9539 - val_loss: 0.2344 - val_acc: 0.9158\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1302 - acc: 0.9501 - val_loss: 0.2155 - val_acc: 0.9209\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1382 - acc: 0.9493 - val_loss: 0.2864 - val_acc: 0.9091\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1270 - acc: 0.9499 - val_loss: 0.2507 - val_acc: 0.9172\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1185 - acc: 0.9502 - val_loss: 0.2657 - val_acc: 0.9138\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1172 - acc: 0.9538 - val_loss: 0.2899 - val_acc: 0.9169\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1247 - acc: 0.9531 - val_loss: 0.3691 - val_acc: 0.8992\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1196 - acc: 0.9510 - val_loss: 0.2459 - val_acc: 0.9287\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1194 - acc: 0.9506 - val_loss: 0.3139 - val_acc: 0.9148\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1262 - acc: 0.9502 - val_loss: 0.3886 - val_acc: 0.9091\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1168 - acc: 0.9518 - val_loss: 0.2559 - val_acc: 0.9253\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1240 - acc: 0.9544 - val_loss: 0.3017 - val_acc: 0.9216\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1146 - acc: 0.9567 - val_loss: 0.3124 - val_acc: 0.9192\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1245 - acc: 0.9525 - val_loss: 0.2584 - val_acc: 0.9179\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1095 - acc: 0.9567 - val_loss: 0.3425 - val_acc: 0.9165\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1129 - acc: 0.9547 - val_loss: 0.2718 - val_acc: 0.9213\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1199 - acc: 0.9512 - val_loss: 0.3193 - val_acc: 0.9155\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1114 - acc: 0.9524 - val_loss: 0.2180 - val_acc: 0.9179\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1115 - acc: 0.9536 - val_loss: 0.2738 - val_acc: 0.9016\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1194 - acc: 0.9544 - val_loss: 0.3192 - val_acc: 0.9114\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1227 - acc: 0.9561 - val_loss: 0.3759 - val_acc: 0.9121\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1208 - acc: 0.9535 - val_loss: 0.4527 - val_acc: 0.8996\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, nb_epoch=50, batch_size=50 ,verbose=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmjczQyuxiTo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "nt4Eph-_xiRc",
    "outputId": "1c81d134-a340-42f3-ea3b-988a2cd2e082"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf+8BntSGzgYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('categorical_crossentropy')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,50+1))\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzq87HdG9wSw"
   },
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2,dropout_rate1,dropout_rate2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neuron1,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    model.add(LSTM(neuron2))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    model.add(Dense(n_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh0GReERAesZ"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jubczCw_AewQ"
   },
   "outputs": [],
   "source": [
    "neuron1 = [48, 128]\n",
    "neuron2 =[64,128]\n",
    "dropout_rate1 = [0.3, 0.5, 0.7]\n",
    "dropout_rate2 = [0.3, 0.5, 0.7]\n",
    "param_grid = dict(neuron1=neuron1,neuron2=neuron2,dropout_rate1=dropout_rate1,dropout_rate2=dropout_rate2)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "\n",
    "# Could not execute the above code because of less computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitbohra/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.4528 - acc: 0.3738 - val_loss: 1.4074 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.3322 - acc: 0.3920 - val_loss: 1.4159 - val_acc: 0.3532\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 35s 7ms/step - loss: 1.3022 - acc: 0.3920 - val_loss: 1.3624 - val_acc: 0.3539\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.1838 - acc: 0.4603 - val_loss: 1.2859 - val_acc: 0.4096\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.1343 - acc: 0.4795 - val_loss: 1.1412 - val_acc: 0.4425\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0555 - acc: 0.4821 - val_loss: 1.1022 - val_acc: 0.4401\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0730 - acc: 0.4913 - val_loss: 1.0627 - val_acc: 0.4418\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.9106 - acc: 0.5183 - val_loss: 0.9752 - val_acc: 0.5721\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.8099 - acc: 0.6215 - val_loss: 0.9139 - val_acc: 0.6050\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.7598 - acc: 0.6386 - val_loss: 0.8482 - val_acc: 0.6003\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7178 - acc: 0.6472 - val_loss: 0.8224 - val_acc: 0.6088\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6696 - acc: 0.6554 - val_loss: 0.8884 - val_acc: 0.5830\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7173 - acc: 0.6513 - val_loss: 0.8147 - val_acc: 0.5969\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7053 - acc: 0.6435 - val_loss: 0.9583 - val_acc: 0.5887\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6357 - acc: 0.6697 - val_loss: 0.8594 - val_acc: 0.6026\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6238 - acc: 0.6868 - val_loss: 0.8084 - val_acc: 0.6227\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6099 - acc: 0.7286 - val_loss: 0.8152 - val_acc: 0.7024\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5745 - acc: 0.7484 - val_loss: 0.7446 - val_acc: 0.7085\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5335 - acc: 0.7678 - val_loss: 0.7095 - val_acc: 0.7336\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5279 - acc: 0.7727 - val_loss: 0.7192 - val_acc: 0.7265\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4936 - acc: 0.7758 - val_loss: 0.6991 - val_acc: 0.7316\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4846 - acc: 0.7939 - val_loss: 0.6827 - val_acc: 0.7438\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4636 - acc: 0.7913 - val_loss: 0.6634 - val_acc: 0.7424\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4361 - acc: 0.8053 - val_loss: 0.6325 - val_acc: 0.7618\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3829 - acc: 0.8166 - val_loss: 0.5778 - val_acc: 0.7594\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3490 - acc: 0.8439 - val_loss: 0.7734 - val_acc: 0.7516\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3281 - acc: 0.8786 - val_loss: 0.6014 - val_acc: 0.8259\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2700 - acc: 0.9068 - val_loss: 0.5056 - val_acc: 0.8534\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2175 - acc: 0.9251 - val_loss: 0.5974 - val_acc: 0.8412\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1819 - acc: 0.9390 - val_loss: 0.4156 - val_acc: 0.8846\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.4275 - acc: 0.3793 - val_loss: 1.4235 - val_acc: 0.3851\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2124 - acc: 0.4724 - val_loss: 1.2760 - val_acc: 0.4503\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1116 - acc: 0.4909 - val_loss: 1.1250 - val_acc: 0.4649\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9845 - acc: 0.5611 - val_loss: 1.0092 - val_acc: 0.5114\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8477 - acc: 0.6097 - val_loss: 0.8646 - val_acc: 0.5908\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7775 - acc: 0.6050 - val_loss: 1.2394 - val_acc: 0.4299\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7491 - acc: 0.5864 - val_loss: 0.8068 - val_acc: 0.5806\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6237 - acc: 0.6421 - val_loss: 0.7223 - val_acc: 0.6121\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6052 - acc: 0.6733 - val_loss: 0.6745 - val_acc: 0.6644\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5157 - acc: 0.7317 - val_loss: 0.6119 - val_acc: 0.7414\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4979 - acc: 0.7678 - val_loss: 0.6227 - val_acc: 0.7553\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4495 - acc: 0.7943 - val_loss: 0.5560 - val_acc: 0.7625\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3951 - acc: 0.7978 - val_loss: 0.5899 - val_acc: 0.7543\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3572 - acc: 0.8047 - val_loss: 0.5293 - val_acc: 0.7676\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3846 - acc: 0.7788 - val_loss: 0.5681 - val_acc: 0.7384\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3227 - acc: 0.7984 - val_loss: 0.5363 - val_acc: 0.7350\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3156 - acc: 0.8021 - val_loss: 0.6081 - val_acc: 0.7458\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2827 - acc: 0.8051 - val_loss: 0.5248 - val_acc: 0.7513\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2741 - acc: 0.8076 - val_loss: 0.4625 - val_acc: 0.7465\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2567 - acc: 0.8104 - val_loss: 0.4841 - val_acc: 0.7591\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2625 - acc: 0.8239 - val_loss: 0.6024 - val_acc: 0.7201\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2601 - acc: 0.8590 - val_loss: 0.4852 - val_acc: 0.8629\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2400 - acc: 0.9200 - val_loss: 0.4406 - val_acc: 0.8768\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2274 - acc: 0.9461 - val_loss: 0.5681 - val_acc: 0.8755\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1838 - acc: 0.9531 - val_loss: 0.4461 - val_acc: 0.8863\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1753 - acc: 0.9423 - val_loss: 0.4473 - val_acc: 0.8728\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1476 - acc: 0.9484 - val_loss: 0.4503 - val_acc: 0.8785\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1294 - acc: 0.9551 - val_loss: 0.4370 - val_acc: 0.8843\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1287 - acc: 0.9565 - val_loss: 0.4346 - val_acc: 0.8884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1283 - acc: 0.9549 - val_loss: 0.5381 - val_acc: 0.8816\n",
      "2451/2451 [==============================] - 3s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 54s 11ms/step - loss: 1.4643 - acc: 0.3403 - val_loss: 1.4158 - val_acc: 0.3112\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2461 - acc: 0.4492 - val_loss: 1.2675 - val_acc: 0.4221\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.0909 - acc: 0.5135 - val_loss: 1.0907 - val_acc: 0.4903\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9410 - acc: 0.5659 - val_loss: 1.3525 - val_acc: 0.4102\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8452 - acc: 0.6032 - val_loss: 1.5454 - val_acc: 0.4096\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7819 - acc: 0.6022 - val_loss: 0.8820 - val_acc: 0.5718\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6400 - acc: 0.6381 - val_loss: 0.6926 - val_acc: 0.6060\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5865 - acc: 0.6506 - val_loss: 0.6398 - val_acc: 0.6159\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5660 - acc: 0.6583 - val_loss: 0.6836 - val_acc: 0.6074\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5578 - acc: 0.6638 - val_loss: 0.7183 - val_acc: 0.5860\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5157 - acc: 0.7109 - val_loss: 0.7097 - val_acc: 0.7272\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4981 - acc: 0.7621 - val_loss: 0.7091 - val_acc: 0.7122\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4696 - acc: 0.7946 - val_loss: 0.5999 - val_acc: 0.7421\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5566 - acc: 0.7503 - val_loss: 0.6063 - val_acc: 0.7296\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3513 - acc: 0.8074 - val_loss: 0.5632 - val_acc: 0.7333\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3281 - acc: 0.8058 - val_loss: 0.4926 - val_acc: 0.7343\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2995 - acc: 0.8184 - val_loss: 0.6243 - val_acc: 0.7465\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2908 - acc: 0.8390 - val_loss: 0.9421 - val_acc: 0.7306\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3293 - acc: 0.8900 - val_loss: 0.5383 - val_acc: 0.8571\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2520 - acc: 0.9304 - val_loss: 0.6722 - val_acc: 0.7991\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2085 - acc: 0.9337 - val_loss: 0.4641 - val_acc: 0.8731\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1596 - acc: 0.9449 - val_loss: 0.3865 - val_acc: 0.8880\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1854 - acc: 0.9366 - val_loss: 0.4839 - val_acc: 0.8921\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1448 - acc: 0.9441 - val_loss: 0.6173 - val_acc: 0.8666\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1368 - acc: 0.9453 - val_loss: 0.5041 - val_acc: 0.8965\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1395 - acc: 0.9472 - val_loss: 0.4255 - val_acc: 0.9043\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1426 - acc: 0.9408 - val_loss: 0.4893 - val_acc: 0.8802\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1348 - acc: 0.9463 - val_loss: 0.3967 - val_acc: 0.9023\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1245 - acc: 0.9504 - val_loss: 0.4286 - val_acc: 0.8965\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1267 - acc: 0.9498 - val_loss: 0.4339 - val_acc: 0.8985\n",
      "2450/2450 [==============================] - 3s 1ms/step\n",
      "4902/4902 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 66s 14ms/step - loss: 1.4588 - acc: 0.3909 - val_loss: 1.3533 - val_acc: 0.4259\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.2467 - acc: 0.4983 - val_loss: 1.8740 - val_acc: 0.2301\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.2745 - acc: 0.4183 - val_loss: 1.1288 - val_acc: 0.5008\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.9733 - acc: 0.5805 - val_loss: 0.9360 - val_acc: 0.5948\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 43s 9ms/step - loss: 0.8302 - acc: 0.6170 - val_loss: 1.0097 - val_acc: 0.5568\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7473 - acc: 0.6289 - val_loss: 1.0114 - val_acc: 0.5585\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7219 - acc: 0.6472 - val_loss: 1.4865 - val_acc: 0.3936\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7215 - acc: 0.6478 - val_loss: 0.7534 - val_acc: 0.6627\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6827 - acc: 0.6760 - val_loss: 0.7905 - val_acc: 0.6515\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5938 - acc: 0.7256 - val_loss: 0.7111 - val_acc: 0.6878\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5142 - acc: 0.7603 - val_loss: 1.0734 - val_acc: 0.6464\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4641 - acc: 0.7737 - val_loss: 0.7508 - val_acc: 0.7024\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4431 - acc: 0.7788 - val_loss: 0.5900 - val_acc: 0.7350\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4092 - acc: 0.8039 - val_loss: 0.5786 - val_acc: 0.7669\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3981 - acc: 0.8257 - val_loss: 0.6204 - val_acc: 0.7397\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3639 - acc: 0.8517 - val_loss: 0.5631 - val_acc: 0.7788\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3097 - acc: 0.8890 - val_loss: 0.5926 - val_acc: 0.8202\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2400 - acc: 0.9157 - val_loss: 0.5105 - val_acc: 0.8599\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2123 - acc: 0.9245 - val_loss: 0.5376 - val_acc: 0.8507\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1952 - acc: 0.9294 - val_loss: 1.2695 - val_acc: 0.7075\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1995 - acc: 0.9263 - val_loss: 0.4817 - val_acc: 0.8653\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1848 - acc: 0.9365 - val_loss: 0.5507 - val_acc: 0.8507\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1594 - acc: 0.9396 - val_loss: 0.4650 - val_acc: 0.8721\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1782 - acc: 0.9349 - val_loss: 0.4027 - val_acc: 0.8697\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1526 - acc: 0.9412 - val_loss: 0.3964 - val_acc: 0.8829\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1691 - acc: 0.9402 - val_loss: 0.5116 - val_acc: 0.7676\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1518 - acc: 0.9431 - val_loss: 0.4806 - val_acc: 0.8609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1413 - acc: 0.9459 - val_loss: 0.4071 - val_acc: 0.8880\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1415 - acc: 0.9469 - val_loss: 0.5049 - val_acc: 0.8670\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1397 - acc: 0.9510 - val_loss: 0.6541 - val_acc: 0.8537\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 66s 14ms/step - loss: 1.2896 - acc: 0.4379 - val_loss: 1.5527 - val_acc: 0.3709\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1222 - acc: 0.4932 - val_loss: 1.5657 - val_acc: 0.3841\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.9537 - acc: 0.5713 - val_loss: 1.4819 - val_acc: 0.4079\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7749 - acc: 0.6491 - val_loss: 0.8665 - val_acc: 0.6627\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7553 - acc: 0.6542 - val_loss: 0.9890 - val_acc: 0.6240\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6631 - acc: 0.7001 - val_loss: 0.8632 - val_acc: 0.6603\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7433 - acc: 0.6870 - val_loss: 0.8475 - val_acc: 0.6963\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6121 - acc: 0.7205 - val_loss: 0.8111 - val_acc: 0.6831\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5068 - acc: 0.7631 - val_loss: 0.6771 - val_acc: 0.7187\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4802 - acc: 0.7729 - val_loss: 0.6844 - val_acc: 0.7404\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3787 - acc: 0.8111 - val_loss: 0.6881 - val_acc: 0.7506\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 43s 9ms/step - loss: 0.3496 - acc: 0.8572 - val_loss: 0.5777 - val_acc: 0.7703\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3090 - acc: 0.8992 - val_loss: 0.4946 - val_acc: 0.8585\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2430 - acc: 0.9194 - val_loss: 0.5441 - val_acc: 0.8337\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1833 - acc: 0.9398 - val_loss: 0.8292 - val_acc: 0.7781\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1605 - acc: 0.9416 - val_loss: 0.5367 - val_acc: 0.8663\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1417 - acc: 0.9457 - val_loss: 0.5117 - val_acc: 0.8704\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1442 - acc: 0.9467 - val_loss: 0.5717 - val_acc: 0.8514\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1289 - acc: 0.9533 - val_loss: 0.5324 - val_acc: 0.8643\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1480 - acc: 0.9441 - val_loss: 0.4631 - val_acc: 0.8907\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1237 - acc: 0.9535 - val_loss: 0.4452 - val_acc: 0.8938\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1260 - acc: 0.9525 - val_loss: 0.4900 - val_acc: 0.8935\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1214 - acc: 0.9512 - val_loss: 0.5443 - val_acc: 0.8901\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1139 - acc: 0.9574 - val_loss: 0.5642 - val_acc: 0.8829\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1079 - acc: 0.9561 - val_loss: 0.5377 - val_acc: 0.8935\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1099 - acc: 0.9539 - val_loss: 0.7571 - val_acc: 0.8690\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1106 - acc: 0.9576 - val_loss: 0.5641 - val_acc: 0.8992\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1038 - acc: 0.9567 - val_loss: 0.5914 - val_acc: 0.8833\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.0970 - acc: 0.9600 - val_loss: 0.7888 - val_acc: 0.8375\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1038 - acc: 0.9586 - val_loss: 0.6192 - val_acc: 0.8738\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 67s 14ms/step - loss: 1.3526 - acc: 0.3870 - val_loss: 1.3319 - val_acc: 0.3624\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.1510 - acc: 0.4943 - val_loss: 1.6187 - val_acc: 0.3743\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.9287 - acc: 0.5759 - val_loss: 0.9511 - val_acc: 0.6244\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.8322 - acc: 0.6342 - val_loss: 0.8348 - val_acc: 0.6485\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7095 - acc: 0.6865 - val_loss: 0.8140 - val_acc: 0.6651\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6036 - acc: 0.7289 - val_loss: 1.1489 - val_acc: 0.6033\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5702 - acc: 0.7381 - val_loss: 1.0907 - val_acc: 0.6335\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5180 - acc: 0.7487 - val_loss: 1.1234 - val_acc: 0.5826\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4987 - acc: 0.7648 - val_loss: 0.6154 - val_acc: 0.7441\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4438 - acc: 0.7801 - val_loss: 0.5898 - val_acc: 0.7496\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4111 - acc: 0.8058 - val_loss: 0.5608 - val_acc: 0.7998\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3780 - acc: 0.8629 - val_loss: 0.9096 - val_acc: 0.6926\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5160 - acc: 0.8170 - val_loss: 0.5717 - val_acc: 0.8212\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3306 - acc: 0.8815 - val_loss: 0.7049 - val_acc: 0.8008\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2481 - acc: 0.9135 - val_loss: 0.5945 - val_acc: 0.8554\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2462 - acc: 0.9200 - val_loss: 0.6445 - val_acc: 0.8259\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1982 - acc: 0.9274 - val_loss: 0.6755 - val_acc: 0.8239\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1852 - acc: 0.9284 - val_loss: 0.5201 - val_acc: 0.8680\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1833 - acc: 0.9359 - val_loss: 0.5046 - val_acc: 0.8734\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1862 - acc: 0.9343 - val_loss: 0.4778 - val_acc: 0.8683\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1674 - acc: 0.9376 - val_loss: 0.5224 - val_acc: 0.8670\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1671 - acc: 0.9347 - val_loss: 0.6084 - val_acc: 0.8619\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1644 - acc: 0.9380 - val_loss: 0.3551 - val_acc: 0.8887\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1332 - acc: 0.9449 - val_loss: 0.4262 - val_acc: 0.8880\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1437 - acc: 0.9417 - val_loss: 0.4623 - val_acc: 0.8823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1314 - acc: 0.9429 - val_loss: 0.5424 - val_acc: 0.8626\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1395 - acc: 0.9447 - val_loss: 0.4796 - val_acc: 0.8884\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1323 - acc: 0.9457 - val_loss: 0.4364 - val_acc: 0.8819\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1189 - acc: 0.9466 - val_loss: 0.4580 - val_acc: 0.8924\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1293 - acc: 0.9476 - val_loss: 0.4326 - val_acc: 0.8846\n",
      "2450/2450 [==============================] - 5s 2ms/step\n",
      "4902/4902 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 77s 16ms/step - loss: 1.4429 - acc: 0.3799 - val_loss: 1.3435 - val_acc: 0.3627\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3153 - acc: 0.3918 - val_loss: 1.3261 - val_acc: 0.3627\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2991 - acc: 0.4038 - val_loss: 1.2815 - val_acc: 0.3957\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2556 - acc: 0.4538 - val_loss: 1.3150 - val_acc: 0.4035\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2403 - acc: 0.4409 - val_loss: 1.3209 - val_acc: 0.4398\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1978 - acc: 0.4805 - val_loss: 1.2018 - val_acc: 0.4408\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1280 - acc: 0.4915 - val_loss: 1.3461 - val_acc: 0.4035\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.0573 - acc: 0.4613 - val_loss: 1.0913 - val_acc: 0.4476\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9302 - acc: 0.5228 - val_loss: 1.0039 - val_acc: 0.5626\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.9593 - acc: 0.5756 - val_loss: 1.0421 - val_acc: 0.5809\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9305 - acc: 0.5907 - val_loss: 1.8726 - val_acc: 0.4323\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.0566 - acc: 0.4930 - val_loss: 1.0763 - val_acc: 0.4628\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.8926 - acc: 0.5766 - val_loss: 0.8226 - val_acc: 0.6318\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7859 - acc: 0.6531 - val_loss: 0.8615 - val_acc: 0.5965\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7579 - acc: 0.6511 - val_loss: 0.8298 - val_acc: 0.6033\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7373 - acc: 0.6519 - val_loss: 0.8500 - val_acc: 0.6230\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7041 - acc: 0.6633 - val_loss: 0.7996 - val_acc: 0.6189\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7229 - acc: 0.6593 - val_loss: 0.8348 - val_acc: 0.6176\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6757 - acc: 0.6611 - val_loss: 0.7940 - val_acc: 0.6332\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6593 - acc: 0.6662 - val_loss: 0.8203 - val_acc: 0.6230\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7529 - acc: 0.6431 - val_loss: 0.8518 - val_acc: 0.5989\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.8256 - acc: 0.6233 - val_loss: 0.7833 - val_acc: 0.6532\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6960 - acc: 0.6907 - val_loss: 0.8166 - val_acc: 0.6664\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6608 - acc: 0.7037 - val_loss: 0.6868 - val_acc: 0.6793\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7065 - acc: 0.6803 - val_loss: 0.7577 - val_acc: 0.6522\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6624 - acc: 0.6642 - val_loss: 0.7177 - val_acc: 0.6481\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6855 - acc: 0.6911 - val_loss: 0.6333 - val_acc: 0.7241\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5050 - acc: 0.7770 - val_loss: 0.6220 - val_acc: 0.7333\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5000 - acc: 0.7635 - val_loss: 0.6249 - val_acc: 0.7262\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5005 - acc: 0.7688 - val_loss: 0.6253 - val_acc: 0.7262\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 78s 16ms/step - loss: 1.5440 - acc: 0.3273 - val_loss: 1.4117 - val_acc: 0.3393\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.4002 - acc: 0.3644 - val_loss: 1.4598 - val_acc: 0.2453\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.3412 - acc: 0.3854 - val_loss: 1.4202 - val_acc: 0.3529\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2435 - acc: 0.4348 - val_loss: 1.2768 - val_acc: 0.4164\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2464 - acc: 0.4050 - val_loss: 1.2777 - val_acc: 0.4360\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1346 - acc: 0.4644 - val_loss: 1.1684 - val_acc: 0.4886\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.0821 - acc: 0.5205 - val_loss: 1.1402 - val_acc: 0.4723\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.0180 - acc: 0.5376 - val_loss: 1.4012 - val_acc: 0.3879\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1585 - acc: 0.4640 - val_loss: 1.3111 - val_acc: 0.4279\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9125 - acc: 0.6025 - val_loss: 1.2060 - val_acc: 0.5029\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7588 - acc: 0.6240 - val_loss: 0.8098 - val_acc: 0.6128\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6903 - acc: 0.6527 - val_loss: 0.8167 - val_acc: 0.6060\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6950 - acc: 0.6395 - val_loss: 0.9535 - val_acc: 0.5287\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6549 - acc: 0.6905 - val_loss: 0.7804 - val_acc: 0.6128\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5804 - acc: 0.7417 - val_loss: 0.7464 - val_acc: 0.7350\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5293 - acc: 0.7768 - val_loss: 0.7415 - val_acc: 0.7116\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.4693 - acc: 0.7862 - val_loss: 0.5921 - val_acc: 0.7564\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.4192 - acc: 0.8125 - val_loss: 0.5406 - val_acc: 0.7828\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3462 - acc: 0.8649 - val_loss: 0.5324 - val_acc: 0.8415\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2927 - acc: 0.9141 - val_loss: 0.4875 - val_acc: 0.8459\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2180 - acc: 0.9306 - val_loss: 0.4448 - val_acc: 0.8690\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.2217 - acc: 0.9323 - val_loss: 0.4929 - val_acc: 0.8622\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1727 - acc: 0.9441 - val_loss: 0.4688 - val_acc: 0.8768\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1491 - acc: 0.9480 - val_loss: 0.3796 - val_acc: 0.8935\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1529 - acc: 0.9459 - val_loss: 0.3732 - val_acc: 0.8884\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1422 - acc: 0.9506 - val_loss: 0.4078 - val_acc: 0.8877\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1334 - acc: 0.9498 - val_loss: 0.7019 - val_acc: 0.8622\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2913 - acc: 0.9259 - val_loss: 0.4304 - val_acc: 0.8867\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1570 - acc: 0.9484 - val_loss: 0.5175 - val_acc: 0.8694\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1729 - acc: 0.9412 - val_loss: 0.5687 - val_acc: 0.8595\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 78s 16ms/step - loss: 1.4556 - acc: 0.3674 - val_loss: 1.4563 - val_acc: 0.3359\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3778 - acc: 0.3680 - val_loss: 1.3451 - val_acc: 0.3573\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 54s 11ms/step - loss: 1.3176 - acc: 0.3831 - val_loss: 1.3421 - val_acc: 0.3502\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3269 - acc: 0.3845 - val_loss: 1.3493 - val_acc: 0.3536\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2718 - acc: 0.4286 - val_loss: 1.2981 - val_acc: 0.3926\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2722 - acc: 0.4072 - val_loss: 1.2902 - val_acc: 0.4079\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2339 - acc: 0.4406 - val_loss: 1.2400 - val_acc: 0.4374\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1452 - acc: 0.4700 - val_loss: 1.2539 - val_acc: 0.4265\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1453 - acc: 0.4680 - val_loss: 1.1990 - val_acc: 0.4360\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0756 - acc: 0.4906 - val_loss: 1.2522 - val_acc: 0.4269\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0038 - acc: 0.5486 - val_loss: 1.1723 - val_acc: 0.4757\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3935 - acc: 0.3656 - val_loss: 1.3161 - val_acc: 0.4089\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1730 - acc: 0.4939 - val_loss: 1.1909 - val_acc: 0.5022\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2245 - acc: 0.4755 - val_loss: 1.2757 - val_acc: 0.4469\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0409 - acc: 0.5345 - val_loss: 1.1704 - val_acc: 0.5243\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.8375 - acc: 0.6185 - val_loss: 1.0524 - val_acc: 0.5036\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7480 - acc: 0.6261 - val_loss: 0.9618 - val_acc: 0.6050\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6820 - acc: 0.6728 - val_loss: 0.8639 - val_acc: 0.6485\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6456 - acc: 0.7142 - val_loss: 0.7707 - val_acc: 0.7119\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5692 - acc: 0.7634 - val_loss: 0.8229 - val_acc: 0.6664\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5077 - acc: 0.7699 - val_loss: 0.6790 - val_acc: 0.7109\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4830 - acc: 0.7776 - val_loss: 0.5496 - val_acc: 0.7458\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4352 - acc: 0.7891 - val_loss: 0.6170 - val_acc: 0.7479\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4145 - acc: 0.7925 - val_loss: 0.8238 - val_acc: 0.6882\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3820 - acc: 0.8266 - val_loss: 0.4662 - val_acc: 0.7784\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3283 - acc: 0.8674 - val_loss: 0.4245 - val_acc: 0.8432\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2626 - acc: 0.9096 - val_loss: 0.4067 - val_acc: 0.8721\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.1832 - acc: 0.9335 - val_loss: 0.6992 - val_acc: 0.7991\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.1752 - acc: 0.9327 - val_loss: 0.3495 - val_acc: 0.8887\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.1486 - acc: 0.9415 - val_loss: 0.5555 - val_acc: 0.8317\n",
      "2450/2450 [==============================] - 6s 3ms/step\n",
      "4902/4902 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 97s 20ms/step - loss: 1.4734 - acc: 0.3807 - val_loss: 1.3126 - val_acc: 0.4347\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.2558 - acc: 0.4566 - val_loss: 1.1971 - val_acc: 0.5338\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.0650 - acc: 0.5093 - val_loss: 1.0598 - val_acc: 0.5260\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.8422 - acc: 0.5813 - val_loss: 0.8524 - val_acc: 0.6210\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.7953 - acc: 0.5858 - val_loss: 0.7991 - val_acc: 0.6349\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.7553 - acc: 0.6189 - val_loss: 0.7476 - val_acc: 0.6026\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6941 - acc: 0.6378 - val_loss: 0.9194 - val_acc: 0.5694\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 0.6441 - acc: 0.6529 - val_loss: 0.7018 - val_acc: 0.6278\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6972 - acc: 0.6484 - val_loss: 0.8073 - val_acc: 0.6081\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6156 - acc: 0.6880 - val_loss: 0.8098 - val_acc: 0.6312\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6544 - acc: 0.7076 - val_loss: 0.7996 - val_acc: 0.6383\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6006 - acc: 0.7415 - val_loss: 0.6967 - val_acc: 0.6804\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5689 - acc: 0.7598 - val_loss: 0.7419 - val_acc: 0.7021\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.4953 - acc: 0.8115 - val_loss: 0.6237 - val_acc: 0.7933\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.3654 - acc: 0.8676 - val_loss: 0.5190 - val_acc: 0.8130\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2859 - acc: 0.9031 - val_loss: 0.3978 - val_acc: 0.8853\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2416 - acc: 0.9200 - val_loss: 0.7881 - val_acc: 0.7950\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2003 - acc: 0.9329 - val_loss: 0.4022 - val_acc: 0.8928\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2041 - acc: 0.9304 - val_loss: 0.5007 - val_acc: 0.8626\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1677 - acc: 0.9347 - val_loss: 0.2597 - val_acc: 0.9080\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1656 - acc: 0.9378 - val_loss: 0.3598 - val_acc: 0.8894\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1499 - acc: 0.9437 - val_loss: 0.3029 - val_acc: 0.8962\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1626 - acc: 0.9343 - val_loss: 0.2987 - val_acc: 0.9097\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1420 - acc: 0.9472 - val_loss: 0.3521 - val_acc: 0.8901\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1341 - acc: 0.9504 - val_loss: 0.4418 - val_acc: 0.8918\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1359 - acc: 0.9482 - val_loss: 0.4162 - val_acc: 0.8850\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1561 - acc: 0.9429 - val_loss: 0.3807 - val_acc: 0.8972\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1404 - acc: 0.9445 - val_loss: 0.3692 - val_acc: 0.8938\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1389 - acc: 0.9465 - val_loss: 0.3529 - val_acc: 0.8975\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1223 - acc: 0.9529 - val_loss: 0.4212 - val_acc: 0.8911\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 16s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 94s 19ms/step - loss: 1.4141 - acc: 0.3483 - val_loss: 1.3916 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 71s 15ms/step - loss: 1.3773 - acc: 0.3589 - val_loss: 1.3553 - val_acc: 0.3536\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.2604 - acc: 0.4136 - val_loss: 1.2775 - val_acc: 0.4289\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2177 - acc: 0.4719 - val_loss: 1.2989 - val_acc: 0.4659\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2320 - acc: 0.3987 - val_loss: 1.3798 - val_acc: 0.3217\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.0075 - acc: 0.4454 - val_loss: 1.0269 - val_acc: 0.4299\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.0467 - acc: 0.4789 - val_loss: 1.2120 - val_acc: 0.3498\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8169 - acc: 0.5980 - val_loss: 0.9306 - val_acc: 0.5565\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7686 - acc: 0.6117 - val_loss: 0.9312 - val_acc: 0.5738\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6938 - acc: 0.6544 - val_loss: 0.8876 - val_acc: 0.6010\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6993 - acc: 0.6595 - val_loss: 0.7822 - val_acc: 0.6491\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6683 - acc: 0.6823 - val_loss: 0.8986 - val_acc: 0.6206\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6900 - acc: 0.6846 - val_loss: 0.7519 - val_acc: 0.6264\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6777 - acc: 0.7141 - val_loss: 0.7983 - val_acc: 0.6773\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6146 - acc: 0.7417 - val_loss: 0.8417 - val_acc: 0.6844\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5180 - acc: 0.7892 - val_loss: 0.7672 - val_acc: 0.6943\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.3768 - acc: 0.8566 - val_loss: 0.5750 - val_acc: 0.7805\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2731 - acc: 0.9053 - val_loss: 0.3992 - val_acc: 0.8690\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2313 - acc: 0.9237 - val_loss: 0.4632 - val_acc: 0.8588\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1675 - acc: 0.9372 - val_loss: 0.4266 - val_acc: 0.8741\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1515 - acc: 0.9425 - val_loss: 0.3932 - val_acc: 0.8761\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1386 - acc: 0.9469 - val_loss: 0.4431 - val_acc: 0.8867\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1227 - acc: 0.9547 - val_loss: 0.5297 - val_acc: 0.8646\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1281 - acc: 0.9492 - val_loss: 0.5811 - val_acc: 0.8809\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1258 - acc: 0.9496 - val_loss: 0.4851 - val_acc: 0.8765\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1818 - acc: 0.9374 - val_loss: 0.4341 - val_acc: 0.8945\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1198 - acc: 0.9574 - val_loss: 0.5515 - val_acc: 0.8809\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1204 - acc: 0.9529 - val_loss: 0.4909 - val_acc: 0.8792\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1181 - acc: 0.9547 - val_loss: 0.5789 - val_acc: 0.8839\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1112 - acc: 0.9547 - val_loss: 0.5104 - val_acc: 0.8867\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 94s 19ms/step - loss: 1.3888 - acc: 0.3745 - val_loss: 1.4257 - val_acc: 0.3482\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.3512 - acc: 0.3774 - val_loss: 1.5711 - val_acc: 0.3359\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.4111 - acc: 0.3768 - val_loss: 1.3405 - val_acc: 0.3923\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.1838 - acc: 0.4474 - val_loss: 1.3183 - val_acc: 0.4527\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.9618 - acc: 0.5667 - val_loss: 0.9081 - val_acc: 0.5931\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.8240 - acc: 0.6410 - val_loss: 0.8085 - val_acc: 0.6600\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.7877 - acc: 0.6646 - val_loss: 0.7835 - val_acc: 0.6597\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6070 - acc: 0.7360 - val_loss: 0.7506 - val_acc: 0.7316\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5364 - acc: 0.7721 - val_loss: 0.8912 - val_acc: 0.6566\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.4584 - acc: 0.8227 - val_loss: 0.7616 - val_acc: 0.7438\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.3848 - acc: 0.8570 - val_loss: 0.8242 - val_acc: 0.7750\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.3173 - acc: 0.8902 - val_loss: 0.5946 - val_acc: 0.8198\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2550 - acc: 0.9104 - val_loss: 0.4932 - val_acc: 0.8816\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2424 - acc: 0.9084 - val_loss: 0.5205 - val_acc: 0.8622\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 0.2239 - acc: 0.9176 - val_loss: 0.6404 - val_acc: 0.8568\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.4883 - val_acc: 0.8880\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 70s 14ms/step - loss: 0.1712 - acc: 0.9323 - val_loss: 0.5701 - val_acc: 0.8717\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1654 - acc: 0.9368 - val_loss: 0.4497 - val_acc: 0.8843\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1794 - acc: 0.9329 - val_loss: 0.5405 - val_acc: 0.8731\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1377 - acc: 0.9449 - val_loss: 0.4998 - val_acc: 0.8772\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1398 - acc: 0.9453 - val_loss: 0.3961 - val_acc: 0.9016\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 0.1539 - acc: 0.9455 - val_loss: 0.4664 - val_acc: 0.8792\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 71s 14ms/step - loss: 0.1429 - acc: 0.9431 - val_loss: 0.4247 - val_acc: 0.9108\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 0.1193 - acc: 0.9476 - val_loss: 0.4641 - val_acc: 0.9125\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1485 - acc: 0.9447 - val_loss: 0.4382 - val_acc: 0.9097\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1106 - acc: 0.9496 - val_loss: 0.4958 - val_acc: 0.8945\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1249 - acc: 0.9506 - val_loss: 0.4576 - val_acc: 0.9131\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1295 - acc: 0.9510 - val_loss: 0.4327 - val_acc: 0.9131\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1153 - acc: 0.9494 - val_loss: 0.4517 - val_acc: 0.8921\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 0.1128 - acc: 0.9529 - val_loss: 0.6977 - val_acc: 0.8459\n",
      "2450/2450 [==============================] - 8s 3ms/step\n",
      "4902/4902 [==============================] - 16s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 57s 12ms/step - loss: 1.4689 - acc: 0.3836 - val_loss: 1.3901 - val_acc: 0.3448\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2775 - acc: 0.3942 - val_loss: 1.2034 - val_acc: 0.3536\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0904 - acc: 0.4932 - val_loss: 1.1609 - val_acc: 0.4744\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9999 - acc: 0.5113 - val_loss: 0.9280 - val_acc: 0.5080\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8056 - acc: 0.6019 - val_loss: 0.8194 - val_acc: 0.5993\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7519 - acc: 0.6317 - val_loss: 0.7716 - val_acc: 0.6074\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7578 - acc: 0.6215 - val_loss: 0.8429 - val_acc: 0.6043\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7216 - acc: 0.6429 - val_loss: 0.9639 - val_acc: 0.5619\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6884 - acc: 0.6501 - val_loss: 0.9850 - val_acc: 0.5962\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8229 - acc: 0.5999 - val_loss: 1.0124 - val_acc: 0.5324\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7772 - acc: 0.6205 - val_loss: 0.8911 - val_acc: 0.5938\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6547 - acc: 0.6533 - val_loss: 0.9220 - val_acc: 0.6013\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6613 - acc: 0.6560 - val_loss: 0.8710 - val_acc: 0.6108\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6898 - acc: 0.6503 - val_loss: 0.9264 - val_acc: 0.5962\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6590 - acc: 0.6597 - val_loss: 0.9026 - val_acc: 0.5952\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6305 - acc: 0.6723 - val_loss: 1.2371 - val_acc: 0.5517\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5870 - acc: 0.6782 - val_loss: 0.7425 - val_acc: 0.5948\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5332 - acc: 0.6872 - val_loss: 0.6609 - val_acc: 0.6322\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5182 - acc: 0.7135 - val_loss: 0.6589 - val_acc: 0.7116\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5175 - acc: 0.7596 - val_loss: 1.2454 - val_acc: 0.6468\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4699 - acc: 0.7909 - val_loss: 0.9399 - val_acc: 0.6790\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4545 - acc: 0.7862 - val_loss: 0.6778 - val_acc: 0.7333\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3911 - acc: 0.8066 - val_loss: 0.7279 - val_acc: 0.7143\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4083 - acc: 0.8037 - val_loss: 0.7254 - val_acc: 0.7173\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3766 - acc: 0.8076 - val_loss: 0.6608 - val_acc: 0.7268\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4240 - acc: 0.8135 - val_loss: 0.7142 - val_acc: 0.7642\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3467 - acc: 0.8615 - val_loss: 0.6613 - val_acc: 0.7408\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3057 - acc: 0.8972 - val_loss: 0.5957 - val_acc: 0.8225\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2866 - acc: 0.9051 - val_loss: 0.5837 - val_acc: 0.8432\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4394 - acc: 0.8731 - val_loss: 0.5505 - val_acc: 0.8456\n",
      "2451/2451 [==============================] - 3s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 58s 12ms/step - loss: 1.4903 - acc: 0.3542 - val_loss: 1.4082 - val_acc: 0.3539\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2848 - acc: 0.4291 - val_loss: 1.3537 - val_acc: 0.4299\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1676 - acc: 0.4664 - val_loss: 1.1782 - val_acc: 0.4313\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0373 - acc: 0.5107 - val_loss: 1.1763 - val_acc: 0.4849\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1925 - acc: 0.4420 - val_loss: 1.3001 - val_acc: 0.3926\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1497 - acc: 0.4734 - val_loss: 1.1476 - val_acc: 0.4808\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9949 - acc: 0.5599 - val_loss: 1.0469 - val_acc: 0.4910\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8768 - acc: 0.6074 - val_loss: 1.1246 - val_acc: 0.4954\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7678 - acc: 0.6350 - val_loss: 0.8002 - val_acc: 0.6644\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8616 - acc: 0.6231 - val_loss: 0.8051 - val_acc: 0.6807\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6768 - acc: 0.7127 - val_loss: 0.7552 - val_acc: 0.7031\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5712 - acc: 0.7592 - val_loss: 0.6594 - val_acc: 0.7292\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5799 - acc: 0.7521 - val_loss: 0.7672 - val_acc: 0.6824\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4874 - acc: 0.7798 - val_loss: 0.5762 - val_acc: 0.7499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4309 - acc: 0.7915 - val_loss: 0.6171 - val_acc: 0.7499\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4324 - acc: 0.7956 - val_loss: 0.7450 - val_acc: 0.7170\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4480 - acc: 0.7868 - val_loss: 0.5712 - val_acc: 0.7540\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4088 - acc: 0.7945 - val_loss: 0.5725 - val_acc: 0.7523\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3699 - acc: 0.8062 - val_loss: 0.5723 - val_acc: 0.7628\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3610 - acc: 0.8135 - val_loss: 0.5469 - val_acc: 0.7584\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4098 - acc: 0.8255 - val_loss: 0.9344 - val_acc: 0.7615\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3864 - acc: 0.8596 - val_loss: 0.5072 - val_acc: 0.8653\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2457 - acc: 0.9255 - val_loss: 0.4540 - val_acc: 0.8578\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2189 - acc: 0.9333 - val_loss: 0.4357 - val_acc: 0.8846\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2008 - acc: 0.9433 - val_loss: 0.4184 - val_acc: 0.8870\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1570 - acc: 0.9469 - val_loss: 0.4473 - val_acc: 0.8806\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2020 - acc: 0.9484 - val_loss: 0.4504 - val_acc: 0.8792\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1473 - acc: 0.9504 - val_loss: 0.4344 - val_acc: 0.8761\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1473 - acc: 0.9504 - val_loss: 0.4792 - val_acc: 0.8711\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1296 - acc: 0.9574 - val_loss: 0.5398 - val_acc: 0.8721\n",
      "2451/2451 [==============================] - 3s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 58s 12ms/step - loss: 1.4681 - acc: 0.3427 - val_loss: 1.4796 - val_acc: 0.3258\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.3282 - acc: 0.3588 - val_loss: 1.4020 - val_acc: 0.3332\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2212 - acc: 0.4445 - val_loss: 1.2161 - val_acc: 0.4608\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.0404 - acc: 0.5310 - val_loss: 1.3277 - val_acc: 0.4231\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.0059 - acc: 0.5502 - val_loss: 1.2030 - val_acc: 0.4740\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9419 - acc: 0.5769 - val_loss: 0.9244 - val_acc: 0.5741\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8142 - acc: 0.6242 - val_loss: 0.9047 - val_acc: 0.5982\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7359 - acc: 0.6316 - val_loss: 1.0103 - val_acc: 0.5287\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7074 - acc: 0.6469 - val_loss: 0.8156 - val_acc: 0.5959\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6653 - acc: 0.6675 - val_loss: 0.8590 - val_acc: 0.6108\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5919 - acc: 0.6942 - val_loss: 0.6994 - val_acc: 0.6681\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5591 - acc: 0.7203 - val_loss: 0.7778 - val_acc: 0.6909\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5945 - acc: 0.7370 - val_loss: 0.9172 - val_acc: 0.5942\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5184 - acc: 0.7752 - val_loss: 0.7778 - val_acc: 0.7197\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5104 - acc: 0.7809 - val_loss: 0.5484 - val_acc: 0.7428\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4335 - acc: 0.7923 - val_loss: 0.5674 - val_acc: 0.7421\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4061 - acc: 0.7958 - val_loss: 0.5521 - val_acc: 0.7482\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3620 - acc: 0.8015 - val_loss: 0.5142 - val_acc: 0.7408\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3542 - acc: 0.8005 - val_loss: 0.4902 - val_acc: 0.7499\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3516 - acc: 0.8027 - val_loss: 0.4627 - val_acc: 0.7564\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3237 - acc: 0.8248 - val_loss: 0.5816 - val_acc: 0.7350\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3472 - acc: 0.8201 - val_loss: 0.6224 - val_acc: 0.7231\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2983 - acc: 0.8525 - val_loss: 0.4401 - val_acc: 0.8402\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3164 - acc: 0.8839 - val_loss: 1.1973 - val_acc: 0.7136\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4617 - acc: 0.8470 - val_loss: 0.4840 - val_acc: 0.8768\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2912 - acc: 0.9096 - val_loss: 0.5210 - val_acc: 0.8772\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2218 - acc: 0.9333 - val_loss: 0.3799 - val_acc: 0.8911\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1723 - acc: 0.9386 - val_loss: 0.4631 - val_acc: 0.8782\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1948 - acc: 0.9361 - val_loss: 0.4468 - val_acc: 0.8616\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1710 - acc: 0.9382 - val_loss: 0.4485 - val_acc: 0.8989\n",
      "2450/2450 [==============================] - 3s 1ms/step\n",
      "4902/4902 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.4140 - acc: 0.4024 - val_loss: 1.2663 - val_acc: 0.4262\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1806 - acc: 0.4766 - val_loss: 1.3331 - val_acc: 0.4102\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 1.0185 - acc: 0.5546 - val_loss: 1.2200 - val_acc: 0.4320\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8273 - acc: 0.6229 - val_loss: 1.0113 - val_acc: 0.5294\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7445 - acc: 0.6286 - val_loss: 0.7881 - val_acc: 0.6413\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6826 - acc: 0.6601 - val_loss: 0.6946 - val_acc: 0.6814\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6442 - acc: 0.6909 - val_loss: 0.7161 - val_acc: 0.6495\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5992 - acc: 0.7341 - val_loss: 0.5745 - val_acc: 0.7553\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5276 - acc: 0.7968 - val_loss: 0.6064 - val_acc: 0.7662\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4330 - acc: 0.8404 - val_loss: 0.5562 - val_acc: 0.8073\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3738 - acc: 0.8725 - val_loss: 0.5016 - val_acc: 0.8276\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3507 - acc: 0.8778 - val_loss: 0.4520 - val_acc: 0.8626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2844 - acc: 0.9063 - val_loss: 0.4229 - val_acc: 0.8700\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2671 - acc: 0.9123 - val_loss: 0.3154 - val_acc: 0.8924\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2383 - acc: 0.9235 - val_loss: 0.3492 - val_acc: 0.8799\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2102 - acc: 0.9270 - val_loss: 0.4374 - val_acc: 0.8707\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2126 - acc: 0.9249 - val_loss: 0.4424 - val_acc: 0.8327\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2091 - acc: 0.9251 - val_loss: 0.3752 - val_acc: 0.8962\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1988 - acc: 0.9333 - val_loss: 0.4095 - val_acc: 0.8714\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1850 - acc: 0.9355 - val_loss: 0.4458 - val_acc: 0.8558\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1840 - acc: 0.9355 - val_loss: 0.4562 - val_acc: 0.8219\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1857 - acc: 0.9353 - val_loss: 0.3163 - val_acc: 0.9006\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1786 - acc: 0.9341 - val_loss: 0.3262 - val_acc: 0.9016\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1814 - acc: 0.9343 - val_loss: 0.5380 - val_acc: 0.8602\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1856 - acc: 0.9339 - val_loss: 0.3953 - val_acc: 0.8979\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1573 - acc: 0.9398 - val_loss: 0.3598 - val_acc: 0.9097\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1501 - acc: 0.9412 - val_loss: 0.3953 - val_acc: 0.8968\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1398 - acc: 0.9443 - val_loss: 0.4144 - val_acc: 0.9040\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1445 - acc: 0.9441 - val_loss: 0.4893 - val_acc: 0.8904\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1634 - acc: 0.9445 - val_loss: 0.3791 - val_acc: 0.8867\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.4124 - acc: 0.3946 - val_loss: 1.3658 - val_acc: 0.3919\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.2301 - acc: 0.4460 - val_loss: 1.2384 - val_acc: 0.4432\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1745 - acc: 0.4754 - val_loss: 1.5249 - val_acc: 0.3071\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.0689 - acc: 0.5272 - val_loss: 1.8897 - val_acc: 0.4326\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8322 - acc: 0.6276 - val_loss: 0.9327 - val_acc: 0.6237\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7209 - acc: 0.6984 - val_loss: 0.7646 - val_acc: 0.7163\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5927 - acc: 0.7490 - val_loss: 0.7000 - val_acc: 0.7251\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5469 - acc: 0.7596 - val_loss: 0.7003 - val_acc: 0.6888\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5134 - acc: 0.7641 - val_loss: 0.6408 - val_acc: 0.7309\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4915 - acc: 0.7747 - val_loss: 0.6148 - val_acc: 0.7418\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4299 - acc: 0.7813 - val_loss: 0.6003 - val_acc: 0.7346\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4031 - acc: 0.7917 - val_loss: 0.5623 - val_acc: 0.7560\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3840 - acc: 0.7966 - val_loss: 0.8582 - val_acc: 0.6746\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3761 - acc: 0.8115 - val_loss: 0.5735 - val_acc: 0.7424\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3604 - acc: 0.8194 - val_loss: 0.6564 - val_acc: 0.7503\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3554 - acc: 0.8345 - val_loss: 0.6089 - val_acc: 0.7849\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2946 - acc: 0.8953 - val_loss: 0.5615 - val_acc: 0.8239\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2159 - acc: 0.9276 - val_loss: 0.4657 - val_acc: 0.8436\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1795 - acc: 0.9374 - val_loss: 0.8672 - val_acc: 0.7913\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1848 - acc: 0.9367 - val_loss: 0.5638 - val_acc: 0.8690\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1852 - acc: 0.9347 - val_loss: 0.7518 - val_acc: 0.7737\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1378 - acc: 0.9486 - val_loss: 0.4920 - val_acc: 0.8758\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1370 - acc: 0.9463 - val_loss: 0.4395 - val_acc: 0.8819\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1469 - acc: 0.9453 - val_loss: 0.4826 - val_acc: 0.8897\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1314 - acc: 0.9525 - val_loss: 0.4505 - val_acc: 0.8955\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1408 - acc: 0.9496 - val_loss: 0.6774 - val_acc: 0.8656\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1246 - acc: 0.9529 - val_loss: 0.5880 - val_acc: 0.8853\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1234 - acc: 0.9553 - val_loss: 0.5157 - val_acc: 0.8887\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1138 - acc: 0.9537 - val_loss: 0.5879 - val_acc: 0.8907\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1225 - acc: 0.9533 - val_loss: 0.5334 - val_acc: 0.8911\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 1.3691 - acc: 0.3845 - val_loss: 1.3071 - val_acc: 0.4109\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.1833 - acc: 0.4629 - val_loss: 1.7584 - val_acc: 0.2698\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.0613 - acc: 0.5029 - val_loss: 1.1901 - val_acc: 0.4561\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.9749 - acc: 0.5422 - val_loss: 1.5488 - val_acc: 0.4187\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.2999 - acc: 0.4094 - val_loss: 1.4134 - val_acc: 0.3648\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.2482 - acc: 0.4221 - val_loss: 1.0161 - val_acc: 0.5572\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.8457 - acc: 0.5908 - val_loss: 0.8675 - val_acc: 0.5222\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7047 - acc: 0.6442 - val_loss: 0.7423 - val_acc: 0.6763\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6346 - acc: 0.7111 - val_loss: 0.9354 - val_acc: 0.6410\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5567 - acc: 0.7509 - val_loss: 0.7986 - val_acc: 0.6725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5146 - acc: 0.7574 - val_loss: 0.6628 - val_acc: 0.7234\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4754 - acc: 0.7778 - val_loss: 0.9321 - val_acc: 0.6651\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4218 - acc: 0.7885 - val_loss: 0.5861 - val_acc: 0.7329\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4098 - acc: 0.8072 - val_loss: 0.9602 - val_acc: 0.7106\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3728 - acc: 0.8437 - val_loss: 0.7288 - val_acc: 0.7662\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3409 - acc: 0.8752 - val_loss: 0.5372 - val_acc: 0.7788\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3139 - acc: 0.8868 - val_loss: 0.5227 - val_acc: 0.8439\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.3042 - acc: 0.8935 - val_loss: 0.5197 - val_acc: 0.8331\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2248 - acc: 0.9168 - val_loss: 0.4238 - val_acc: 0.8690\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2059 - acc: 0.9284 - val_loss: 0.4780 - val_acc: 0.8741\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2132 - acc: 0.9198 - val_loss: 0.4859 - val_acc: 0.8714\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1739 - acc: 0.9347 - val_loss: 0.5009 - val_acc: 0.8717\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1551 - acc: 0.9400 - val_loss: 0.4532 - val_acc: 0.8717\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1534 - acc: 0.9429 - val_loss: 0.4807 - val_acc: 0.8755\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1531 - acc: 0.9408 - val_loss: 0.4138 - val_acc: 0.8884\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1771 - acc: 0.9308 - val_loss: 0.3702 - val_acc: 0.8914\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1440 - acc: 0.9427 - val_loss: 0.4034 - val_acc: 0.8839\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1323 - acc: 0.9461 - val_loss: 0.3825 - val_acc: 0.9006\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1302 - acc: 0.9435 - val_loss: 0.5038 - val_acc: 0.8863\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1324 - acc: 0.9459 - val_loss: 0.4507 - val_acc: 0.8931\n",
      "2450/2450 [==============================] - 5s 2ms/step\n",
      "4902/4902 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 81s 16ms/step - loss: 1.5286 - acc: 0.3452 - val_loss: 1.4119 - val_acc: 0.3488\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3402 - acc: 0.4083 - val_loss: 1.5801 - val_acc: 0.1988\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3658 - acc: 0.3693 - val_loss: 1.3242 - val_acc: 0.3631\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2792 - acc: 0.4144 - val_loss: 1.2365 - val_acc: 0.4740\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1583 - acc: 0.4905 - val_loss: 1.1116 - val_acc: 0.5558\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9819 - acc: 0.6003 - val_loss: 0.9179 - val_acc: 0.5735\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9823 - acc: 0.5683 - val_loss: 0.9154 - val_acc: 0.5945\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8567 - acc: 0.6133 - val_loss: 1.6443 - val_acc: 0.3980\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9395 - acc: 0.5729 - val_loss: 0.8400 - val_acc: 0.5843\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7059 - acc: 0.6529 - val_loss: 0.8526 - val_acc: 0.6033\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7097 - acc: 0.6566 - val_loss: 0.8562 - val_acc: 0.6054\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7110 - acc: 0.6509 - val_loss: 0.7954 - val_acc: 0.5976\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7056 - acc: 0.6523 - val_loss: 1.0069 - val_acc: 0.5898\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6984 - acc: 0.6556 - val_loss: 1.1545 - val_acc: 0.5226\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6856 - acc: 0.6448 - val_loss: 1.0266 - val_acc: 0.5714\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6661 - acc: 0.6403 - val_loss: 0.7580 - val_acc: 0.6128\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6437 - acc: 0.6431 - val_loss: 1.4209 - val_acc: 0.4588\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 59s 12ms/step - loss: 0.5764 - acc: 0.6572 - val_loss: 0.7260 - val_acc: 0.6152\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5614 - acc: 0.6572 - val_loss: 0.7704 - val_acc: 0.6094\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5693 - acc: 0.6658 - val_loss: 0.6494 - val_acc: 0.6060\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5446 - acc: 0.6572 - val_loss: 0.6107 - val_acc: 0.6403\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4811 - acc: 0.7154 - val_loss: 0.5297 - val_acc: 0.7313\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4147 - acc: 0.7953 - val_loss: 0.5107 - val_acc: 0.7275\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3616 - acc: 0.8019 - val_loss: 0.5336 - val_acc: 0.7292\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3236 - acc: 0.8376 - val_loss: 0.4851 - val_acc: 0.8147\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2875 - acc: 0.9072 - val_loss: 0.5190 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2264 - acc: 0.9306 - val_loss: 0.4168 - val_acc: 0.8605\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2028 - acc: 0.9310 - val_loss: 0.3265 - val_acc: 0.8873\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2007 - acc: 0.9353 - val_loss: 0.3469 - val_acc: 0.8768\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1772 - acc: 0.9363 - val_loss: 0.4184 - val_acc: 0.8741\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 81s 17ms/step - loss: 1.4891 - acc: 0.3499 - val_loss: 1.3991 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3273 - acc: 0.3685 - val_loss: 1.3892 - val_acc: 0.3397\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3431 - acc: 0.3609 - val_loss: 1.3984 - val_acc: 0.3624\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2917 - acc: 0.4124 - val_loss: 1.3211 - val_acc: 0.3980\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2144 - acc: 0.4407 - val_loss: 1.2721 - val_acc: 0.4425\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2873 - acc: 0.4301 - val_loss: 1.3633 - val_acc: 0.3929\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1852 - acc: 0.4460 - val_loss: 1.2577 - val_acc: 0.4567\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1289 - acc: 0.4815 - val_loss: 1.2343 - val_acc: 0.4557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1953 - acc: 0.4538 - val_loss: 1.2515 - val_acc: 0.4432\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9424 - acc: 0.5715 - val_loss: 1.9176 - val_acc: 0.4072\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9485 - acc: 0.5658 - val_loss: 0.9397 - val_acc: 0.5572\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8150 - acc: 0.6242 - val_loss: 0.8724 - val_acc: 0.6050\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7170 - acc: 0.6539 - val_loss: 0.9237 - val_acc: 0.6010\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8673 - acc: 0.6154 - val_loss: 0.8108 - val_acc: 0.6664\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8705 - acc: 0.6048 - val_loss: 0.9372 - val_acc: 0.5860\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8723 - acc: 0.6215 - val_loss: 0.8447 - val_acc: 0.6349\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8619 - acc: 0.5929 - val_loss: 0.9587 - val_acc: 0.6101\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6819 - acc: 0.6760 - val_loss: 0.8433 - val_acc: 0.6444\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6491 - acc: 0.6933 - val_loss: 0.7488 - val_acc: 0.6746\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6187 - acc: 0.7145 - val_loss: 0.7337 - val_acc: 0.6936\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7272 - acc: 0.6660 - val_loss: 0.8339 - val_acc: 0.6736\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6205 - acc: 0.7196 - val_loss: 0.6719 - val_acc: 0.7112\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5804 - acc: 0.7337 - val_loss: 0.6923 - val_acc: 0.7156\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5655 - acc: 0.7578 - val_loss: 1.0236 - val_acc: 0.6790\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.6300 - acc: 0.7239 - val_loss: 0.7756 - val_acc: 0.7082\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.5362 - acc: 0.7649 - val_loss: 1.0358 - val_acc: 0.6227\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4721 - acc: 0.7825 - val_loss: 0.7624 - val_acc: 0.7336\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5028 - acc: 0.7705 - val_loss: 0.7751 - val_acc: 0.7041\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3862 - acc: 0.8394 - val_loss: 0.5970 - val_acc: 0.8656\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.2956 - acc: 0.9159 - val_loss: 0.4536 - val_acc: 0.8653\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 81s 17ms/step - loss: 1.4898 - acc: 0.3650 - val_loss: 1.4503 - val_acc: 0.3403\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3696 - acc: 0.3713 - val_loss: 1.3738 - val_acc: 0.3495\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.4161 - acc: 0.3609 - val_loss: 1.3617 - val_acc: 0.3573\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3983 - acc: 0.3709 - val_loss: 1.3188 - val_acc: 0.4123\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2791 - acc: 0.4380 - val_loss: 1.2768 - val_acc: 0.4347\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3959 - acc: 0.3803 - val_loss: 1.3567 - val_acc: 0.3885\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3680 - acc: 0.4072 - val_loss: 1.4428 - val_acc: 0.3661\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3287 - acc: 0.4092 - val_loss: 1.5438 - val_acc: 0.3047\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2848 - acc: 0.4206 - val_loss: 1.2558 - val_acc: 0.4184\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 54s 11ms/step - loss: 1.2217 - acc: 0.4353 - val_loss: 1.4223 - val_acc: 0.3251\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1752 - acc: 0.4580 - val_loss: 1.3550 - val_acc: 0.4048\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0888 - acc: 0.4604 - val_loss: 1.5929 - val_acc: 0.2606\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.9851 - acc: 0.5098 - val_loss: 0.9769 - val_acc: 0.5239\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 54s 11ms/step - loss: 0.8418 - acc: 0.6251 - val_loss: 0.9409 - val_acc: 0.6016\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7897 - acc: 0.6218 - val_loss: 0.8665 - val_acc: 0.6071\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7255 - acc: 0.6387 - val_loss: 1.1862 - val_acc: 0.4961\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 54s 11ms/step - loss: 0.8094 - acc: 0.6120 - val_loss: 0.7719 - val_acc: 0.6186\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7182 - acc: 0.6371 - val_loss: 0.6995 - val_acc: 0.6362\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6653 - acc: 0.6563 - val_loss: 0.9116 - val_acc: 0.5993\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6196 - acc: 0.6763 - val_loss: 0.6521 - val_acc: 0.6573\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5528 - acc: 0.7236 - val_loss: 0.6771 - val_acc: 0.7109\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5114 - acc: 0.7829 - val_loss: 0.9537 - val_acc: 0.6525\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4314 - acc: 0.8119 - val_loss: 0.5007 - val_acc: 0.8229\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3781 - acc: 0.8656 - val_loss: 0.5417 - val_acc: 0.8314\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6216 - acc: 0.7319 - val_loss: 0.7149 - val_acc: 0.7866\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2706 - acc: 0.9115 - val_loss: 0.7072 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2910 - acc: 0.9037 - val_loss: 0.4331 - val_acc: 0.8765\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2487 - acc: 0.9135 - val_loss: 0.5469 - val_acc: 0.8507\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.1887 - acc: 0.9376 - val_loss: 0.5405 - val_acc: 0.8683\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2114 - acc: 0.9294 - val_loss: 0.6742 - val_acc: 0.8314\n",
      "2450/2450 [==============================] - 7s 3ms/step\n",
      "4902/4902 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 95s 19ms/step - loss: 1.4059 - acc: 0.3709 - val_loss: 1.4867 - val_acc: 0.3210\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2902 - acc: 0.3918 - val_loss: 1.7249 - val_acc: 0.2759\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2896 - acc: 0.3942 - val_loss: 1.4433 - val_acc: 0.3315\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.2835 - acc: 0.3938 - val_loss: 1.2944 - val_acc: 0.3848\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.3878 - acc: 0.4142 - val_loss: 1.2765 - val_acc: 0.4191\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.2739 - acc: 0.4285 - val_loss: 1.3274 - val_acc: 0.3570\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2943 - acc: 0.4097 - val_loss: 1.2377 - val_acc: 0.4513\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.1620 - acc: 0.4770 - val_loss: 1.2839 - val_acc: 0.4119\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.1394 - acc: 0.4948 - val_loss: 1.2401 - val_acc: 0.4499\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.0991 - acc: 0.4997 - val_loss: 1.2768 - val_acc: 0.4204\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 76s 16ms/step - loss: 1.0791 - acc: 0.4995 - val_loss: 1.1219 - val_acc: 0.4493\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 1.0416 - acc: 0.5036 - val_loss: 1.1146 - val_acc: 0.4557\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 78s 16ms/step - loss: 0.9991 - acc: 0.5154 - val_loss: 1.0543 - val_acc: 0.4696\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.9207 - acc: 0.5982 - val_loss: 0.9117 - val_acc: 0.6091\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 72s 15ms/step - loss: 0.7626 - acc: 0.6460 - val_loss: 0.8845 - val_acc: 0.6216\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7025 - acc: 0.6519 - val_loss: 0.7627 - val_acc: 0.6172\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 76s 15ms/step - loss: 0.6769 - acc: 0.6499 - val_loss: 1.0210 - val_acc: 0.5755\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 75s 15ms/step - loss: 0.6423 - acc: 0.6803 - val_loss: 0.6876 - val_acc: 0.6980\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.7025 - acc: 0.6919 - val_loss: 0.8785 - val_acc: 0.5819\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 75s 15ms/step - loss: 0.6623 - acc: 0.7150 - val_loss: 0.9121 - val_acc: 0.5942\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5544 - acc: 0.7629 - val_loss: 0.6155 - val_acc: 0.7479\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5112 - acc: 0.7692 - val_loss: 0.6884 - val_acc: 0.7642\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.4566 - acc: 0.7953 - val_loss: 0.6068 - val_acc: 0.7662\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.4311 - acc: 0.8151 - val_loss: 0.7543 - val_acc: 0.7116\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.4032 - acc: 0.8525 - val_loss: 0.3825 - val_acc: 0.8734\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.3495 - acc: 0.8821 - val_loss: 0.5319 - val_acc: 0.8134\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2646 - acc: 0.9137 - val_loss: 0.4969 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2690 - acc: 0.9129 - val_loss: 0.5817 - val_acc: 0.8015\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2200 - acc: 0.9235 - val_loss: 0.4165 - val_acc: 0.8819\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1966 - acc: 0.9327 - val_loss: 0.3431 - val_acc: 0.8897\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 95s 19ms/step - loss: 1.4487 - acc: 0.3567 - val_loss: 1.5133 - val_acc: 0.3590\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.2442 - acc: 0.4497 - val_loss: 1.3048 - val_acc: 0.4805\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.0329 - acc: 0.5546 - val_loss: 1.0157 - val_acc: 0.5738\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8813 - acc: 0.6082 - val_loss: 0.8897 - val_acc: 0.5955\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8247 - acc: 0.6209 - val_loss: 0.8791 - val_acc: 0.5982\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7391 - acc: 0.6652 - val_loss: 0.8123 - val_acc: 0.6549\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7316 - acc: 0.6809 - val_loss: 0.9141 - val_acc: 0.6383\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6378 - acc: 0.7127 - val_loss: 0.7117 - val_acc: 0.6966\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5859 - acc: 0.7360 - val_loss: 0.8157 - val_acc: 0.6912\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5308 - acc: 0.7552 - val_loss: 0.7468 - val_acc: 0.7268\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5158 - acc: 0.7600 - val_loss: 0.8744 - val_acc: 0.7160\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5402 - acc: 0.7723 - val_loss: 0.7831 - val_acc: 0.7350\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.4370 - acc: 0.8131 - val_loss: 0.6696 - val_acc: 0.7486\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.3567 - acc: 0.8613 - val_loss: 0.6861 - val_acc: 0.7937\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.2384 - acc: 0.9212 - val_loss: 0.8762 - val_acc: 0.7631\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.2041 - acc: 0.9365 - val_loss: 0.4580 - val_acc: 0.8768\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1681 - acc: 0.9433 - val_loss: 0.4910 - val_acc: 0.8741\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1427 - acc: 0.9486 - val_loss: 0.5210 - val_acc: 0.8812\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1422 - acc: 0.9523 - val_loss: 0.4057 - val_acc: 0.8904\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1473 - acc: 0.9478 - val_loss: 0.5324 - val_acc: 0.8799\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1485 - acc: 0.9467 - val_loss: 0.7597 - val_acc: 0.8398\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 71s 15ms/step - loss: 0.1497 - acc: 0.9472 - val_loss: 0.4256 - val_acc: 0.8836\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1549 - acc: 0.9490 - val_loss: 0.5663 - val_acc: 0.8622\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1382 - acc: 0.9547 - val_loss: 0.4343 - val_acc: 0.8812\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1242 - acc: 0.9518 - val_loss: 0.5399 - val_acc: 0.8846\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1387 - acc: 0.9478 - val_loss: 0.5255 - val_acc: 0.8935\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1276 - acc: 0.9494 - val_loss: 0.4517 - val_acc: 0.8962\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1478 - acc: 0.9500 - val_loss: 0.5007 - val_acc: 0.8789\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1313 - acc: 0.9508 - val_loss: 0.5319 - val_acc: 0.8860\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1226 - acc: 0.9512 - val_loss: 0.5069 - val_acc: 0.8867\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 16s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 96s 20ms/step - loss: 1.4886 - acc: 0.3382 - val_loss: 1.6751 - val_acc: 0.3156\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 1.2192 - acc: 0.4537 - val_loss: 1.2813 - val_acc: 0.4754\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 68s 14ms/step - loss: 1.0146 - acc: 0.5557 - val_loss: 1.1129 - val_acc: 0.5721\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 1.0306 - acc: 0.5082 - val_loss: 1.0704 - val_acc: 0.5300\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.8870 - acc: 0.5955 - val_loss: 0.8990 - val_acc: 0.6115\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.7976 - acc: 0.6230 - val_loss: 0.8354 - val_acc: 0.5925\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.8423 - acc: 0.5985 - val_loss: 1.0473 - val_acc: 0.4886\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.7799 - acc: 0.5904 - val_loss: 0.8221 - val_acc: 0.6288\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.7342 - acc: 0.6499 - val_loss: 0.8145 - val_acc: 0.6478\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.6842 - acc: 0.6573 - val_loss: 0.7992 - val_acc: 0.6427\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.6600 - acc: 0.6705 - val_loss: 0.8799 - val_acc: 0.6485\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.6007 - acc: 0.7144 - val_loss: 0.9202 - val_acc: 0.6440\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5564 - acc: 0.7401 - val_loss: 0.7708 - val_acc: 0.6709\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 71s 14ms/step - loss: 0.5578 - acc: 0.7515 - val_loss: 0.9295 - val_acc: 0.6118\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5051 - acc: 0.7840 - val_loss: 0.7308 - val_acc: 0.7791\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.4554 - acc: 0.8101 - val_loss: 0.8626 - val_acc: 0.7418\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.4203 - acc: 0.8482 - val_loss: 1.9027 - val_acc: 0.5847\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.3502 - acc: 0.8741 - val_loss: 0.6702 - val_acc: 0.8018\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2539 - acc: 0.9106 - val_loss: 0.6228 - val_acc: 0.8280\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2107 - acc: 0.9241 - val_loss: 0.4416 - val_acc: 0.8687\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2318 - acc: 0.9164 - val_loss: 0.5247 - val_acc: 0.8673\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1698 - acc: 0.9339 - val_loss: 0.4215 - val_acc: 0.8873\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 71s 15ms/step - loss: 0.1683 - acc: 0.9394 - val_loss: 0.5358 - val_acc: 0.8700\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1468 - acc: 0.9423 - val_loss: 0.3879 - val_acc: 0.8924\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1624 - acc: 0.9400 - val_loss: 0.3630 - val_acc: 0.8894\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1471 - acc: 0.9441 - val_loss: 0.3500 - val_acc: 0.8778\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1586 - acc: 0.9402 - val_loss: 0.4497 - val_acc: 0.8856\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1516 - acc: 0.9380 - val_loss: 0.5111 - val_acc: 0.8314\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1362 - acc: 0.9429 - val_loss: 0.4239 - val_acc: 0.9070\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1271 - acc: 0.9476 - val_loss: 1.3929 - val_acc: 0.7313\n",
      "2450/2450 [==============================] - 8s 3ms/step\n",
      "4902/4902 [==============================] - 17s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 61s 12ms/step - loss: 1.4728 - acc: 0.3734 - val_loss: 1.4093 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 1.3310 - acc: 0.3964 - val_loss: 1.3367 - val_acc: 0.4086\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2811 - acc: 0.4164 - val_loss: 1.3263 - val_acc: 0.3709\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 1.2354 - acc: 0.4473 - val_loss: 1.1914 - val_acc: 0.4211\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.3176 - acc: 0.4042 - val_loss: 1.1629 - val_acc: 0.4364\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 1.1226 - acc: 0.4440 - val_loss: 1.0645 - val_acc: 0.3695\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9878 - acc: 0.4824 - val_loss: 0.9791 - val_acc: 0.4394\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0080 - acc: 0.5185 - val_loss: 1.2076 - val_acc: 0.5572\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.9068 - acc: 0.5770 - val_loss: 0.9197 - val_acc: 0.5979\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.8796 - acc: 0.6111 - val_loss: 0.9568 - val_acc: 0.6054\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.8185 - acc: 0.6346 - val_loss: 1.0874 - val_acc: 0.5901\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.7732 - acc: 0.6335 - val_loss: 0.8498 - val_acc: 0.6098\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7536 - acc: 0.6325 - val_loss: 0.8275 - val_acc: 0.6172\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.7445 - acc: 0.6360 - val_loss: 0.8243 - val_acc: 0.6023\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.6917 - acc: 0.6564 - val_loss: 0.8020 - val_acc: 0.6098\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6861 - acc: 0.6576 - val_loss: 0.7980 - val_acc: 0.6077\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.7262 - acc: 0.6550 - val_loss: 0.8062 - val_acc: 0.6200\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6839 - acc: 0.6546 - val_loss: 0.8498 - val_acc: 0.6176\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6686 - acc: 0.6633 - val_loss: 0.9117 - val_acc: 0.6094\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9782 - acc: 0.6115 - val_loss: 0.7834 - val_acc: 0.6213\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.6651 - acc: 0.6703 - val_loss: 0.7794 - val_acc: 0.6210\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6403 - acc: 0.6829 - val_loss: 0.7056 - val_acc: 0.6247\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6103 - acc: 0.6784 - val_loss: 1.1992 - val_acc: 0.5175\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.5962 - acc: 0.6897 - val_loss: 1.0454 - val_acc: 0.5948\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5975 - acc: 0.6974 - val_loss: 0.6134 - val_acc: 0.6824\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.5172 - acc: 0.7294 - val_loss: 0.6568 - val_acc: 0.7058\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5226 - acc: 0.7637 - val_loss: 0.7308 - val_acc: 0.7109\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4834 - acc: 0.7890 - val_loss: 0.6548 - val_acc: 0.7255\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 32s 7ms/step - loss: 0.4112 - acc: 0.8306 - val_loss: 0.5434 - val_acc: 0.7587\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4547 - acc: 0.8362 - val_loss: 0.5804 - val_acc: 0.7940\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 62s 13ms/step - loss: 1.4827 - acc: 0.3514 - val_loss: 1.4583 - val_acc: 0.3288\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2759 - acc: 0.4332 - val_loss: 1.3240 - val_acc: 0.4605\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1172 - acc: 0.5313 - val_loss: 1.1519 - val_acc: 0.5165\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9868 - acc: 0.5754 - val_loss: 1.0269 - val_acc: 0.5222\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8988 - acc: 0.6201 - val_loss: 1.0487 - val_acc: 0.5416\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8637 - acc: 0.6223 - val_loss: 0.9136 - val_acc: 0.5694\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8213 - acc: 0.6250 - val_loss: 0.8522 - val_acc: 0.5813\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7738 - acc: 0.6505 - val_loss: 0.8762 - val_acc: 0.5799\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7510 - acc: 0.6754 - val_loss: 0.9730 - val_acc: 0.6220\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8376 - acc: 0.6701 - val_loss: 0.9690 - val_acc: 0.6281\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7067 - acc: 0.7064 - val_loss: 0.8760 - val_acc: 0.6522\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7493 - acc: 0.6935 - val_loss: 1.0533 - val_acc: 0.6081\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6854 - acc: 0.7262 - val_loss: 0.7190 - val_acc: 0.7129\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7102 - acc: 0.7280 - val_loss: 0.7046 - val_acc: 0.7302\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5944 - acc: 0.7643 - val_loss: 0.7208 - val_acc: 0.7082\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5681 - acc: 0.7658 - val_loss: 0.7504 - val_acc: 0.7061\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5130 - acc: 0.7790 - val_loss: 0.6780 - val_acc: 0.7089\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5129 - acc: 0.7709 - val_loss: 0.7178 - val_acc: 0.7245\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4925 - acc: 0.7845 - val_loss: 0.7615 - val_acc: 0.7068\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4631 - acc: 0.7919 - val_loss: 0.8333 - val_acc: 0.6702\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4802 - acc: 0.7794 - val_loss: 0.6849 - val_acc: 0.7265\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5085 - acc: 0.7856 - val_loss: 0.6843 - val_acc: 0.7262\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4338 - acc: 0.8029 - val_loss: 0.7004 - val_acc: 0.7234\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4186 - acc: 0.8029 - val_loss: 0.6555 - val_acc: 0.7360\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4059 - acc: 0.8068 - val_loss: 0.9559 - val_acc: 0.7469\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3991 - acc: 0.8284 - val_loss: 0.6141 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3629 - acc: 0.8321 - val_loss: 0.6034 - val_acc: 0.8219\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3219 - acc: 0.8737 - val_loss: 0.9972 - val_acc: 0.8069\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3061 - acc: 0.9039 - val_loss: 1.2113 - val_acc: 0.7201\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3145 - acc: 0.9135 - val_loss: 0.4987 - val_acc: 0.8748\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 61s 12ms/step - loss: 1.4810 - acc: 0.3390 - val_loss: 1.4438 - val_acc: 0.3610\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.3168 - acc: 0.3800 - val_loss: 1.3414 - val_acc: 0.4126\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.1742 - acc: 0.5031 - val_loss: 1.3497 - val_acc: 0.4113\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2420 - acc: 0.4361 - val_loss: 1.2672 - val_acc: 0.4401\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2106 - acc: 0.4574 - val_loss: 1.5449 - val_acc: 0.3682\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.0747 - acc: 0.5110 - val_loss: 1.0364 - val_acc: 0.5222\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9426 - acc: 0.5661 - val_loss: 0.9409 - val_acc: 0.5806\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8826 - acc: 0.6036 - val_loss: 1.2277 - val_acc: 0.4449\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7805 - acc: 0.6377 - val_loss: 0.9345 - val_acc: 0.5782\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7492 - acc: 0.6348 - val_loss: 0.8679 - val_acc: 0.5799\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 34s 7ms/step - loss: 0.7029 - acc: 0.6516 - val_loss: 0.8027 - val_acc: 0.5758\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6881 - acc: 0.6444 - val_loss: 0.7487 - val_acc: 0.6006\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6624 - acc: 0.6518 - val_loss: 0.8072 - val_acc: 0.5901\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6655 - acc: 0.6426 - val_loss: 0.7794 - val_acc: 0.6094\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6616 - acc: 0.6512 - val_loss: 0.9968 - val_acc: 0.5748\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6256 - acc: 0.6712 - val_loss: 0.8008 - val_acc: 0.6149\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6590 - acc: 0.6526 - val_loss: 0.8269 - val_acc: 0.5599\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7009 - acc: 0.6163 - val_loss: 0.7934 - val_acc: 0.5385\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5966 - acc: 0.6520 - val_loss: 0.7548 - val_acc: 0.6077\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5823 - acc: 0.6736 - val_loss: 0.7905 - val_acc: 0.6695\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5945 - acc: 0.6783 - val_loss: 0.7266 - val_acc: 0.6970\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5254 - acc: 0.7505 - val_loss: 0.6985 - val_acc: 0.7357\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4745 - acc: 0.7948 - val_loss: 0.6499 - val_acc: 0.7913\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4172 - acc: 0.8072 - val_loss: 0.6075 - val_acc: 0.7747\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4378 - acc: 0.7952 - val_loss: 0.8944 - val_acc: 0.6960\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3928 - acc: 0.8186 - val_loss: 0.6037 - val_acc: 0.7598\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3796 - acc: 0.8452 - val_loss: 0.6665 - val_acc: 0.8076\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3488 - acc: 0.8586 - val_loss: 0.6163 - val_acc: 0.8449\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3266 - acc: 0.8800 - val_loss: 0.6527 - val_acc: 0.8113\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3089 - acc: 0.9049 - val_loss: 0.7058 - val_acc: 0.8378\n",
      "2450/2450 [==============================] - 3s 1ms/step\n",
      "4902/4902 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 72s 15ms/step - loss: 1.3676 - acc: 0.4269 - val_loss: 1.3431 - val_acc: 0.4252\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1454 - acc: 0.4999 - val_loss: 1.1322 - val_acc: 0.4255\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.0042 - acc: 0.5685 - val_loss: 1.6918 - val_acc: 0.3702\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8049 - acc: 0.5968 - val_loss: 0.7570 - val_acc: 0.6203\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8024 - acc: 0.6162 - val_loss: 1.0976 - val_acc: 0.4130\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7317 - acc: 0.6266 - val_loss: 0.7528 - val_acc: 0.6274\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7167 - acc: 0.6319 - val_loss: 0.8308 - val_acc: 0.6149\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6808 - acc: 0.6442 - val_loss: 0.7727 - val_acc: 0.6145\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7267 - acc: 0.6378 - val_loss: 1.0390 - val_acc: 0.5029\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6605 - acc: 0.6670 - val_loss: 0.7267 - val_acc: 0.6186\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5970 - acc: 0.7164 - val_loss: 0.7034 - val_acc: 0.6966\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5217 - acc: 0.7619 - val_loss: 1.1425 - val_acc: 0.5555\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4775 - acc: 0.7745 - val_loss: 0.6991 - val_acc: 0.6973\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4748 - acc: 0.7984 - val_loss: 0.5860 - val_acc: 0.7866\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4038 - acc: 0.8459 - val_loss: 0.4710 - val_acc: 0.8507\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3413 - acc: 0.8868 - val_loss: 0.4346 - val_acc: 0.8663\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2692 - acc: 0.9086 - val_loss: 0.4500 - val_acc: 0.8622\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2634 - acc: 0.9053 - val_loss: 0.4434 - val_acc: 0.8758\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2340 - acc: 0.9214 - val_loss: 0.4895 - val_acc: 0.8602\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2478 - acc: 0.9192 - val_loss: 0.4531 - val_acc: 0.8911\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2218 - acc: 0.9176 - val_loss: 0.6092 - val_acc: 0.8470\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1854 - acc: 0.9310 - val_loss: 0.4905 - val_acc: 0.8629\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2134 - acc: 0.9286 - val_loss: 0.5081 - val_acc: 0.8561\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1887 - acc: 0.9284 - val_loss: 0.4365 - val_acc: 0.8792\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1928 - acc: 0.9298 - val_loss: 0.4388 - val_acc: 0.8901\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1666 - acc: 0.9408 - val_loss: 0.3556 - val_acc: 0.9040\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1535 - acc: 0.9431 - val_loss: 0.9465 - val_acc: 0.8500\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1750 - acc: 0.9408 - val_loss: 0.4002 - val_acc: 0.8962\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1585 - acc: 0.9388 - val_loss: 0.4418 - val_acc: 0.8999\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1503 - acc: 0.9445 - val_loss: 0.5935 - val_acc: 0.8924\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 73s 15ms/step - loss: 1.3896 - acc: 0.4060 - val_loss: 1.3322 - val_acc: 0.4106\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1202 - acc: 0.4848 - val_loss: 1.3011 - val_acc: 0.4611\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.2848 - acc: 0.4330 - val_loss: 1.3480 - val_acc: 0.4075\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.0913 - acc: 0.4999 - val_loss: 1.0362 - val_acc: 0.5229\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8382 - acc: 0.6248 - val_loss: 0.8820 - val_acc: 0.6339\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7209 - acc: 0.6690 - val_loss: 0.8212 - val_acc: 0.6759\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6765 - acc: 0.7143 - val_loss: 0.7981 - val_acc: 0.6895\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6332 - acc: 0.7131 - val_loss: 0.7247 - val_acc: 0.7041\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7197 - acc: 0.6609 - val_loss: 0.9987 - val_acc: 0.5772\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6520 - acc: 0.7176 - val_loss: 0.7275 - val_acc: 0.6725\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5119 - acc: 0.7627 - val_loss: 0.7086 - val_acc: 0.7272\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4882 - acc: 0.7784 - val_loss: 0.7240 - val_acc: 0.7160\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4479 - acc: 0.7929 - val_loss: 0.6739 - val_acc: 0.7231\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4271 - acc: 0.8039 - val_loss: 0.6386 - val_acc: 0.7452\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4111 - acc: 0.8029 - val_loss: 0.6477 - val_acc: 0.7387\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4003 - acc: 0.8047 - val_loss: 0.5924 - val_acc: 0.7560\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4223 - acc: 0.8133 - val_loss: 0.6554 - val_acc: 0.8113\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3638 - acc: 0.8674 - val_loss: 0.7324 - val_acc: 0.8229\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3444 - acc: 0.8972 - val_loss: 0.5419 - val_acc: 0.8476\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.3177 - acc: 0.9094 - val_loss: 0.7353 - val_acc: 0.8056\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2697 - acc: 0.9190 - val_loss: 0.4109 - val_acc: 0.8782\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3593 - acc: 0.8876 - val_loss: 0.4770 - val_acc: 0.8565\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2260 - acc: 0.9341 - val_loss: 0.5675 - val_acc: 0.8344\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1909 - acc: 0.9404 - val_loss: 0.4793 - val_acc: 0.8816\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1750 - acc: 0.9455 - val_loss: 0.4462 - val_acc: 0.8928\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1626 - acc: 0.9486 - val_loss: 0.4848 - val_acc: 0.8833\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1941 - acc: 0.9404 - val_loss: 0.7914 - val_acc: 0.8500\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1585 - acc: 0.9461 - val_loss: 0.9351 - val_acc: 0.8409\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1574 - acc: 0.9433 - val_loss: 0.5228 - val_acc: 0.8548\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2348 - acc: 0.9188 - val_loss: 0.4969 - val_acc: 0.8846\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 73s 15ms/step - loss: 1.3535 - acc: 0.4047 - val_loss: 1.2628 - val_acc: 0.4662\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.0985 - acc: 0.5039 - val_loss: 1.1278 - val_acc: 0.4771\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.8952 - acc: 0.5930 - val_loss: 0.8865 - val_acc: 0.5847\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.8761 - acc: 0.5853 - val_loss: 0.8263 - val_acc: 0.6413\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.7115 - acc: 0.6779 - val_loss: 0.8155 - val_acc: 0.6546\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7251 - acc: 0.6891 - val_loss: 0.8903 - val_acc: 0.6437\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6384 - acc: 0.7177 - val_loss: 0.7066 - val_acc: 0.6844\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6145 - acc: 0.7250 - val_loss: 1.2407 - val_acc: 0.5589\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5389 - acc: 0.7554 - val_loss: 0.8030 - val_acc: 0.6766\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5020 - acc: 0.7707 - val_loss: 0.6269 - val_acc: 0.7611\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4533 - acc: 0.7982 - val_loss: 0.6338 - val_acc: 0.7682\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4438 - acc: 0.8154 - val_loss: 0.7448 - val_acc: 0.7530\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4379 - acc: 0.8360 - val_loss: 0.6432 - val_acc: 0.7883\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3800 - acc: 0.8607 - val_loss: 0.7950 - val_acc: 0.7808\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3577 - acc: 0.8866 - val_loss: 0.4959 - val_acc: 0.8483\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3051 - acc: 0.8956 - val_loss: 0.6722 - val_acc: 0.8168\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2861 - acc: 0.9017 - val_loss: 0.6369 - val_acc: 0.8222\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2616 - acc: 0.9062 - val_loss: 0.6217 - val_acc: 0.8351\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2366 - acc: 0.9141 - val_loss: 0.4666 - val_acc: 0.8761\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2074 - acc: 0.9215 - val_loss: 0.7491 - val_acc: 0.8541\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1892 - acc: 0.9270 - val_loss: 0.5184 - val_acc: 0.8643\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1926 - acc: 0.9215 - val_loss: 0.4788 - val_acc: 0.8724\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1861 - acc: 0.9243 - val_loss: 0.5513 - val_acc: 0.8653\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1737 - acc: 0.9294 - val_loss: 0.5846 - val_acc: 0.8772\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1723 - acc: 0.9317 - val_loss: 1.5645 - val_acc: 0.7679\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2216 - acc: 0.9288 - val_loss: 0.4980 - val_acc: 0.8867\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1573 - acc: 0.9302 - val_loss: 0.5143 - val_acc: 0.8789\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1865 - acc: 0.9343 - val_loss: 0.5326 - val_acc: 0.8850\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1338 - acc: 0.9431 - val_loss: 0.4534 - val_acc: 0.8938\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1327 - acc: 0.9384 - val_loss: 0.5897 - val_acc: 0.8894\n",
      "2450/2450 [==============================] - 5s 2ms/step\n",
      "4902/4902 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 83s 17ms/step - loss: 1.5307 - acc: 0.3563 - val_loss: 1.4263 - val_acc: 0.3583\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.3441 - acc: 0.4236 - val_loss: 1.3884 - val_acc: 0.2793\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1528 - acc: 0.4811 - val_loss: 1.3044 - val_acc: 0.4130\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2751 - acc: 0.4358 - val_loss: 1.1956 - val_acc: 0.4489\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1938 - acc: 0.4552 - val_loss: 1.2857 - val_acc: 0.4123\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2220 - acc: 0.4540 - val_loss: 1.2776 - val_acc: 0.4187\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.1305 - acc: 0.4885 - val_loss: 1.2115 - val_acc: 0.4466\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 1.1861 - acc: 0.4644 - val_loss: 1.2867 - val_acc: 0.4133\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1961 - acc: 0.4587 - val_loss: 1.2886 - val_acc: 0.3383\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2352 - acc: 0.4126 - val_loss: 1.3646 - val_acc: 0.3570\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1255 - acc: 0.4807 - val_loss: 1.1544 - val_acc: 0.3974\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.9276 - acc: 0.4972 - val_loss: 0.9342 - val_acc: 0.4445\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.8466 - acc: 0.5425 - val_loss: 0.8792 - val_acc: 0.4598\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8358 - acc: 0.5709 - val_loss: 0.9859 - val_acc: 0.5938\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7965 - acc: 0.6046 - val_loss: 0.9352 - val_acc: 0.6108\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7906 - acc: 0.6378 - val_loss: 1.2127 - val_acc: 0.5850\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7505 - acc: 0.6529 - val_loss: 0.9992 - val_acc: 0.5619\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6902 - acc: 0.6511 - val_loss: 0.7716 - val_acc: 0.6091\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7261 - acc: 0.6454 - val_loss: 0.8165 - val_acc: 0.6230\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6497 - acc: 0.6693 - val_loss: 0.7462 - val_acc: 0.6210\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7955 - acc: 0.6362 - val_loss: 0.9091 - val_acc: 0.5792\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7222 - acc: 0.6639 - val_loss: 0.7353 - val_acc: 0.6196\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6342 - acc: 0.6697 - val_loss: 0.7857 - val_acc: 0.6247\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6600 - acc: 0.6703 - val_loss: 0.7752 - val_acc: 0.6284\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6427 - acc: 0.6676 - val_loss: 0.8172 - val_acc: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6518 - acc: 0.6750 - val_loss: 0.7496 - val_acc: 0.6278\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6558 - acc: 0.6678 - val_loss: 0.6973 - val_acc: 0.6274\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6081 - acc: 0.6770 - val_loss: 0.7703 - val_acc: 0.6172\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6815 - acc: 0.6623 - val_loss: 0.7847 - val_acc: 0.6179\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5991 - acc: 0.6731 - val_loss: 0.6644 - val_acc: 0.6162\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 84s 17ms/step - loss: 1.4663 - acc: 0.3542 - val_loss: 1.4144 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3485 - acc: 0.3540 - val_loss: 1.4639 - val_acc: 0.3448\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.4226 - acc: 0.3414 - val_loss: 1.4161 - val_acc: 0.3536\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3196 - acc: 0.3575 - val_loss: 1.4205 - val_acc: 0.3519\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3484 - acc: 0.3607 - val_loss: 1.4132 - val_acc: 0.3448\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3173 - acc: 0.3618 - val_loss: 1.4088 - val_acc: 0.3451\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2728 - acc: 0.4215 - val_loss: 1.3337 - val_acc: 0.3960\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3102 - acc: 0.3865 - val_loss: 1.3343 - val_acc: 0.3631\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1852 - acc: 0.4366 - val_loss: 1.2002 - val_acc: 0.4795\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1409 - acc: 0.4758 - val_loss: 1.0482 - val_acc: 0.5568\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9184 - acc: 0.5762 - val_loss: 0.9210 - val_acc: 0.6060\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 1.2864 - acc: 0.4428 - val_loss: 1.5029 - val_acc: 0.3692\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.5583 - acc: 0.3483 - val_loss: 1.4766 - val_acc: 0.3329\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 57s 12ms/step - loss: 1.3494 - acc: 0.3591 - val_loss: 1.4437 - val_acc: 0.3515\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2480 - acc: 0.4377 - val_loss: 1.3055 - val_acc: 0.4286\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2673 - acc: 0.4548 - val_loss: 1.2918 - val_acc: 0.4388\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3298 - acc: 0.3946 - val_loss: 1.3234 - val_acc: 0.4001\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1313 - acc: 0.4960 - val_loss: 1.3706 - val_acc: 0.4588\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1239 - acc: 0.4870 - val_loss: 1.3337 - val_acc: 0.4611\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1539 - acc: 0.4860 - val_loss: 1.2090 - val_acc: 0.5266\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3430 - acc: 0.4501 - val_loss: 1.4302 - val_acc: 0.4181\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1742 - acc: 0.4603 - val_loss: 1.0087 - val_acc: 0.5059\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9328 - acc: 0.5754 - val_loss: 0.9332 - val_acc: 0.5697\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8092 - acc: 0.6064 - val_loss: 0.8976 - val_acc: 0.5860\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7203 - acc: 0.6421 - val_loss: 0.8377 - val_acc: 0.6060\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7458 - acc: 0.6358 - val_loss: 0.8422 - val_acc: 0.6257\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6610 - acc: 0.6558 - val_loss: 0.8243 - val_acc: 0.6071\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6459 - acc: 0.6656 - val_loss: 0.8100 - val_acc: 0.6081\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8385 - acc: 0.6260 - val_loss: 1.2681 - val_acc: 0.5707\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5769 - acc: 0.6705 - val_loss: 0.6573 - val_acc: 0.6220\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 91s 18ms/step - loss: 1.5333 - acc: 0.3388 - val_loss: 1.4723 - val_acc: 0.3482\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.4800 - acc: 0.3511 - val_loss: 1.4014 - val_acc: 0.3482\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3456 - acc: 0.3772 - val_loss: 1.4224 - val_acc: 0.3471\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.3413 - acc: 0.3768 - val_loss: 1.4333 - val_acc: 0.3597\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.2991 - acc: 0.3976 - val_loss: 1.6521 - val_acc: 0.3342\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2367 - acc: 0.4310 - val_loss: 1.1621 - val_acc: 0.4303\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0919 - acc: 0.4543 - val_loss: 1.0779 - val_acc: 0.4499\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.9507 - acc: 0.5702 - val_loss: 0.9568 - val_acc: 0.5752\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1134 - acc: 0.5124 - val_loss: 0.9386 - val_acc: 0.6060\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.8186 - acc: 0.6310 - val_loss: 0.7985 - val_acc: 0.6101\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.0715 - acc: 0.5277 - val_loss: 1.3956 - val_acc: 0.3695\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.2601 - acc: 0.4102 - val_loss: 1.3787 - val_acc: 0.3363\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 59s 12ms/step - loss: 1.1317 - acc: 0.4888 - val_loss: 0.9009 - val_acc: 0.5724\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7597 - acc: 0.6438 - val_loss: 0.7836 - val_acc: 0.6111\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6978 - acc: 0.6538 - val_loss: 0.7740 - val_acc: 0.6179\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6639 - acc: 0.6618 - val_loss: 0.8531 - val_acc: 0.6172\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7410 - acc: 0.6410 - val_loss: 0.7463 - val_acc: 0.6179\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6269 - acc: 0.6477 - val_loss: 0.8428 - val_acc: 0.6183\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7132 - acc: 0.6236 - val_loss: 0.6944 - val_acc: 0.6213\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.6349 - acc: 0.6361 - val_loss: 0.9173 - val_acc: 0.6135\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 57s 12ms/step - loss: 0.6895 - acc: 0.6246 - val_loss: 0.9394 - val_acc: 0.5803\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.6067 - acc: 0.6516 - val_loss: 0.6673 - val_acc: 0.5996\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.5290 - acc: 0.6748 - val_loss: 0.7132 - val_acc: 0.6237\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.5243 - acc: 0.6787 - val_loss: 0.6592 - val_acc: 0.6186\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5143 - acc: 0.6946 - val_loss: 0.7292 - val_acc: 0.6267\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4964 - acc: 0.7391 - val_loss: 1.0083 - val_acc: 0.6206\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4891 - acc: 0.7556 - val_loss: 0.7719 - val_acc: 0.7139\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4374 - acc: 0.7968 - val_loss: 0.5906 - val_acc: 0.7567\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4096 - acc: 0.8072 - val_loss: 0.6269 - val_acc: 0.7642\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3651 - acc: 0.8374 - val_loss: 0.5628 - val_acc: 0.7051\n",
      "2450/2450 [==============================] - 7s 3ms/step\n",
      "4902/4902 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 99s 20ms/step - loss: 1.4018 - acc: 0.3818 - val_loss: 1.3537 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.2780 - acc: 0.4136 - val_loss: 1.1521 - val_acc: 0.4886\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.0291 - acc: 0.5134 - val_loss: 0.8797 - val_acc: 0.5090\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7947 - acc: 0.5458 - val_loss: 0.8462 - val_acc: 0.5755\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.7970 - acc: 0.5848 - val_loss: 0.8701 - val_acc: 0.5083\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7443 - acc: 0.6007 - val_loss: 0.8784 - val_acc: 0.5304\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.7110 - acc: 0.6374 - val_loss: 0.7134 - val_acc: 0.6223\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7973 - acc: 0.6203 - val_loss: 0.7204 - val_acc: 0.6189\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6660 - acc: 0.6595 - val_loss: 0.6846 - val_acc: 0.6413\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6697 - acc: 0.6748 - val_loss: 0.7135 - val_acc: 0.6345\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6886 - acc: 0.6744 - val_loss: 0.7112 - val_acc: 0.6539\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6333 - acc: 0.7172 - val_loss: 0.6994 - val_acc: 0.6797\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 0.5390 - acc: 0.7798 - val_loss: 1.0045 - val_acc: 0.6172\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.4580 - acc: 0.8058 - val_loss: 0.4358 - val_acc: 0.8181\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.4134 - acc: 0.8419 - val_loss: 0.4797 - val_acc: 0.8086\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5496 - acc: 0.7576 - val_loss: 0.5717 - val_acc: 0.7984\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.3922 - acc: 0.8604 - val_loss: 0.4026 - val_acc: 0.8609\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.3120 - acc: 0.8984 - val_loss: 0.3362 - val_acc: 0.8738\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2513 - acc: 0.9145 - val_loss: 0.6822 - val_acc: 0.8062\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2340 - acc: 0.9227 - val_loss: 0.4476 - val_acc: 0.8575\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2363 - acc: 0.9310 - val_loss: 0.4080 - val_acc: 0.8843\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2047 - acc: 0.9339 - val_loss: 0.3143 - val_acc: 0.8850\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1906 - acc: 0.9374 - val_loss: 0.3601 - val_acc: 0.8816\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1668 - acc: 0.9416 - val_loss: 0.2949 - val_acc: 0.8904\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1651 - acc: 0.9396 - val_loss: 0.4517 - val_acc: 0.8877\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1646 - acc: 0.9396 - val_loss: 0.3976 - val_acc: 0.8911\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1673 - acc: 0.9431 - val_loss: 0.6678 - val_acc: 0.8666\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 0.1849 - acc: 0.9474 - val_loss: 0.5307 - val_acc: 0.8792\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1478 - acc: 0.9486 - val_loss: 0.3607 - val_acc: 0.9016\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2100 - acc: 0.9331 - val_loss: 0.5343 - val_acc: 0.8887\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 100s 20ms/step - loss: 1.3971 - acc: 0.3540 - val_loss: 1.3509 - val_acc: 0.3532\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.3292 - acc: 0.3587 - val_loss: 1.3703 - val_acc: 0.3536\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.3120 - acc: 0.3665 - val_loss: 1.3695 - val_acc: 0.3536\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.4154 - acc: 0.3852 - val_loss: 1.3834 - val_acc: 0.3750\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2104 - acc: 0.4601 - val_loss: 1.2379 - val_acc: 0.4398\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.9748 - acc: 0.5554 - val_loss: 1.0382 - val_acc: 0.5677\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8018 - acc: 0.6333 - val_loss: 0.9201 - val_acc: 0.6006\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7218 - acc: 0.6346 - val_loss: 0.8928 - val_acc: 0.5979\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.9128 - acc: 0.6040 - val_loss: 0.8689 - val_acc: 0.5993\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7458 - acc: 0.6474 - val_loss: 0.8454 - val_acc: 0.6094\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6839 - acc: 0.6525 - val_loss: 0.8469 - val_acc: 0.6529\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7118 - acc: 0.6839 - val_loss: 0.8128 - val_acc: 0.6267\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6270 - acc: 0.7025 - val_loss: 0.9428 - val_acc: 0.6807\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 0.5145 - acc: 0.7674 - val_loss: 0.6482 - val_acc: 0.7313\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5154 - acc: 0.7654 - val_loss: 0.6804 - val_acc: 0.7316\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.4724 - acc: 0.8002 - val_loss: 0.7527 - val_acc: 0.7638\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.4285 - acc: 0.8574 - val_loss: 0.7593 - val_acc: 0.7696\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.4115 - acc: 0.8659 - val_loss: 0.9346 - val_acc: 0.7740\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2803 - acc: 0.9117 - val_loss: 0.6058 - val_acc: 0.8490\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2094 - acc: 0.9325 - val_loss: 0.6449 - val_acc: 0.8565\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1809 - acc: 0.9402 - val_loss: 0.7968 - val_acc: 0.8208\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2093 - acc: 0.9292 - val_loss: 0.6497 - val_acc: 0.8704\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1571 - acc: 0.9459 - val_loss: 0.5102 - val_acc: 0.8911\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2387 - acc: 0.9341 - val_loss: 0.5108 - val_acc: 0.8806\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1392 - acc: 0.9504 - val_loss: 0.5201 - val_acc: 0.8853\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1721 - acc: 0.9482 - val_loss: 0.5398 - val_acc: 0.8833\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2128 - acc: 0.9378 - val_loss: 0.7354 - val_acc: 0.8202\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1619 - acc: 0.9447 - val_loss: 0.5776 - val_acc: 0.8911\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1507 - acc: 0.9494 - val_loss: 0.4962 - val_acc: 0.8809\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1446 - acc: 0.9531 - val_loss: 0.6002 - val_acc: 0.8853\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 100s 20ms/step - loss: 1.4713 - acc: 0.3621 - val_loss: 1.4026 - val_acc: 0.4388\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.3107 - acc: 0.4080 - val_loss: 1.3449 - val_acc: 0.3990\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 70s 14ms/step - loss: 1.3809 - acc: 0.4068 - val_loss: 1.5859 - val_acc: 0.3159\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.2464 - acc: 0.4392 - val_loss: 1.3223 - val_acc: 0.4065\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.1918 - acc: 0.4514 - val_loss: 1.1471 - val_acc: 0.5120\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.1048 - acc: 0.4827 - val_loss: 1.2709 - val_acc: 0.4611\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.0338 - acc: 0.5647 - val_loss: 1.1145 - val_acc: 0.5087\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.8159 - acc: 0.6277 - val_loss: 0.9764 - val_acc: 0.4835\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.7952 - acc: 0.6259 - val_loss: 0.7718 - val_acc: 0.6308\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.8670 - acc: 0.6012 - val_loss: 0.7493 - val_acc: 0.6267\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.7208 - acc: 0.6442 - val_loss: 0.7426 - val_acc: 0.6060\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6877 - acc: 0.6630 - val_loss: 0.9290 - val_acc: 0.5480\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6684 - acc: 0.6758 - val_loss: 0.7228 - val_acc: 0.6773\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6830 - acc: 0.6785 - val_loss: 0.8605 - val_acc: 0.6325\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6828 - acc: 0.6699 - val_loss: 0.7891 - val_acc: 0.6797\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6379 - acc: 0.6948 - val_loss: 0.7594 - val_acc: 0.7119\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6407 - acc: 0.7062 - val_loss: 0.8251 - val_acc: 0.6759\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6121 - acc: 0.7311 - val_loss: 0.9660 - val_acc: 0.6980\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5381 - acc: 0.7646 - val_loss: 1.0598 - val_acc: 0.5901\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5137 - acc: 0.7709 - val_loss: 0.9579 - val_acc: 0.6502\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.5385 - acc: 0.7485 - val_loss: 0.6810 - val_acc: 0.7591\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.4200 - acc: 0.7962 - val_loss: 0.6177 - val_acc: 0.7547\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.4218 - acc: 0.8031 - val_loss: 0.8321 - val_acc: 0.7309\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.3910 - acc: 0.8286 - val_loss: 0.6604 - val_acc: 0.7998\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.3443 - acc: 0.8800 - val_loss: 0.5889 - val_acc: 0.8252\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2688 - acc: 0.9047 - val_loss: 0.5124 - val_acc: 0.8734\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 73s 15ms/step - loss: 0.2214 - acc: 0.9243 - val_loss: 0.5808 - val_acc: 0.8347\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 83s 17ms/step - loss: 0.2116 - acc: 0.9204 - val_loss: 0.4909 - val_acc: 0.8795\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 77s 16ms/step - loss: 0.1815 - acc: 0.9353 - val_loss: 0.6357 - val_acc: 0.8582\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 73s 15ms/step - loss: 0.1765 - acc: 0.9378 - val_loss: 0.5195 - val_acc: 0.8843\n",
      "2450/2450 [==============================] - 8s 3ms/step\n",
      "4902/4902 [==============================] - 16s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.3965 - acc: 0.4420 - val_loss: 1.2526 - val_acc: 0.4398\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.1698 - acc: 0.4811 - val_loss: 1.1832 - val_acc: 0.4282\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9919 - acc: 0.5454 - val_loss: 1.0076 - val_acc: 0.4808\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8679 - acc: 0.6282 - val_loss: 0.9882 - val_acc: 0.5877\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7515 - acc: 0.6429 - val_loss: 0.7998 - val_acc: 0.6417\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7195 - acc: 0.6458 - val_loss: 0.7728 - val_acc: 0.6121\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6572 - acc: 0.6621 - val_loss: 0.7406 - val_acc: 0.6288\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6520 - acc: 0.6737 - val_loss: 0.7289 - val_acc: 0.6647\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7200 - acc: 0.6552 - val_loss: 0.6797 - val_acc: 0.7027\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5628 - acc: 0.7492 - val_loss: 0.6920 - val_acc: 0.7190\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4895 - acc: 0.7849 - val_loss: 0.6589 - val_acc: 0.7289\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4623 - acc: 0.7827 - val_loss: 0.6174 - val_acc: 0.7201\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4069 - acc: 0.7974 - val_loss: 0.5341 - val_acc: 0.7421\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3963 - acc: 0.7947 - val_loss: 0.5406 - val_acc: 0.7387\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3491 - acc: 0.7970 - val_loss: 0.5694 - val_acc: 0.7313\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3520 - acc: 0.8055 - val_loss: 0.5541 - val_acc: 0.7346\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2919 - acc: 0.8523 - val_loss: 0.6247 - val_acc: 0.7988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2914 - acc: 0.8986 - val_loss: 0.7484 - val_acc: 0.7682\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3023 - acc: 0.9161 - val_loss: 0.5105 - val_acc: 0.8656\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2363 - acc: 0.9343 - val_loss: 0.4249 - val_acc: 0.8337\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1760 - acc: 0.9388 - val_loss: 0.3587 - val_acc: 0.8863\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1834 - acc: 0.9376 - val_loss: 0.5571 - val_acc: 0.8402\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1590 - acc: 0.9453 - val_loss: 0.5395 - val_acc: 0.8554\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2009 - acc: 0.9349 - val_loss: 0.5306 - val_acc: 0.8700\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1651 - acc: 0.9441 - val_loss: 0.4555 - val_acc: 0.8833\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1605 - acc: 0.9447 - val_loss: 0.4108 - val_acc: 0.8843\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1414 - acc: 0.9494 - val_loss: 0.4067 - val_acc: 0.8829\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1576 - acc: 0.9451 - val_loss: 0.4656 - val_acc: 0.8890\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1800 - acc: 0.9335 - val_loss: 0.4434 - val_acc: 0.8884\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1626 - acc: 0.9461 - val_loss: 0.5815 - val_acc: 0.8561\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 64s 13ms/step - loss: 1.4658 - acc: 0.3477 - val_loss: 1.4275 - val_acc: 0.3366\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2781 - acc: 0.3828 - val_loss: 1.3553 - val_acc: 0.4157\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0988 - acc: 0.5246 - val_loss: 1.1857 - val_acc: 0.4768\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0379 - acc: 0.5366 - val_loss: 1.6947 - val_acc: 0.3230\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0120 - acc: 0.5438 - val_loss: 1.0223 - val_acc: 0.5623\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.8917 - acc: 0.6062 - val_loss: 0.9378 - val_acc: 0.5843\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7423 - acc: 0.6446 - val_loss: 0.9229 - val_acc: 0.5741\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7489 - acc: 0.6348 - val_loss: 0.8786 - val_acc: 0.5799\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6646 - acc: 0.6566 - val_loss: 0.8939 - val_acc: 0.6105\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6456 - acc: 0.6866 - val_loss: 0.8804 - val_acc: 0.6047\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7761 - acc: 0.6582 - val_loss: 0.7103 - val_acc: 0.6854\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6138 - acc: 0.7162 - val_loss: 0.7022 - val_acc: 0.6990\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5653 - acc: 0.7547 - val_loss: 0.7724 - val_acc: 0.6885\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5002 - acc: 0.7721 - val_loss: 0.6713 - val_acc: 0.7231\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4692 - acc: 0.7809 - val_loss: 0.6701 - val_acc: 0.7133\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4437 - acc: 0.7902 - val_loss: 0.6656 - val_acc: 0.7441\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4510 - acc: 0.7872 - val_loss: 0.6514 - val_acc: 0.7394\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3893 - acc: 0.8058 - val_loss: 0.8102 - val_acc: 0.7503\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.3749 - acc: 0.8235 - val_loss: 0.5864 - val_acc: 0.7913\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3388 - acc: 0.8629 - val_loss: 0.7033 - val_acc: 0.7788\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2802 - acc: 0.9086 - val_loss: 0.4486 - val_acc: 0.8490\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2595 - acc: 0.9143 - val_loss: 0.6104 - val_acc: 0.8480\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1990 - acc: 0.9355 - val_loss: 0.5627 - val_acc: 0.8660\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1711 - acc: 0.9386 - val_loss: 0.6565 - val_acc: 0.8537\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2990 - acc: 0.8998 - val_loss: 0.6085 - val_acc: 0.8734\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1671 - acc: 0.9425 - val_loss: 0.6669 - val_acc: 0.8599\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1556 - acc: 0.9457 - val_loss: 0.6039 - val_acc: 0.8663\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1365 - acc: 0.9461 - val_loss: 0.5752 - val_acc: 0.8728\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1507 - acc: 0.9490 - val_loss: 0.4607 - val_acc: 0.8880\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1169 - acc: 0.9529 - val_loss: 0.5433 - val_acc: 0.8853\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 67s 14ms/step - loss: 1.4492 - acc: 0.3688 - val_loss: 1.4025 - val_acc: 0.3485\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.3235 - acc: 0.3923 - val_loss: 1.3375 - val_acc: 0.4191\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2628 - acc: 0.4370 - val_loss: 1.2982 - val_acc: 0.4106\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.2221 - acc: 0.4533 - val_loss: 1.9109 - val_acc: 0.3967\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.1660 - acc: 0.4600 - val_loss: 1.1745 - val_acc: 0.4330\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.1424 - acc: 0.4627 - val_loss: 1.3063 - val_acc: 0.4235\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.0587 - acc: 0.4716 - val_loss: 1.2648 - val_acc: 0.4167\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9838 - acc: 0.5059 - val_loss: 1.0203 - val_acc: 0.4642\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9533 - acc: 0.5424 - val_loss: 1.0598 - val_acc: 0.4995\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8799 - acc: 0.5936 - val_loss: 0.9615 - val_acc: 0.5816\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8152 - acc: 0.6187 - val_loss: 0.9182 - val_acc: 0.5456\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7200 - acc: 0.6412 - val_loss: 0.8844 - val_acc: 0.5877\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7427 - acc: 0.6563 - val_loss: 0.8587 - val_acc: 0.5623\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7516 - acc: 0.6503 - val_loss: 0.8055 - val_acc: 0.6875\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6551 - acc: 0.7209 - val_loss: 0.8036 - val_acc: 0.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8479 - acc: 0.6493 - val_loss: 0.7381 - val_acc: 0.7150\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6165 - acc: 0.7264 - val_loss: 0.7191 - val_acc: 0.7129\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5735 - acc: 0.7377 - val_loss: 0.9271 - val_acc: 0.6013\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5647 - acc: 0.7346 - val_loss: 0.6936 - val_acc: 0.6654\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4700 - acc: 0.7652 - val_loss: 0.7120 - val_acc: 0.7048\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4584 - acc: 0.7968 - val_loss: 0.5363 - val_acc: 0.8062\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 34s 7ms/step - loss: 0.3786 - acc: 0.8554 - val_loss: 0.8443 - val_acc: 0.6624\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3210 - acc: 0.8827 - val_loss: 0.5004 - val_acc: 0.8327\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2751 - acc: 0.9031 - val_loss: 0.4199 - val_acc: 0.8609\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2497 - acc: 0.9104 - val_loss: 0.4274 - val_acc: 0.8605\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2280 - acc: 0.9125 - val_loss: 0.4211 - val_acc: 0.8744\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2362 - acc: 0.9188 - val_loss: 0.4878 - val_acc: 0.8694\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2027 - acc: 0.9194 - val_loss: 0.5721 - val_acc: 0.8426\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1810 - acc: 0.9241 - val_loss: 0.4290 - val_acc: 0.8741\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1865 - acc: 0.9259 - val_loss: 0.4722 - val_acc: 0.8772\n",
      "2450/2450 [==============================] - 4s 1ms/step\n",
      "4902/4902 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 77s 16ms/step - loss: 1.3377 - acc: 0.4238 - val_loss: 1.4590 - val_acc: 0.4018\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.0612 - acc: 0.5538 - val_loss: 0.9350 - val_acc: 0.5745\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8242 - acc: 0.6231 - val_loss: 0.8206 - val_acc: 0.6518\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7705 - acc: 0.6403 - val_loss: 0.7581 - val_acc: 0.6468\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7204 - acc: 0.6425 - val_loss: 0.9506 - val_acc: 0.5789\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6907 - acc: 0.6588 - val_loss: 0.8049 - val_acc: 0.6274\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.6833 - acc: 0.6654 - val_loss: 0.8701 - val_acc: 0.5691\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6659 - acc: 0.6697 - val_loss: 0.7625 - val_acc: 0.6722\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 46s 9ms/step - loss: 0.6152 - acc: 0.7080 - val_loss: 0.7447 - val_acc: 0.6804\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5412 - acc: 0.7466 - val_loss: 0.6647 - val_acc: 0.7309\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5378 - acc: 0.7678 - val_loss: 0.6300 - val_acc: 0.7462\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4470 - acc: 0.8019 - val_loss: 1.5762 - val_acc: 0.6043\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4044 - acc: 0.8427 - val_loss: 0.8033 - val_acc: 0.6630\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3383 - acc: 0.8690 - val_loss: 0.5765 - val_acc: 0.8039\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2834 - acc: 0.8890 - val_loss: 0.6079 - val_acc: 0.8012\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2354 - acc: 0.9074 - val_loss: 0.7320 - val_acc: 0.7991\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2455 - acc: 0.9055 - val_loss: 0.5200 - val_acc: 0.8697\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2261 - acc: 0.9137 - val_loss: 0.4955 - val_acc: 0.8622\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1992 - acc: 0.9208 - val_loss: 0.5602 - val_acc: 0.8147\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1882 - acc: 0.9227 - val_loss: 0.6023 - val_acc: 0.8490\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1804 - acc: 0.9292 - val_loss: 0.3783 - val_acc: 0.8768\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1756 - acc: 0.9310 - val_loss: 0.4625 - val_acc: 0.8721\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1585 - acc: 0.9363 - val_loss: 0.5388 - val_acc: 0.8772\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1487 - acc: 0.9431 - val_loss: 0.4348 - val_acc: 0.8907\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1526 - acc: 0.9425 - val_loss: 0.4381 - val_acc: 0.8819\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1375 - acc: 0.9472 - val_loss: 0.4588 - val_acc: 0.8911\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1490 - acc: 0.9406 - val_loss: 0.5035 - val_acc: 0.8850\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1433 - acc: 0.9400 - val_loss: 0.4376 - val_acc: 0.8823\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1464 - acc: 0.9467 - val_loss: 0.4090 - val_acc: 0.9019\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1625 - acc: 0.9449 - val_loss: 0.5097 - val_acc: 0.8867\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 78s 16ms/step - loss: 1.3873 - acc: 0.3799 - val_loss: 1.4396 - val_acc: 0.3448\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.2354 - acc: 0.4264 - val_loss: 1.2375 - val_acc: 0.4340\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.1903 - acc: 0.4742 - val_loss: 1.2599 - val_acc: 0.4041\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 1.0043 - acc: 0.5636 - val_loss: 1.7598 - val_acc: 0.4130\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8727 - acc: 0.5866 - val_loss: 1.0715 - val_acc: 0.4886\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.7251 - acc: 0.6795 - val_loss: 0.8554 - val_acc: 0.6413\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6814 - acc: 0.7019 - val_loss: 0.8095 - val_acc: 0.6973\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6170 - acc: 0.7437 - val_loss: 0.7917 - val_acc: 0.7065\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.5403 - acc: 0.7733 - val_loss: 0.9302 - val_acc: 0.6705\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4723 - acc: 0.8088 - val_loss: 0.7557 - val_acc: 0.7055\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4259 - acc: 0.8286 - val_loss: 0.6224 - val_acc: 0.7774\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3341 - acc: 0.8764 - val_loss: 0.6760 - val_acc: 0.8198\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2912 - acc: 0.9055 - val_loss: 0.5564 - val_acc: 0.8347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2239 - acc: 0.9257 - val_loss: 0.4959 - val_acc: 0.8673\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1762 - acc: 0.9370 - val_loss: 0.5167 - val_acc: 0.8690\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1494 - acc: 0.9461 - val_loss: 0.6295 - val_acc: 0.8694\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1497 - acc: 0.9500 - val_loss: 0.5430 - val_acc: 0.8592\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 46s 9ms/step - loss: 0.1489 - acc: 0.9469 - val_loss: 0.5043 - val_acc: 0.8768\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1443 - acc: 0.9463 - val_loss: 0.5952 - val_acc: 0.8717\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1250 - acc: 0.9553 - val_loss: 0.4851 - val_acc: 0.8853\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1219 - acc: 0.9545 - val_loss: 0.4948 - val_acc: 0.8860\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1253 - acc: 0.9512 - val_loss: 0.8164 - val_acc: 0.8626\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1218 - acc: 0.9551 - val_loss: 0.6725 - val_acc: 0.8480\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1180 - acc: 0.9545 - val_loss: 0.6107 - val_acc: 0.8721\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1202 - acc: 0.9539 - val_loss: 0.5251 - val_acc: 0.8877\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1204 - acc: 0.9549 - val_loss: 0.5632 - val_acc: 0.8738\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1147 - acc: 0.9586 - val_loss: 0.5313 - val_acc: 0.8806\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1203 - acc: 0.9551 - val_loss: 0.4822 - val_acc: 0.8877\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1131 - acc: 0.9563 - val_loss: 0.5289 - val_acc: 0.8643\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1153 - acc: 0.9543 - val_loss: 0.4598 - val_acc: 0.8907\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 81s 16ms/step - loss: 1.3656 - acc: 0.3849 - val_loss: 1.3745 - val_acc: 0.3797\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 1.1385 - acc: 0.4614 - val_loss: 1.5755 - val_acc: 0.4035\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.9958 - acc: 0.5239 - val_loss: 1.7361 - val_acc: 0.4204\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7936 - acc: 0.6253 - val_loss: 0.8832 - val_acc: 0.5670\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6617 - acc: 0.6677 - val_loss: 0.8134 - val_acc: 0.6804\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5617 - acc: 0.7375 - val_loss: 0.8764 - val_acc: 0.6077\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4821 - acc: 0.7572 - val_loss: 1.0712 - val_acc: 0.5847\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.4324 - acc: 0.7691 - val_loss: 0.6459 - val_acc: 0.7129\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.3782 - acc: 0.8166 - val_loss: 0.5521 - val_acc: 0.8137\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.3474 - acc: 0.8670 - val_loss: 0.8859 - val_acc: 0.7129\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2926 - acc: 0.8905 - val_loss: 0.5502 - val_acc: 0.8178\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2458 - acc: 0.9086 - val_loss: 0.9623 - val_acc: 0.7282\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2090 - acc: 0.9239 - val_loss: 0.4205 - val_acc: 0.8690\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2159 - acc: 0.9196 - val_loss: 0.4128 - val_acc: 0.8697\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1745 - acc: 0.9286 - val_loss: 0.4602 - val_acc: 0.8670\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1653 - acc: 0.9327 - val_loss: 0.7885 - val_acc: 0.7540\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1643 - acc: 0.9345 - val_loss: 0.6469 - val_acc: 0.8412\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1537 - acc: 0.9408 - val_loss: 0.4782 - val_acc: 0.8843\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1537 - acc: 0.9410 - val_loss: 0.4339 - val_acc: 0.8836\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1382 - acc: 0.9419 - val_loss: 0.4332 - val_acc: 0.8870\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1534 - acc: 0.9404 - val_loss: 0.4736 - val_acc: 0.8812\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1358 - acc: 0.9455 - val_loss: 0.4329 - val_acc: 0.8897\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1453 - acc: 0.9406 - val_loss: 0.3936 - val_acc: 0.8979\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1035 - acc: 0.9508 - val_loss: 0.4312 - val_acc: 0.8826\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1247 - acc: 0.9519 - val_loss: 0.5972 - val_acc: 0.8694\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1236 - acc: 0.9494 - val_loss: 0.3769 - val_acc: 0.8935\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 46s 9ms/step - loss: 0.1214 - acc: 0.9496 - val_loss: 0.4737 - val_acc: 0.8968\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1215 - acc: 0.9519 - val_loss: 0.4453 - val_acc: 0.8894\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1219 - acc: 0.9498 - val_loss: 0.4990 - val_acc: 0.9006\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1209 - acc: 0.9502 - val_loss: 0.4706 - val_acc: 0.8856\n",
      "2450/2450 [==============================] - 5s 2ms/step\n",
      "4902/4902 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 89s 18ms/step - loss: 1.6234 - acc: 0.3193 - val_loss: 1.4426 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.4024 - acc: 0.3795 - val_loss: 1.3813 - val_acc: 0.3397\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3197 - acc: 0.4034 - val_loss: 1.3583 - val_acc: 0.3566\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1757 - acc: 0.4507 - val_loss: 1.1470 - val_acc: 0.4150\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.9834 - acc: 0.5246 - val_loss: 0.9675 - val_acc: 0.5640\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8418 - acc: 0.6062 - val_loss: 0.8462 - val_acc: 0.5721\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7224 - acc: 0.6260 - val_loss: 0.8083 - val_acc: 0.5765\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7243 - acc: 0.6358 - val_loss: 0.8142 - val_acc: 0.5918\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7091 - acc: 0.6429 - val_loss: 0.7803 - val_acc: 0.6084\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6969 - acc: 0.6352 - val_loss: 0.7842 - val_acc: 0.6145\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6645 - acc: 0.6554 - val_loss: 0.8571 - val_acc: 0.6088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6849 - acc: 0.6415 - val_loss: 0.7623 - val_acc: 0.6166\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6718 - acc: 0.6515 - val_loss: 0.8544 - val_acc: 0.5847\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7088 - acc: 0.6337 - val_loss: 0.7583 - val_acc: 0.6223\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5929 - acc: 0.6868 - val_loss: 0.7695 - val_acc: 0.6427\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5948 - acc: 0.7343 - val_loss: 0.6684 - val_acc: 0.7438\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5062 - acc: 0.8092 - val_loss: 0.6543 - val_acc: 0.7591\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.4169 - acc: 0.8351 - val_loss: 0.5517 - val_acc: 0.7961\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3772 - acc: 0.8557 - val_loss: 0.4641 - val_acc: 0.8714\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.3056 - acc: 0.8921 - val_loss: 0.5484 - val_acc: 0.8334\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2727 - acc: 0.9047 - val_loss: 0.5563 - val_acc: 0.8096\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.2541 - acc: 0.9117 - val_loss: 0.4070 - val_acc: 0.8829\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.3257 - acc: 0.8810 - val_loss: 0.4231 - val_acc: 0.8816\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.2455 - acc: 0.9202 - val_loss: 0.4522 - val_acc: 0.8789\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.2073 - acc: 0.9294 - val_loss: 0.5373 - val_acc: 0.8639\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1938 - acc: 0.9347 - val_loss: 0.3073 - val_acc: 0.9013\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1981 - acc: 0.9312 - val_loss: 0.3496 - val_acc: 0.8724\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1838 - acc: 0.9329 - val_loss: 0.3748 - val_acc: 0.9016\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1625 - acc: 0.9439 - val_loss: 0.4564 - val_acc: 0.8761\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.1588 - acc: 0.9429 - val_loss: 0.3532 - val_acc: 0.8965\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 94s 19ms/step - loss: 1.4980 - acc: 0.3432 - val_loss: 1.3668 - val_acc: 0.3529\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 60s 12ms/step - loss: 1.3146 - acc: 0.3969 - val_loss: 1.3181 - val_acc: 0.3831\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2265 - acc: 0.3969 - val_loss: 1.0521 - val_acc: 0.3386\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 1.1259 - acc: 0.4558 - val_loss: 1.2158 - val_acc: 0.4320\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.9881 - acc: 0.5013 - val_loss: 0.9447 - val_acc: 0.5938\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8541 - acc: 0.6170 - val_loss: 0.9390 - val_acc: 0.5901\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7183 - acc: 0.6476 - val_loss: 0.8851 - val_acc: 0.6172\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.8746 - acc: 0.5921 - val_loss: 0.8770 - val_acc: 0.5833\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6592 - acc: 0.6488 - val_loss: 0.9149 - val_acc: 0.5898\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6513 - acc: 0.6666 - val_loss: 0.7987 - val_acc: 0.6295\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6361 - acc: 0.7086 - val_loss: 0.7041 - val_acc: 0.6637\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.5973 - acc: 0.7307 - val_loss: 0.7685 - val_acc: 0.6675\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5300 - acc: 0.7592 - val_loss: 0.8322 - val_acc: 0.6719\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4816 - acc: 0.7788 - val_loss: 0.7004 - val_acc: 0.7343\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4543 - acc: 0.8051 - val_loss: 0.5836 - val_acc: 0.7852\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4098 - acc: 0.8192 - val_loss: 0.5227 - val_acc: 0.8439\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3749 - acc: 0.8517 - val_loss: 0.5098 - val_acc: 0.8147\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2951 - acc: 0.9096 - val_loss: 0.4196 - val_acc: 0.8785\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2838 - acc: 0.9053 - val_loss: 0.4471 - val_acc: 0.8711\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3286 - acc: 0.8933 - val_loss: 0.8548 - val_acc: 0.7136\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2560 - acc: 0.9098 - val_loss: 0.3965 - val_acc: 0.8928\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1884 - acc: 0.9359 - val_loss: 0.4286 - val_acc: 0.8792\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1698 - acc: 0.9400 - val_loss: 0.4293 - val_acc: 0.8724\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1506 - acc: 0.9423 - val_loss: 0.3934 - val_acc: 0.9013\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1367 - acc: 0.9453 - val_loss: 0.3695 - val_acc: 0.8887\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.1438 - acc: 0.9467 - val_loss: 0.3667 - val_acc: 0.8931\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1304 - acc: 0.9502 - val_loss: 0.3374 - val_acc: 0.8945\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1351 - acc: 0.9521 - val_loss: 0.3904 - val_acc: 0.8985\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1169 - acc: 0.9527 - val_loss: 0.3749 - val_acc: 0.8996\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1142 - acc: 0.9567 - val_loss: 0.4281 - val_acc: 0.9002\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 93s 19ms/step - loss: 1.4714 - acc: 0.3603 - val_loss: 1.4733 - val_acc: 0.3478\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3446 - acc: 0.3786 - val_loss: 1.4501 - val_acc: 0.3482\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3312 - acc: 0.3780 - val_loss: 1.4636 - val_acc: 0.3482\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.6048 - acc: 0.2982 - val_loss: 1.6385 - val_acc: 0.3627\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.5307 - acc: 0.3462 - val_loss: 1.4302 - val_acc: 0.3543\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3807 - acc: 0.3792 - val_loss: 1.4064 - val_acc: 0.3346\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3085 - acc: 0.4204 - val_loss: 1.3898 - val_acc: 0.3526\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2392 - acc: 0.4315 - val_loss: 1.3944 - val_acc: 0.3522\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2116 - acc: 0.4410 - val_loss: 1.2986 - val_acc: 0.4048\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1570 - acc: 0.4543 - val_loss: 1.2759 - val_acc: 0.3984\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1410 - acc: 0.4670 - val_loss: 2.0132 - val_acc: 0.2796\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1832 - acc: 0.4317 - val_loss: 1.5093 - val_acc: 0.4350\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.0611 - acc: 0.4853 - val_loss: 1.1958 - val_acc: 0.4343\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.9482 - acc: 0.5467 - val_loss: 1.2660 - val_acc: 0.4309\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.8885 - acc: 0.5985 - val_loss: 1.0955 - val_acc: 0.5314\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7090 - acc: 0.6308 - val_loss: 0.8244 - val_acc: 0.5806\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5967 - acc: 0.6514 - val_loss: 0.6999 - val_acc: 0.6020\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5583 - acc: 0.6761 - val_loss: 0.6946 - val_acc: 0.5952\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5465 - acc: 0.6973 - val_loss: 0.7580 - val_acc: 0.6759\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5403 - acc: 0.7401 - val_loss: 1.2833 - val_acc: 0.6135\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4929 - acc: 0.7768 - val_loss: 0.6535 - val_acc: 0.7421\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4337 - acc: 0.7901 - val_loss: 0.5580 - val_acc: 0.7248\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3861 - acc: 0.7917 - val_loss: 0.5038 - val_acc: 0.7533\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3540 - acc: 0.8178 - val_loss: 0.6375 - val_acc: 0.7204\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.3178 - acc: 0.8460 - val_loss: 0.4829 - val_acc: 0.8056\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2889 - acc: 0.8933 - val_loss: 0.5074 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2150 - acc: 0.9241 - val_loss: 0.4617 - val_acc: 0.8599\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2458 - acc: 0.9068 - val_loss: 0.7019 - val_acc: 0.7075\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.2485 - acc: 0.9045 - val_loss: 0.5239 - val_acc: 0.8466\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.1550 - acc: 0.9400 - val_loss: 0.4480 - val_acc: 0.8778\n",
      "2450/2450 [==============================] - 7s 3ms/step\n",
      "4902/4902 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 107s 22ms/step - loss: 1.4002 - acc: 0.3807 - val_loss: 1.4187 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2774 - acc: 0.4391 - val_loss: 1.2718 - val_acc: 0.4303\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.1717 - acc: 0.4864 - val_loss: 2.4326 - val_acc: 0.2789\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.1731 - acc: 0.4801 - val_loss: 1.1153 - val_acc: 0.4455\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.0233 - acc: 0.4677 - val_loss: 1.1085 - val_acc: 0.4364\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.8931 - acc: 0.5393 - val_loss: 0.9041 - val_acc: 0.5914\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8777 - acc: 0.6101 - val_loss: 0.8845 - val_acc: 0.6060\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8927 - acc: 0.6050 - val_loss: 1.2396 - val_acc: 0.4197\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8890 - acc: 0.6001 - val_loss: 0.8517 - val_acc: 0.6101\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.7460 - acc: 0.6513 - val_loss: 0.8375 - val_acc: 0.6091\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.6771 - acc: 0.6513 - val_loss: 0.9988 - val_acc: 0.4608\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.6385 - acc: 0.6586 - val_loss: 0.6796 - val_acc: 0.6162\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6368 - acc: 0.6831 - val_loss: 0.6034 - val_acc: 0.7129\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.5461 - acc: 0.7535 - val_loss: 0.5409 - val_acc: 0.7336\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5359 - acc: 0.7390 - val_loss: 0.6488 - val_acc: 0.6926\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.4762 - acc: 0.7876 - val_loss: 0.6618 - val_acc: 0.7184\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.3790 - acc: 0.8370 - val_loss: 0.5648 - val_acc: 0.7615\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.3764 - acc: 0.8743 - val_loss: 0.3696 - val_acc: 0.8653\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2425 - acc: 0.9204 - val_loss: 0.9418 - val_acc: 0.7720\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.2119 - acc: 0.9261 - val_loss: 0.3528 - val_acc: 0.8772\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1834 - acc: 0.9319 - val_loss: 0.2743 - val_acc: 0.8996\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1857 - acc: 0.9349 - val_loss: 0.2870 - val_acc: 0.9013\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1693 - acc: 0.9394 - val_loss: 0.3767 - val_acc: 0.8870\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1797 - acc: 0.9357 - val_loss: 0.2621 - val_acc: 0.9033\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1901 - acc: 0.9372 - val_loss: 0.3703 - val_acc: 0.8839\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2175 - acc: 0.9204 - val_loss: 0.3659 - val_acc: 0.8945\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1529 - acc: 0.9414 - val_loss: 0.2676 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1563 - acc: 0.9429 - val_loss: 0.2507 - val_acc: 0.9145\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1533 - acc: 0.9423 - val_loss: 0.2576 - val_acc: 0.9247\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1466 - acc: 0.9461 - val_loss: 0.2244 - val_acc: 0.9243\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 16s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 108s 22ms/step - loss: 1.3980 - acc: 0.3632 - val_loss: 1.3811 - val_acc: 0.3414\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.3259 - acc: 0.4009 - val_loss: 1.5006 - val_acc: 0.3312\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.1955 - acc: 0.4591 - val_loss: 1.2106 - val_acc: 0.4635\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2897 - acc: 0.4540 - val_loss: 1.3473 - val_acc: 0.4048\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 1.0103 - acc: 0.5640 - val_loss: 0.9398 - val_acc: 0.6312\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.8534 - acc: 0.6276 - val_loss: 0.8675 - val_acc: 0.6318\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.7221 - acc: 0.6862 - val_loss: 1.7167 - val_acc: 0.4255\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.7200 - acc: 0.7092 - val_loss: 1.1100 - val_acc: 0.5986\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.6561 - acc: 0.7272 - val_loss: 0.7405 - val_acc: 0.7245\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.5395 - acc: 0.7756 - val_loss: 0.6479 - val_acc: 0.7472\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.4057 - acc: 0.8513 - val_loss: 0.7330 - val_acc: 0.7638\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.2683 - acc: 0.9190 - val_loss: 0.5367 - val_acc: 0.8544\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2350 - acc: 0.9223 - val_loss: 0.6379 - val_acc: 0.8368\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1867 - acc: 0.9380 - val_loss: 0.4894 - val_acc: 0.8721\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1786 - acc: 0.9408 - val_loss: 0.5531 - val_acc: 0.8341\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1588 - acc: 0.9449 - val_loss: 0.6665 - val_acc: 0.8147\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.3238 - acc: 0.9137 - val_loss: 0.7422 - val_acc: 0.7693\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1750 - acc: 0.9386 - val_loss: 0.5153 - val_acc: 0.8792\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1483 - acc: 0.9488 - val_loss: 0.5767 - val_acc: 0.8677\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1302 - acc: 0.9504 - val_loss: 0.5341 - val_acc: 0.8612\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1355 - acc: 0.9469 - val_loss: 0.9362 - val_acc: 0.7659\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1221 - acc: 0.9523 - val_loss: 0.5248 - val_acc: 0.8833\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1427 - acc: 0.9514 - val_loss: 0.5314 - val_acc: 0.8901\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1110 - acc: 0.9578 - val_loss: 0.3834 - val_acc: 0.8877\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1377 - acc: 0.9529 - val_loss: 0.5788 - val_acc: 0.8633\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.1071 - acc: 0.9547 - val_loss: 0.4982 - val_acc: 0.8765\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1045 - acc: 0.9563 - val_loss: 0.5443 - val_acc: 0.8738\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1156 - acc: 0.9572 - val_loss: 0.5916 - val_acc: 0.8707\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1353 - acc: 0.9553 - val_loss: 0.6102 - val_acc: 0.8728\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1093 - acc: 0.9561 - val_loss: 0.5653 - val_acc: 0.8799\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 110s 22ms/step - loss: 1.4349 - acc: 0.3672 - val_loss: 1.4590 - val_acc: 0.3492\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 1.2713 - acc: 0.4049 - val_loss: 1.2956 - val_acc: 0.4418\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 1.0545 - acc: 0.5355 - val_loss: 0.9762 - val_acc: 0.5789\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.8509 - acc: 0.6075 - val_loss: 0.9728 - val_acc: 0.5283\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.7806 - acc: 0.6155 - val_loss: 1.0830 - val_acc: 0.5382\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.7160 - acc: 0.6391 - val_loss: 0.8633 - val_acc: 0.5891\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.7051 - acc: 0.6444 - val_loss: 0.7519 - val_acc: 0.6407\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6550 - acc: 0.6705 - val_loss: 0.7747 - val_acc: 0.6586\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6608 - acc: 0.6863 - val_loss: 0.9302 - val_acc: 0.6223\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.6248 - acc: 0.7064 - val_loss: 0.8926 - val_acc: 0.6091\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.5629 - acc: 0.7293 - val_loss: 0.6452 - val_acc: 0.7092\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.4593 - acc: 0.7756 - val_loss: 0.6018 - val_acc: 0.7309\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.3843 - acc: 0.8091 - val_loss: 0.5540 - val_acc: 0.7669\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.3329 - acc: 0.8527 - val_loss: 0.4977 - val_acc: 0.7771\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.2664 - acc: 0.9035 - val_loss: 0.6391 - val_acc: 0.8107\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1958 - acc: 0.9298 - val_loss: 0.8402 - val_acc: 0.7879\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1746 - acc: 0.9323 - val_loss: 0.4367 - val_acc: 0.8975\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1755 - acc: 0.9361 - val_loss: 0.4033 - val_acc: 0.8799\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1431 - acc: 0.9447 - val_loss: 0.3743 - val_acc: 0.8921\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1435 - acc: 0.9445 - val_loss: 0.4864 - val_acc: 0.8863\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1368 - acc: 0.9468 - val_loss: 0.4573 - val_acc: 0.9036\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1421 - acc: 0.9437 - val_loss: 0.4226 - val_acc: 0.9121\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1241 - acc: 0.9506 - val_loss: 0.4759 - val_acc: 0.8941\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1223 - acc: 0.9470 - val_loss: 0.4105 - val_acc: 0.8907\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1226 - acc: 0.9457 - val_loss: 0.4832 - val_acc: 0.9080\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1289 - acc: 0.9484 - val_loss: 0.5302 - val_acc: 0.8860\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1293 - acc: 0.9474 - val_loss: 0.5159 - val_acc: 0.8921\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1164 - acc: 0.9488 - val_loss: 0.4703 - val_acc: 0.8928\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 69s 14ms/step - loss: 0.1160 - acc: 0.9533 - val_loss: 0.4131 - val_acc: 0.9158\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 68s 14ms/step - loss: 0.1573 - acc: 0.9415 - val_loss: 0.4338 - val_acc: 0.8951\n",
      "2450/2450 [==============================] - 8s 3ms/step\n",
      "4902/4902 [==============================] - 17s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 72s 15ms/step - loss: 1.4525 - acc: 0.3756 - val_loss: 1.4068 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.3173 - acc: 0.3911 - val_loss: 1.3158 - val_acc: 0.3804\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.1968 - acc: 0.4630 - val_loss: 1.2106 - val_acc: 0.4313\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.0841 - acc: 0.4756 - val_loss: 1.0718 - val_acc: 0.4462\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 1.0437 - acc: 0.4879 - val_loss: 1.1103 - val_acc: 0.4225\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.9708 - acc: 0.5046 - val_loss: 0.9687 - val_acc: 0.4153\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.9281 - acc: 0.5525 - val_loss: 0.9959 - val_acc: 0.5395\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.9449 - acc: 0.5711 - val_loss: 0.9365 - val_acc: 0.5976\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.8530 - acc: 0.6119 - val_loss: 1.0716 - val_acc: 0.5059\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.8004 - acc: 0.6168 - val_loss: 1.1059 - val_acc: 0.4445\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.7658 - acc: 0.6158 - val_loss: 0.8547 - val_acc: 0.5436\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6869 - acc: 0.6417 - val_loss: 0.7914 - val_acc: 0.6020\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.7149 - acc: 0.6401 - val_loss: 0.7827 - val_acc: 0.6115\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6460 - acc: 0.6562 - val_loss: 0.7053 - val_acc: 0.6356\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6388 - acc: 0.6554 - val_loss: 0.9243 - val_acc: 0.5945\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6765 - acc: 0.6499 - val_loss: 0.8573 - val_acc: 0.5826\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.6187 - acc: 0.6586 - val_loss: 0.7183 - val_acc: 0.6362\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.5738 - acc: 0.6786 - val_loss: 0.7980 - val_acc: 0.6128\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.5629 - acc: 0.6854 - val_loss: 0.8003 - val_acc: 0.6427\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.5131 - acc: 0.7235 - val_loss: 0.7686 - val_acc: 0.6739\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.5234 - acc: 0.7374 - val_loss: 1.1603 - val_acc: 0.6010\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.4586 - acc: 0.7770 - val_loss: 0.6939 - val_acc: 0.7313\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.4197 - acc: 0.8104 - val_loss: 0.7587 - val_acc: 0.7482\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.3625 - acc: 0.8435 - val_loss: 0.6168 - val_acc: 0.8079\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.3673 - acc: 0.8741 - val_loss: 0.5634 - val_acc: 0.8347\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.3401 - acc: 0.9008 - val_loss: 0.5378 - val_acc: 0.8446\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 35s 7ms/step - loss: 0.3236 - acc: 0.9135 - val_loss: 0.4653 - val_acc: 0.8612\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.3225 - acc: 0.9190 - val_loss: 0.4706 - val_acc: 0.8639\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.2689 - acc: 0.9249 - val_loss: 0.3703 - val_acc: 0.8666\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 34s 7ms/step - loss: 0.2060 - acc: 0.9339 - val_loss: 0.3829 - val_acc: 0.8683\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 71s 15ms/step - loss: 1.4671 - acc: 0.3471 - val_loss: 1.4229 - val_acc: 0.3397\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.3488 - acc: 0.3536 - val_loss: 1.4296 - val_acc: 0.3957\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.3501 - acc: 0.3597 - val_loss: 1.4751 - val_acc: 0.3448\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.3177 - acc: 0.3640 - val_loss: 1.3736 - val_acc: 0.3451\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.2508 - acc: 0.4315 - val_loss: 1.2123 - val_acc: 0.4659\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 1.0438 - acc: 0.5101 - val_loss: 1.0673 - val_acc: 0.4897\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.9172 - acc: 0.5340 - val_loss: 0.9183 - val_acc: 0.5721\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.7963 - acc: 0.5987 - val_loss: 0.8480 - val_acc: 0.5884\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6720 - acc: 0.6264 - val_loss: 0.8020 - val_acc: 0.6006\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.6302 - acc: 0.6442 - val_loss: 0.8305 - val_acc: 0.6040\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5805 - acc: 0.6546 - val_loss: 0.6972 - val_acc: 0.6508\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5273 - acc: 0.6762 - val_loss: 0.7289 - val_acc: 0.6332\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.5145 - acc: 0.6895 - val_loss: 0.7360 - val_acc: 0.6352\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4717 - acc: 0.7035 - val_loss: 0.7198 - val_acc: 0.6444\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4631 - acc: 0.7407 - val_loss: 0.6644 - val_acc: 0.7564\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4474 - acc: 0.7760 - val_loss: 0.8724 - val_acc: 0.7190\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4186 - acc: 0.8227 - val_loss: 0.6656 - val_acc: 0.7727\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.4144 - acc: 0.8172 - val_loss: 0.5902 - val_acc: 0.8436\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.3434 - acc: 0.8672 - val_loss: 0.5317 - val_acc: 0.8446\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2900 - acc: 0.9127 - val_loss: 0.6037 - val_acc: 0.8504\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2479 - acc: 0.9190 - val_loss: 0.5402 - val_acc: 0.8470\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.2068 - acc: 0.9376 - val_loss: 0.5202 - val_acc: 0.8751\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1923 - acc: 0.9347 - val_loss: 0.4562 - val_acc: 0.8778\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1937 - acc: 0.9394 - val_loss: 0.5733 - val_acc: 0.8734\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1730 - acc: 0.9451 - val_loss: 0.6685 - val_acc: 0.8605\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1802 - acc: 0.9402 - val_loss: 0.5254 - val_acc: 0.8860\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1565 - acc: 0.9492 - val_loss: 0.5004 - val_acc: 0.8856\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1634 - acc: 0.9459 - val_loss: 0.6331 - val_acc: 0.8724\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1519 - acc: 0.9498 - val_loss: 0.8460 - val_acc: 0.8480\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 33s 7ms/step - loss: 0.1502 - acc: 0.9496 - val_loss: 0.5521 - val_acc: 0.8904\n",
      "2451/2451 [==============================] - 4s 1ms/step\n",
      "4901/4901 [==============================] - 7s 1ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 71s 15ms/step - loss: 1.4434 - acc: 0.3986 - val_loss: 1.3655 - val_acc: 0.3702\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 1.1789 - acc: 0.4757 - val_loss: 1.3072 - val_acc: 0.4377\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9939 - acc: 0.5610 - val_loss: 1.0464 - val_acc: 0.5199\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.9068 - acc: 0.6261 - val_loss: 1.0851 - val_acc: 0.5141\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.8245 - acc: 0.6308 - val_loss: 0.7797 - val_acc: 0.6705\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7295 - acc: 0.6722 - val_loss: 0.9028 - val_acc: 0.6356\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.7050 - acc: 0.6797 - val_loss: 0.6915 - val_acc: 0.7187\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.6351 - acc: 0.7350 - val_loss: 0.7676 - val_acc: 0.6943\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5985 - acc: 0.7440 - val_loss: 0.6471 - val_acc: 0.7384\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5746 - acc: 0.7489 - val_loss: 0.6359 - val_acc: 0.7150\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.5010 - acc: 0.7687 - val_loss: 0.6278 - val_acc: 0.7377\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4574 - acc: 0.7772 - val_loss: 0.5389 - val_acc: 0.7469\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4564 - acc: 0.7795 - val_loss: 0.5872 - val_acc: 0.7258\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4268 - acc: 0.7870 - val_loss: 0.5456 - val_acc: 0.7530\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.4274 - acc: 0.7891 - val_loss: 0.6896 - val_acc: 0.6949\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 34s 7ms/step - loss: 0.4130 - acc: 0.8237 - val_loss: 0.4551 - val_acc: 0.8157\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3561 - acc: 0.8721 - val_loss: 0.5832 - val_acc: 0.8239\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.3356 - acc: 0.8953 - val_loss: 0.4102 - val_acc: 0.8680\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2616 - acc: 0.9184 - val_loss: 0.4021 - val_acc: 0.8711\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2383 - acc: 0.9278 - val_loss: 0.3603 - val_acc: 0.8711\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2025 - acc: 0.9304 - val_loss: 0.5670 - val_acc: 0.8636\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2196 - acc: 0.9300 - val_loss: 0.2826 - val_acc: 0.8996\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.2230 - acc: 0.9319 - val_loss: 0.3090 - val_acc: 0.9009\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1889 - acc: 0.9327 - val_loss: 0.2975 - val_acc: 0.9141\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1637 - acc: 0.9388 - val_loss: 0.2823 - val_acc: 0.9033\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1794 - acc: 0.9341 - val_loss: 0.2592 - val_acc: 0.9111\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1775 - acc: 0.9398 - val_loss: 0.2975 - val_acc: 0.8996\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1567 - acc: 0.9372 - val_loss: 0.4427 - val_acc: 0.8721\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1540 - acc: 0.9402 - val_loss: 0.2973 - val_acc: 0.9026\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 33s 7ms/step - loss: 0.1503 - acc: 0.9433 - val_loss: 0.3659 - val_acc: 0.8812\n",
      "2450/2450 [==============================] - 4s 1ms/step\n",
      "4902/4902 [==============================] - 7s 1ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 83s 17ms/step - loss: 1.3588 - acc: 0.4215 - val_loss: 1.2437 - val_acc: 0.4282\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 1.0883 - acc: 0.5274 - val_loss: 1.2128 - val_acc: 0.5643\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.9018 - acc: 0.6072 - val_loss: 0.8577 - val_acc: 0.6624\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.7315 - acc: 0.6452 - val_loss: 0.9600 - val_acc: 0.5507\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.9043 - acc: 0.5738 - val_loss: 0.9491 - val_acc: 0.5765\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.7238 - acc: 0.6572 - val_loss: 0.8011 - val_acc: 0.6315\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.6763 - acc: 0.6878 - val_loss: 0.8039 - val_acc: 0.6817\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.6166 - acc: 0.7192 - val_loss: 0.7248 - val_acc: 0.7265\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.5188 - acc: 0.7629 - val_loss: 0.7238 - val_acc: 0.6719\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.5455 - acc: 0.7533 - val_loss: 0.4812 - val_acc: 0.7594\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4182 - acc: 0.7947 - val_loss: 1.2115 - val_acc: 0.6111\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.4321 - acc: 0.8182 - val_loss: 0.5274 - val_acc: 0.7984\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.3488 - acc: 0.8700 - val_loss: 0.5061 - val_acc: 0.7947\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.3197 - acc: 0.8955 - val_loss: 0.3852 - val_acc: 0.8775\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2604 - acc: 0.9100 - val_loss: 0.3616 - val_acc: 0.8928\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2279 - acc: 0.9206 - val_loss: 0.4168 - val_acc: 0.8717\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2072 - acc: 0.9206 - val_loss: 0.3978 - val_acc: 0.8887\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1958 - acc: 0.9335 - val_loss: 0.3682 - val_acc: 0.8870\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2008 - acc: 0.9314 - val_loss: 0.3638 - val_acc: 0.8914\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1905 - acc: 0.9331 - val_loss: 0.4156 - val_acc: 0.8897\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 46s 9ms/step - loss: 0.2095 - acc: 0.9296 - val_loss: 0.6208 - val_acc: 0.8358\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1982 - acc: 0.9290 - val_loss: 0.3872 - val_acc: 0.8829\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1779 - acc: 0.9319 - val_loss: 0.3229 - val_acc: 0.8931\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1607 - acc: 0.9404 - val_loss: 0.2877 - val_acc: 0.9067\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1620 - acc: 0.9386 - val_loss: 0.3377 - val_acc: 0.9002\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1800 - acc: 0.9296 - val_loss: 0.3995 - val_acc: 0.8870\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1727 - acc: 0.9396 - val_loss: 0.4755 - val_acc: 0.8829\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 46s 9ms/step - loss: 0.1526 - acc: 0.9423 - val_loss: 0.2983 - val_acc: 0.9213\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1492 - acc: 0.9418 - val_loss: 0.3603 - val_acc: 0.9101\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 46s 9ms/step - loss: 0.1777 - acc: 0.9321 - val_loss: 0.3943 - val_acc: 0.9019\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 87s 18ms/step - loss: 1.3710 - acc: 0.4220 - val_loss: 1.2302 - val_acc: 0.4459\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 1.1132 - acc: 0.4936 - val_loss: 1.2043 - val_acc: 0.4381\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.9859 - acc: 0.5670 - val_loss: 1.0423 - val_acc: 0.5422\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.8836 - acc: 0.5858 - val_loss: 0.8841 - val_acc: 0.5928\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.7722 - acc: 0.6264 - val_loss: 0.8229 - val_acc: 0.6478\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.6723 - acc: 0.6701 - val_loss: 0.7674 - val_acc: 0.6064\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.6024 - acc: 0.7248 - val_loss: 0.6728 - val_acc: 0.7248\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.5263 - acc: 0.7654 - val_loss: 0.6008 - val_acc: 0.7550\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4571 - acc: 0.7853 - val_loss: 0.5012 - val_acc: 0.7710\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4137 - acc: 0.7870 - val_loss: 0.7196 - val_acc: 0.7346\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4120 - acc: 0.7925 - val_loss: 1.2314 - val_acc: 0.6630\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.4658 - acc: 0.7984 - val_loss: 0.5986 - val_acc: 0.7455\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.3313 - acc: 0.8715 - val_loss: 0.5081 - val_acc: 0.8310\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.2464 - acc: 0.9131 - val_loss: 0.4468 - val_acc: 0.8629\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.2097 - acc: 0.9280 - val_loss: 0.4435 - val_acc: 0.8561\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.3154 - acc: 0.9110 - val_loss: 0.5003 - val_acc: 0.8283\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1929 - acc: 0.9335 - val_loss: 0.9619 - val_acc: 0.7374\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1988 - acc: 0.9294 - val_loss: 0.4257 - val_acc: 0.8819\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1683 - acc: 0.9400 - val_loss: 0.4695 - val_acc: 0.8595\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1329 - acc: 0.9510 - val_loss: 0.6234 - val_acc: 0.8483\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1457 - acc: 0.9494 - val_loss: 0.4960 - val_acc: 0.8663\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1405 - acc: 0.9500 - val_loss: 0.5138 - val_acc: 0.8741\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1502 - acc: 0.9457 - val_loss: 0.5220 - val_acc: 0.8836\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1198 - acc: 0.9529 - val_loss: 0.4802 - val_acc: 0.8711\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1267 - acc: 0.9516 - val_loss: 0.5349 - val_acc: 0.8765\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1149 - acc: 0.9541 - val_loss: 0.6495 - val_acc: 0.8636\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1181 - acc: 0.9574 - val_loss: 0.7046 - val_acc: 0.8619\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 44s 9ms/step - loss: 0.1148 - acc: 0.9561 - val_loss: 0.6374 - val_acc: 0.8680\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1110 - acc: 0.9545 - val_loss: 0.6737 - val_acc: 0.8836\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 45s 9ms/step - loss: 0.1275 - acc: 0.9537 - val_loss: 0.7230 - val_acc: 0.8619\n",
      "2451/2451 [==============================] - 5s 2ms/step\n",
      "4901/4901 [==============================] - 10s 2ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 85s 17ms/step - loss: 1.3462 - acc: 0.4162 - val_loss: 1.3314 - val_acc: 0.3756\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 1.0790 - acc: 0.5139 - val_loss: 0.9924 - val_acc: 0.5769\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.8600 - acc: 0.6010 - val_loss: 0.8795 - val_acc: 0.6105\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7596 - acc: 0.6397 - val_loss: 0.8499 - val_acc: 0.5850\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.7584 - acc: 0.6479 - val_loss: 1.3959 - val_acc: 0.4713\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.6727 - acc: 0.7081 - val_loss: 0.7202 - val_acc: 0.7241\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5889 - acc: 0.7424 - val_loss: 0.7473 - val_acc: 0.7082\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5337 - acc: 0.7491 - val_loss: 0.6824 - val_acc: 0.7241\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.5014 - acc: 0.7687 - val_loss: 0.7101 - val_acc: 0.6926\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.5179 - acc: 0.7919 - val_loss: 0.7242 - val_acc: 0.7397\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3884 - acc: 0.8621 - val_loss: 0.5649 - val_acc: 0.8168\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3610 - acc: 0.8752 - val_loss: 0.8393 - val_acc: 0.7319\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.3546 - acc: 0.8713 - val_loss: 0.4713 - val_acc: 0.8422\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.2528 - acc: 0.9106 - val_loss: 0.4492 - val_acc: 0.8426\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2297 - acc: 0.9198 - val_loss: 0.4421 - val_acc: 0.8649\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.2171 - acc: 0.9170 - val_loss: 0.5216 - val_acc: 0.8446\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1716 - acc: 0.9339 - val_loss: 0.4683 - val_acc: 0.8853\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 47s 10ms/step - loss: 0.1792 - acc: 0.9280 - val_loss: 0.3396 - val_acc: 0.8996\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1545 - acc: 0.9396 - val_loss: 0.3757 - val_acc: 0.8982\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1573 - acc: 0.9359 - val_loss: 0.3130 - val_acc: 0.9043\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1541 - acc: 0.9327 - val_loss: 0.3607 - val_acc: 0.8839\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1619 - acc: 0.9380 - val_loss: 0.4911 - val_acc: 0.9040\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1598 - acc: 0.9433 - val_loss: 0.3662 - val_acc: 0.9067\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1284 - acc: 0.9459 - val_loss: 0.4659 - val_acc: 0.8890\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1324 - acc: 0.9459 - val_loss: 0.3544 - val_acc: 0.9002\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1403 - acc: 0.9425 - val_loss: 0.3662 - val_acc: 0.8975\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1190 - acc: 0.9480 - val_loss: 0.2859 - val_acc: 0.8999\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902/4902 [==============================] - 45s 9ms/step - loss: 0.1307 - acc: 0.9390 - val_loss: 0.3861 - val_acc: 0.8901\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1236 - acc: 0.9498 - val_loss: 0.3399 - val_acc: 0.8918\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 44s 9ms/step - loss: 0.1206 - acc: 0.9496 - val_loss: 0.3212 - val_acc: 0.8989\n",
      "2450/2450 [==============================] - 5s 2ms/step\n",
      "4902/4902 [==============================] - 10s 2ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 95s 19ms/step - loss: 1.4942 - acc: 0.3646 - val_loss: 1.4159 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.7309 - acc: 0.3399 - val_loss: 2.1672 - val_acc: 0.1849\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.4829 - acc: 0.3530 - val_loss: 1.3805 - val_acc: 0.3536\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3323 - acc: 0.3909 - val_loss: 1.3237 - val_acc: 0.3627\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3299 - acc: 0.3920 - val_loss: 1.3923 - val_acc: 0.3536\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3794 - acc: 0.3948 - val_loss: 1.4214 - val_acc: 0.3536\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.4411 - acc: 0.3865 - val_loss: 1.3562 - val_acc: 0.3566\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2476 - acc: 0.4670 - val_loss: 1.2714 - val_acc: 0.4547\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 1.2060 - acc: 0.4795 - val_loss: 1.2296 - val_acc: 0.4425\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1759 - acc: 0.4805 - val_loss: 1.1712 - val_acc: 0.4381\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.0699 - acc: 0.4928 - val_loss: 1.0600 - val_acc: 0.4618\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3061 - acc: 0.4099 - val_loss: 1.4184 - val_acc: 0.3665\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3086 - acc: 0.4181 - val_loss: 1.2368 - val_acc: 0.4394\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 56s 11ms/step - loss: 1.2397 - acc: 0.4507 - val_loss: 1.5381 - val_acc: 0.3397\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1182 - acc: 0.5023 - val_loss: 1.3151 - val_acc: 0.4255\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1295 - acc: 0.4840 - val_loss: 1.1452 - val_acc: 0.4499\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1164 - acc: 0.4944 - val_loss: 1.2216 - val_acc: 0.4466\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.0118 - acc: 0.5015 - val_loss: 1.0428 - val_acc: 0.4221\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8934 - acc: 0.5674 - val_loss: 0.9185 - val_acc: 0.5707\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8099 - acc: 0.6211 - val_loss: 0.9565 - val_acc: 0.5596\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7864 - acc: 0.6299 - val_loss: 0.8160 - val_acc: 0.6037\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7014 - acc: 0.6427 - val_loss: 0.8407 - val_acc: 0.6077\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.6583 - acc: 0.6642 - val_loss: 0.8270 - val_acc: 0.6037\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6795 - acc: 0.6523 - val_loss: 0.8416 - val_acc: 0.6149\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.7051 - acc: 0.6450 - val_loss: 0.9932 - val_acc: 0.4971\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6602 - acc: 0.6574 - val_loss: 0.7683 - val_acc: 0.6223\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6267 - acc: 0.6750 - val_loss: 0.7172 - val_acc: 0.6349\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 54s 11ms/step - loss: 0.7647 - acc: 0.6415 - val_loss: 0.9519 - val_acc: 0.5959\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6169 - acc: 0.6903 - val_loss: 0.6781 - val_acc: 0.6736\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6355 - acc: 0.6848 - val_loss: 0.8059 - val_acc: 0.6240\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 99s 20ms/step - loss: 1.4689 - acc: 0.3501 - val_loss: 1.4406 - val_acc: 0.3536\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3624 - acc: 0.3648 - val_loss: 1.4468 - val_acc: 0.3448\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3180 - acc: 0.3656 - val_loss: 1.4693 - val_acc: 0.3448\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3174 - acc: 0.3683 - val_loss: 1.4389 - val_acc: 0.3329\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2644 - acc: 0.4336 - val_loss: 1.2846 - val_acc: 0.4479\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3108 - acc: 0.4195 - val_loss: 1.5206 - val_acc: 0.3390\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.3232 - acc: 0.4003 - val_loss: 1.3733 - val_acc: 0.3600\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2271 - acc: 0.4285 - val_loss: 1.2587 - val_acc: 0.4320\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.2332 - acc: 0.4487 - val_loss: 1.3157 - val_acc: 0.4584\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.1175 - acc: 0.5334 - val_loss: 1.1361 - val_acc: 0.5663\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 1.0563 - acc: 0.5715 - val_loss: 1.3389 - val_acc: 0.5148\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.8043 - acc: 0.6697 - val_loss: 0.8495 - val_acc: 0.6600\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6892 - acc: 0.7199 - val_loss: 0.7022 - val_acc: 0.7041\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.6194 - acc: 0.7462 - val_loss: 0.7239 - val_acc: 0.7011\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5295 - acc: 0.7747 - val_loss: 0.6712 - val_acc: 0.7204\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.5016 - acc: 0.7739 - val_loss: 0.6711 - val_acc: 0.7255\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4631 - acc: 0.7876 - val_loss: 0.7277 - val_acc: 0.7329\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4260 - acc: 0.8086 - val_loss: 0.6037 - val_acc: 0.7526\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4306 - acc: 0.8009 - val_loss: 0.5298 - val_acc: 0.7635\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.4007 - acc: 0.8213 - val_loss: 0.6315 - val_acc: 0.7828\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.3427 - acc: 0.8772 - val_loss: 0.6434 - val_acc: 0.8107\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2973 - acc: 0.9043 - val_loss: 0.6398 - val_acc: 0.7950\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.2535 - acc: 0.9180 - val_loss: 0.4253 - val_acc: 0.8812\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1967 - acc: 0.9392 - val_loss: 0.4776 - val_acc: 0.8809\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 56s 11ms/step - loss: 0.2020 - acc: 0.9400 - val_loss: 0.4007 - val_acc: 0.8931\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1663 - acc: 0.9429 - val_loss: 0.4796 - val_acc: 0.8812\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1637 - acc: 0.9435 - val_loss: 0.4804 - val_acc: 0.8839\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1385 - acc: 0.9506 - val_loss: 0.4263 - val_acc: 0.8968\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1687 - acc: 0.9421 - val_loss: 0.4983 - val_acc: 0.8870\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 55s 11ms/step - loss: 0.1400 - acc: 0.9516 - val_loss: 0.4374 - val_acc: 0.9016\n",
      "2451/2451 [==============================] - 7s 3ms/step\n",
      "4901/4901 [==============================] - 13s 3ms/step\n",
      "Train on 4902 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4902/4902 [==============================] - 100s 20ms/step - loss: 1.5691 - acc: 0.3411 - val_loss: 1.4012 - val_acc: 0.3573\n",
      "Epoch 2/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.4001 - acc: 0.3709 - val_loss: 1.4206 - val_acc: 0.3482\n",
      "Epoch 3/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3510 - acc: 0.3803 - val_loss: 1.4576 - val_acc: 0.3600\n",
      "Epoch 4/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3253 - acc: 0.4023 - val_loss: 1.3798 - val_acc: 0.3953\n",
      "Epoch 5/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2863 - acc: 0.4202 - val_loss: 1.3652 - val_acc: 0.4181\n",
      "Epoch 6/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2843 - acc: 0.4382 - val_loss: 1.4157 - val_acc: 0.3610\n",
      "Epoch 7/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3000 - acc: 0.4190 - val_loss: 1.4389 - val_acc: 0.4211\n",
      "Epoch 8/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2629 - acc: 0.4243 - val_loss: 1.3406 - val_acc: 0.3980\n",
      "Epoch 9/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2457 - acc: 0.4376 - val_loss: 1.3766 - val_acc: 0.4204\n",
      "Epoch 10/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3103 - acc: 0.4353 - val_loss: 1.5349 - val_acc: 0.3488\n",
      "Epoch 11/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.3203 - acc: 0.4086 - val_loss: 1.4121 - val_acc: 0.3763\n",
      "Epoch 12/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2527 - acc: 0.4270 - val_loss: 1.3621 - val_acc: 0.3977\n",
      "Epoch 13/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.4724 - acc: 0.4178 - val_loss: 1.3182 - val_acc: 0.4303\n",
      "Epoch 14/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1715 - acc: 0.4641 - val_loss: 1.4290 - val_acc: 0.4024\n",
      "Epoch 15/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.1442 - acc: 0.4804 - val_loss: 1.2277 - val_acc: 0.4588\n",
      "Epoch 16/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2589 - acc: 0.4290 - val_loss: 1.5779 - val_acc: 0.3488\n",
      "Epoch 17/30\n",
      "4902/4902 [==============================] - 56s 12ms/step - loss: 1.4085 - acc: 0.3450 - val_loss: 1.6196 - val_acc: 0.3407\n",
      "Epoch 18/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 1.2500 - acc: 0.4649 - val_loss: 1.3417 - val_acc: 0.4839\n",
      "Epoch 19/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2283 - acc: 0.4847 - val_loss: 1.3744 - val_acc: 0.4679\n",
      "Epoch 20/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.2412 - acc: 0.4765 - val_loss: 1.2486 - val_acc: 0.4930\n",
      "Epoch 21/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 1.1002 - acc: 0.5320 - val_loss: 1.1091 - val_acc: 0.5589\n",
      "Epoch 22/30\n",
      "4902/4902 [==============================] - 56s 11ms/step - loss: 0.9827 - acc: 0.5406 - val_loss: 1.0065 - val_acc: 0.5674\n",
      "Epoch 23/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.8325 - acc: 0.6089 - val_loss: 1.0735 - val_acc: 0.5317\n",
      "Epoch 24/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.8024 - acc: 0.6304 - val_loss: 0.9225 - val_acc: 0.5904\n",
      "Epoch 25/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.7421 - acc: 0.6344 - val_loss: 0.8195 - val_acc: 0.6047\n",
      "Epoch 26/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6605 - acc: 0.6771 - val_loss: 0.7292 - val_acc: 0.6729\n",
      "Epoch 27/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.6457 - acc: 0.6962 - val_loss: 0.7018 - val_acc: 0.7194\n",
      "Epoch 28/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.5199 - acc: 0.7729 - val_loss: 0.6987 - val_acc: 0.6824\n",
      "Epoch 29/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4939 - acc: 0.7654 - val_loss: 0.5949 - val_acc: 0.7214\n",
      "Epoch 30/30\n",
      "4902/4902 [==============================] - 55s 11ms/step - loss: 0.4833 - acc: 0.7699 - val_loss: 0.5702 - val_acc: 0.7540\n",
      "2450/2450 [==============================] - 7s 3ms/step\n",
      "4902/4902 [==============================] - 13s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 112s 23ms/step - loss: 1.4519 - acc: 0.3648 - val_loss: 1.3398 - val_acc: 0.3627\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.3223 - acc: 0.3895 - val_loss: 1.3305 - val_acc: 0.3610\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.2835 - acc: 0.4089 - val_loss: 1.3165 - val_acc: 0.4578\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.0769 - acc: 0.5038 - val_loss: 0.8783 - val_acc: 0.5025\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.8876 - acc: 0.5644 - val_loss: 0.9298 - val_acc: 0.5979\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7564 - acc: 0.6244 - val_loss: 0.9783 - val_acc: 0.4924\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.7349 - acc: 0.6411 - val_loss: 0.8127 - val_acc: 0.6288\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.6253 - acc: 0.7280 - val_loss: 0.8048 - val_acc: 0.6491\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.6498 - acc: 0.7474 - val_loss: 0.7697 - val_acc: 0.7085\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.4433 - acc: 0.8217 - val_loss: 0.5595 - val_acc: 0.8490\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 68s 14ms/step - loss: 0.3436 - acc: 0.8804 - val_loss: 0.5075 - val_acc: 0.8225\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2932 - acc: 0.9019 - val_loss: 0.5214 - val_acc: 0.8361\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2631 - acc: 0.9104 - val_loss: 0.4011 - val_acc: 0.8816\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2510 - acc: 0.9141 - val_loss: 0.4320 - val_acc: 0.8819\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1957 - acc: 0.9261 - val_loss: 0.4454 - val_acc: 0.8782\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2006 - acc: 0.9294 - val_loss: 0.6130 - val_acc: 0.8344\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1912 - acc: 0.9333 - val_loss: 0.3149 - val_acc: 0.8765\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1993 - acc: 0.9284 - val_loss: 0.3059 - val_acc: 0.9036\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.2037 - acc: 0.9261 - val_loss: 0.3645 - val_acc: 0.8894\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1734 - acc: 0.9388 - val_loss: 0.2648 - val_acc: 0.9108\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1696 - acc: 0.9392 - val_loss: 0.4712 - val_acc: 0.8931\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1612 - acc: 0.9384 - val_loss: 0.3781 - val_acc: 0.8962\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1561 - acc: 0.9451 - val_loss: 0.4440 - val_acc: 0.8744\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1533 - acc: 0.9418 - val_loss: 0.4460 - val_acc: 0.8802\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1580 - acc: 0.9312 - val_loss: 0.6202 - val_acc: 0.8504\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1439 - acc: 0.9480 - val_loss: 0.4002 - val_acc: 0.8938\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1616 - acc: 0.9453 - val_loss: 0.6025 - val_acc: 0.8697\n",
      "Epoch 28/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1404 - acc: 0.9469 - val_loss: 0.5905 - val_acc: 0.8476\n",
      "Epoch 29/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1543 - acc: 0.9437 - val_loss: 0.3467 - val_acc: 0.9036\n",
      "Epoch 30/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1645 - acc: 0.9365 - val_loss: 0.4407 - val_acc: 0.8968\n",
      "2451/2451 [==============================] - 8s 3ms/step\n",
      "4901/4901 [==============================] - 17s 3ms/step\n",
      "Train on 4901 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "4901/4901 [==============================] - 113s 23ms/step - loss: 1.3822 - acc: 0.3591 - val_loss: 1.5073 - val_acc: 0.3383\n",
      "Epoch 2/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.3582 - acc: 0.3622 - val_loss: 1.3940 - val_acc: 0.3546\n",
      "Epoch 3/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 1.3054 - acc: 0.4009 - val_loss: 1.3651 - val_acc: 0.3811\n",
      "Epoch 4/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 1.1558 - acc: 0.4524 - val_loss: 1.2019 - val_acc: 0.4228\n",
      "Epoch 5/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.9894 - acc: 0.5234 - val_loss: 0.9997 - val_acc: 0.5087\n",
      "Epoch 6/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.9214 - acc: 0.5968 - val_loss: 1.0475 - val_acc: 0.5348\n",
      "Epoch 7/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.6312 - acc: 0.6660 - val_loss: 0.7002 - val_acc: 0.6166\n",
      "Epoch 8/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.6669 - acc: 0.6703 - val_loss: 0.7029 - val_acc: 0.6274\n",
      "Epoch 9/30\n",
      "4901/4901 [==============================] - 71s 14ms/step - loss: 0.9282 - acc: 0.5785 - val_loss: 1.1005 - val_acc: 0.4476\n",
      "Epoch 10/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.5971 - acc: 0.7411 - val_loss: 1.5187 - val_acc: 0.4642\n",
      "Epoch 11/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.5021 - acc: 0.7741 - val_loss: 0.5648 - val_acc: 0.7441\n",
      "Epoch 12/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.4314 - acc: 0.8202 - val_loss: 0.5380 - val_acc: 0.8042\n",
      "Epoch 13/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.3486 - acc: 0.8904 - val_loss: 0.5190 - val_acc: 0.8385\n",
      "Epoch 14/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2564 - acc: 0.9174 - val_loss: 0.6892 - val_acc: 0.8205\n",
      "Epoch 15/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2509 - acc: 0.9161 - val_loss: 0.3487 - val_acc: 0.8829\n",
      "Epoch 16/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.2215 - acc: 0.9286 - val_loss: 0.5069 - val_acc: 0.8012\n",
      "Epoch 17/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1998 - acc: 0.9286 - val_loss: 0.3660 - val_acc: 0.8972\n",
      "Epoch 18/30\n",
      "4901/4901 [==============================] - 69s 14ms/step - loss: 0.1667 - acc: 0.9404 - val_loss: 0.4122 - val_acc: 0.8823\n",
      "Epoch 19/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1613 - acc: 0.9449 - val_loss: 0.3502 - val_acc: 0.9009\n",
      "Epoch 20/30\n",
      "4901/4901 [==============================] - 70s 14ms/step - loss: 0.1482 - acc: 0.9484 - val_loss: 0.3097 - val_acc: 0.9002\n",
      "Epoch 21/30\n",
      "4901/4901 [==============================] - 78s 16ms/step - loss: 0.1555 - acc: 0.9412 - val_loss: 0.5811 - val_acc: 0.8616\n",
      "Epoch 22/30\n",
      "4901/4901 [==============================] - 145s 30ms/step - loss: 0.1605 - acc: 0.9465 - val_loss: 0.3635 - val_acc: 0.8901\n",
      "Epoch 23/30\n",
      "4901/4901 [==============================] - 163s 33ms/step - loss: 0.1358 - acc: 0.9531 - val_loss: 0.5207 - val_acc: 0.8463\n",
      "Epoch 24/30\n",
      "4901/4901 [==============================] - 164s 33ms/step - loss: 0.1332 - acc: 0.9506 - val_loss: 0.3782 - val_acc: 0.8826\n",
      "Epoch 25/30\n",
      "4901/4901 [==============================] - 163s 33ms/step - loss: 0.1349 - acc: 0.9557 - val_loss: 0.3810 - val_acc: 0.9013\n",
      "Epoch 26/30\n",
      "4901/4901 [==============================] - 163s 33ms/step - loss: 0.1239 - acc: 0.9492 - val_loss: 0.3887 - val_acc: 0.9063\n",
      "Epoch 27/30\n",
      "4901/4901 [==============================] - 163s 33ms/step - loss: 0.1421 - acc: 0.9482 - val_loss: 0.3923 - val_acc: 0.8907\n",
      "Epoch 28/30\n",
      "1150/4901 [======>.......................] - ETA: 1:46 - loss: 0.1467 - acc: 0.9383"
     ]
    }
   ],
   "source": [
    "#grid_result = grid.fit(X_train, Y_train)\n",
    "grid_result  = grid.fit(X_train,\n",
    "                           Y_train,\n",
    "                           validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "pDQ23QfzC9XQ",
    "outputId": "16ddf981-2481-48f3-e97d-914f469cc1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 128)          70656     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 466,438\n",
      "Trainable params: 466,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(n_classes,kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1839
    },
    "colab_type": "code",
    "id": "sVXI-cXaCvL9",
    "outputId": "2b605f11-ee8d-4fc0-89cb-1acf6bd369af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 138s 19ms/step - loss: 1.3694 - acc: 0.3945 - val_loss: 2.2371 - val_acc: 0.2284\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 139s 19ms/step - loss: 1.1898 - acc: 0.4497 - val_loss: 1.0940 - val_acc: 0.5239\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.9724 - acc: 0.5335 - val_loss: 1.0509 - val_acc: 0.5707\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.8199 - acc: 0.6035 - val_loss: 0.8872 - val_acc: 0.5898\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 137s 19ms/step - loss: 0.7409 - acc: 0.6357 - val_loss: 0.8779 - val_acc: 0.6305\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.6975 - acc: 0.6594 - val_loss: 0.8771 - val_acc: 0.5728\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.6736 - acc: 0.6814 - val_loss: 0.8874 - val_acc: 0.6159\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.5794 - acc: 0.7311 - val_loss: 0.6869 - val_acc: 0.7499\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.5925 - acc: 0.7345 - val_loss: 0.6720 - val_acc: 0.7078\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.5077 - acc: 0.7811 - val_loss: 0.6462 - val_acc: 0.7822\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.4268 - acc: 0.8421 - val_loss: 0.4576 - val_acc: 0.8140\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.3046 - acc: 0.8976 - val_loss: 0.3923 - val_acc: 0.8823\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.2446 - acc: 0.9159 - val_loss: 0.3602 - val_acc: 0.8938\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.2240 - acc: 0.9236 - val_loss: 0.3749 - val_acc: 0.8938\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1849 - acc: 0.9329 - val_loss: 0.2970 - val_acc: 0.9074\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.1862 - acc: 0.9325 - val_loss: 0.2673 - val_acc: 0.9121\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1595 - acc: 0.9433 - val_loss: 0.2648 - val_acc: 0.9074\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1592 - acc: 0.9423 - val_loss: 0.2967 - val_acc: 0.9077\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1588 - acc: 0.9422 - val_loss: 0.4456 - val_acc: 0.8989\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1439 - acc: 0.9412 - val_loss: 0.3015 - val_acc: 0.9118\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1454 - acc: 0.9461 - val_loss: 0.3200 - val_acc: 0.9172\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1411 - acc: 0.9501 - val_loss: 0.2262 - val_acc: 0.9172\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1314 - acc: 0.9489 - val_loss: 0.2911 - val_acc: 0.9175\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1701 - acc: 0.9423 - val_loss: 0.3305 - val_acc: 0.9253\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1438 - acc: 0.9468 - val_loss: 0.7643 - val_acc: 0.8755\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1438 - acc: 0.9487 - val_loss: 0.2761 - val_acc: 0.9209\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1363 - acc: 0.9479 - val_loss: 0.3053 - val_acc: 0.9152\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1454 - acc: 0.9478 - val_loss: 0.3322 - val_acc: 0.9206\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1339 - acc: 0.9464 - val_loss: 0.3612 - val_acc: 0.9189\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.1376 - acc: 0.9455 - val_loss: 0.3418 - val_acc: 0.9277\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.1496 - acc: 0.9457 - val_loss: 0.4070 - val_acc: 0.9199\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1285 - acc: 0.9497 - val_loss: 0.4626 - val_acc: 0.9091\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1258 - acc: 0.9508 - val_loss: 0.4123 - val_acc: 0.9084\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.1394 - acc: 0.9471 - val_loss: 0.3678 - val_acc: 0.9270\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1197 - acc: 0.9539 - val_loss: 0.3871 - val_acc: 0.9101\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1340 - acc: 0.9529 - val_loss: 0.3410 - val_acc: 0.9213\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1320 - acc: 0.9497 - val_loss: 0.4934 - val_acc: 0.9030\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1179 - acc: 0.9524 - val_loss: 0.4031 - val_acc: 0.9165\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.1473 - acc: 0.9484 - val_loss: 0.3101 - val_acc: 0.9220\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 134s 18ms/step - loss: 0.1163 - acc: 0.9518 - val_loss: 0.4339 - val_acc: 0.9128\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1243 - acc: 0.9501 - val_loss: 0.3783 - val_acc: 0.9206\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1329 - acc: 0.9510 - val_loss: 0.5333 - val_acc: 0.9033\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.2407 - acc: 0.9339 - val_loss: 0.4043 - val_acc: 0.9131\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.1352 - acc: 0.9483 - val_loss: 0.4706 - val_acc: 0.9111\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1201 - acc: 0.9513 - val_loss: 0.4183 - val_acc: 0.9294\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.1414 - acc: 0.9505 - val_loss: 0.5044 - val_acc: 0.8985\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 137s 19ms/step - loss: 0.1236 - acc: 0.9501 - val_loss: 0.4662 - val_acc: 0.9172\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 136s 19ms/step - loss: 0.1179 - acc: 0.9518 - val_loss: 0.4144 - val_acc: 0.9233\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 137s 19ms/step - loss: 0.1215 - acc: 0.9533 - val_loss: 0.4894 - val_acc: 0.9240\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 137s 19ms/step - loss: 0.1197 - acc: 0.9525 - val_loss: 0.4575 - val_acc: 0.9101\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, nb_epoch=50, batch_size=50 ,verbose=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "ts2ltKCtlRxK",
    "outputId": "f837bb05-4244-49fa-e860-27fc03b5ba61"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('categorical_crossentropy')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,50+1))\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "SIAPBu_AvnmW",
    "outputId": "f14b9b61-b982-46a3-b499-6ecb27243927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------------+---------------------------+--------------+-------------+------------+\n",
      "| No. of hidden layers | No. of neurons in layer 1 | No. of neurons in layer 2 | Dropout rate | Train Score | Test Score |\n",
      "+----------------------+---------------------------+---------------------------+--------------+-------------+------------+\n",
      "|          1           |            128            |            None           |     0.3      |    0.9535   |   0.8996   |\n",
      "|          2           |            128            |            256            |     0.7      |    0.9525   |   0.9101   |\n",
      "+----------------------+---------------------------+---------------------------+--------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"No. of hidden layers\",\"No. of neurons in layer 1\",\"No. of neurons in layer 2\",\"Dropout rate\", \"Train Score\", \"Test Score\"]\n",
    "\n",
    "x.add_row([1,128,\"None\", 0.3, 0.9535, 0.8996])\n",
    "x.add_row([2,128,256, 0.7, 0.9525, 0.9101])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5oBP0HAj_Jg"
   },
   "source": [
    "### There are a total of two LSTM models. One with a single layer of LSTM and Another with 2 layered LSTM layers.\n",
    "\n",
    "## 1 layered model\n",
    "\n",
    "    1. For one layered LSTM model Hyperparameter tuning was done for number of neurons and dropout rates.\n",
    "\n",
    "    2. The number of neurons to selesct from were 48,128  neurons.\n",
    "    \n",
    "    3. The dropout rate for the model were 0.3, 0.5, 0.7\n",
    "\n",
    "\n",
    "## 2 layered model\n",
    "\n",
    "    1. The number of neurons for first layer is 128 with a dropout rate of 0.7 \n",
    "    \n",
    "    2. The number of neurons for second layer is 256 with a dropout rate of 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kh2FhYkHuyMi"
   },
   "source": [
    "# CONCLUSION\n",
    "\n",
    "1) For single LSTM model, best hyperparameter was found to be of 128 neurons and 0.3 dropout rate. The Trainscore is 95.35% and Test score is 89.96%\n",
    "\n",
    "2) The Train score is 96.8% and Test score us 92.98%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKBq_3C2yNIt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_submittion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
